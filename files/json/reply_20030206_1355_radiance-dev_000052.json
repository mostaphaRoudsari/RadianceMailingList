{"body": "--0-1823404658-1044568528=:53774\nContent-Type: text/plain; charset=us-ascii\n\n\n\n\nWhat about a process that works with the ambient file and, either in real-time, or as a batch process, distills the ambient data points.  At a minimum, it should cull duplicate points, and preferably, could do some gaussian (or other) smoothing on the data.  The culling would reduce child process startup times for large datasets and the smoothing would possibly reduce wierdness in the ambient data, or at least make the wierdness less obvious.\nI mention it now not only because I've been frustrated with long startup times in the past, but also because if this mechanism is to work in real time, then the design of the ambient data file server should keep this capability in mind.\n-Chas\n\n\n--0-1823404658-1044568528=:53774\nContent-Type: text/html; charset=us-ascii\n\n\n<P>What about a process that works with the ambient file and, either in real-time, or as a batch process, distills the ambient data points.&nbsp; At a minimum, it should cull duplicate points, and preferably, could do some gaussian (or other)&nbsp;smoothing on the data.&nbsp; The culling would reduce child process startup times for large datasets and the smoothing would possibly reduce wierdness in the ambient data, or at least make the wierdness less obvious.\n<P>I mention it now not only because I've been frustrated with long startup times in the past, but also because if this mechanism is to work in real time, then the design of the ambient data file server should keep this capability in mind.\n<P>-Chas</P>\n--0-1823404658-1044568528=:53774--\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/radiance-dev/2003-February/000052.html).</sup>", "attachments": [], "created_by_name": "Charles Ehrlich", "created_at": "February 06, 2003 at 01:55PM", "created_by": "Charles_Ehrlich", "parent_id": "radiance-dev_000042", "id": "radiance-dev_000052"}