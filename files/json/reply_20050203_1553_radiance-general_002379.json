{"body": "Say you are tracing your 10,000,000 rays to generate a test image that \nyou hope to compare to the official result for Radiance 3.6.1.  \nSomewhere in the middle of your image (more likely the beginning), you \nhit some surface deep in the ray tree after 4 or 5 reflections, and \nRadiance makes the following test:\n\n\n\tif (r->rweight < minweight)\n\t\treturn(0);\t\t\t/* don't trace this ray */\n\n\nwhere minweight is set by the -lw option to rpict.  Well, it just so \nhappens that r->rweight is almost exactly equal to minweight at this \npoint in the calculation.  On one machine, the statement will evaluate \nto true, and on another machine architecture, it evaluates to false.  \nBig deal.  You've just altered the result by maybe 1e-3, which is \nwithin the tolerance of your image comparison metric.\n\n\nHowever, since you've decided not to trace that ray and all the rays \nthat spawn from it, let's say that's 12 calls to random() that you \nwon't be making during this rendering.  (It doesn't matter how many \ncalls it is you miss -- one is enough.)  All your subsequent calls to \nrandom() will therefore be completely different from what they were on \nthat other machine, even using the exact same implementation of \nrandom().\n\n\nHow likely is the above scenario?  Nearly 100%, because in 10,000,000 \nrays you are bound to find some threshold test somewhere in the code \nthat can go one way or another.  Setting -lw 0 is only a partial \nsolution, because there are other floating point tests and thresholds \nthat can't be altered or avoided within the code.  Welcome to the \nvaguaries of floating-point calculations.\n\n\n-Greg\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/radiance-general/2005-February/002379.html).</sup>", "attachments": [], "created_by_name": "Greg Ward", "created_at": "February 03, 2005 at 03:53PM", "created_by": "Greg_Ward", "parent_id": "radiance-general_002366", "id": "radiance-general_002379"}