{"body": "Hi Marcus,\n\n\nChas' suggestion of rendering small white cards into your scene at  \nlow resolution would certainly work.  It would give you a pretty good  \nidea of the color cast resulting from interreflections, which you  \ncould then correct using pfilt.  However, it may not be necessary to  \nfind a white or gray surface at all, since you know what you want  \neach surface to be based on the diffuse RGB values you've assigned to  \nthem in your material description.  Simply divide the RGB's measured  \nfrom the rendering into the RGB's in your input and apply this as a  \ncolor correction.  Say you have a diffuse surface whose reddish color  \ncast you don't like, whose specification says it should have an RGB  \nvalue of (0.35,0.21,0.47) and whose actual RGB value as measured by  \nthe 'c' command in ximage gives you back (2.15,1.1,1.5).  You could  \nbalance the color of this image with:\n\n\n     % pfilt -1 -er `ev 0.35/2.15` -eg `ev 0.21/1.1` -eb `ev  \n0.47/1.5` rendered.pic > corrected.pic\n\n\nYou say you are getting an error about \"exposure out of range,\" but  \nyou didn't say which program was generating this error or under what  \ncircumstances.\n\n\nThe reason I'm less fond of your code change suggestion is because  \ncolor bleeding really does happen, and if you've modeled your surface  \ncolors correctly, your overall result will appear more realistic if  \nyou perform white balancing rather than getting rid of color bleeding  \naltogether.\n\n\n-Greg\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/radiance-dev/2005-August/000632.html).</sup>", "attachments": [], "created_by_name": "Greg Ward", "created_at": "August 18, 2005 at 03:53AM", "created_by": "Greg_Ward", "parent_id": "radiance-dev_000628", "id": "radiance-dev_000632"}