{"body": "Hi Lisa,\n\n\nNikon really does make the greatest lenses.  LBNL has this f/2.8  \nNikkor fisheye that's just amazing, but unfortunately doesn't work  \nwith any of the Nikon digital cameras in the sense that the 1.5  \nmultiplier turns the 180 degree circle into a partial view.  It's  \nvignetting is quite low for a fisheye -- just -20% at the edge at f/ \n4.0.  The 8mm Sigma lens we got for the Canon is pathetic by  \ncomparison, with vignetting of -80% from at the edge at f/5.6, and  \nthe eccentricity is not very linear, either.  (See attached graphs  \nfor comparison.)  Unfortunately, the Nikkor->Canon adaptor ring we  \nbought doesn't seem to work for a Nikkor manual lens.\n\n\nRegarding RAW captures, I've run into problems with pink highlights  \nshowing up under some lighting conditions, and I can't seem to shake  \nthem.  There are also issues with noise at the bottom end, and we  \navoid this as well if we just use JPEG or 24-bit TIFF output.  The  \nreason is that cameras have a lot of built-in processing that cleans  \nup the sensor range and shortcomings you just don't want to deal with  \nyourself.  As long as the camera doesn't mess up the tone curve, the  \non board processing generally helps the HDR merge process more than  \nit hurts it.  (Automatic white balance is one of the notable  \nexceptions, but luckily we can disable that.)\n\n\nThe potential benefit you cite for RAW images, the bit depth, turns  \nout to be an illusion.  Although many RAW files contain 12 bits/ \nchannel, it's in a linear space rather than the gamma response space  \nof JPEG or 24-bit TIFF, and doesn't actually encompass a greater  \ndynamic range.  (See my page at <http://www.anyhere.com/gward/hdrenc/ \n >  and scroll down to \"What Is a Gamma Encoding?\" to more.)  Since  \nthe camera and the A/D converter inside the camera are both linear  \ndevices, this is in fact why 12 bits is necessary for an 8-bit gamma- \nencoded output.  Otherwise, you'd end up with horribly visible  \nquantization errors (banding) at the bottom end.\n\n\nSo what happens to the extra 4 bits of resolution?  The answer is, it  \ngets *wasted* at the top end, giving us much finer steps than we're  \nable to see or represent in an 8-bit, gamma=2.2 encoding.  Could this  \never be useful in an HDR merging process?  Maybe, if your output  \nformat could capture these finer steps, and you spaced your exposures  \nclose enough that you could get the top ends of all your exposures to  \ncover the full range of the scene, but by that time, exposure  \naveraging will give you the same benefit from standard 8-bit/channel  \nJPEGs.  In other words, a RAW process to HDR is a lot of work for  \nvery little benefit.  You don't get additional range at the top or  \nbottom; white balance ends up as more of a problem rather than less  \nof one, and the loss of noise-reduction processing in the camera  \nmakes the deep shadows look much worse.\n\n\nI spent the better part of a week playing with dcraw.c and the Canon  \nEOS 5D to find all this out.  It's possible that my conclusions don't  \napply to all cameras that produce RAW output, but in some ways,  \nthat's another argumentagainst it -- camera RAW files are all  \ndifferent!  If you're trying to build up or recommend a standard  \npractice, I think RAW is a great big unknown in the equation, and  \nmuch harder to work out than the camera response function, which is  \nas far as I can tell, the *only* effort RAW saves you.\n\n\nThat's my 2 cents.\n-Greg\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/hdri/2006-January/000021.html).</sup>", "attachments": [], "created_by_name": "Greg Ward", "created_at": "January 21, 2006 at 08:16AM", "created_by": "Greg_Ward", "parent_id": "hdri_000017", "id": "hdri_000021"}