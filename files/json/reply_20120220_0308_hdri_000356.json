{"body": "Hi Yulia,\n\n\nI, too, am looking at HDR measurements of artificial light sources in\nthe hope of measuring glare. The results I've been getting are rather\ninconsistent, so I've been doing some googling and reading.\n\n\n> I was able to figure out luminance values for a single LED, which can be\n> compared to the ones from HDR images. But I have a couple of\n> questions/concerns on HDRI technique and Photosphere.\n\n\n> At first, I\u2019ve used \u201cregular\u201d scene to retrieve response curve of the camera\n> (large smooth gradients with very dark and bright areas, and had reflectance\n> standards for the absolute calibration).\n>\n> Camera: EOS T1i Rebel with 28-105mm lens, at 28mm\n> Calibrated at the grey reflectance sample 186.45 cd/m2\n> CF=0.957\n\n\n> Then I use this RC to analyze HDRI of a captured LED. The value is 230,000\n> cd/m2 for a single LED, which is low (it\u2019s has to be around 7*106 cd/m2).\n> So, it underestimates the luminance.\n\n\nMcCann and Rizzi have done some quite comprehensive research into the\ndynamic range of cameras and how it is limited by veiling glare. They\nhave published an HDR book\n\"The Art and Science of HDR Imaging\" (Wiley, 2011), and many of their\npapers are available on\nhttp://web.mac.com/mccanns/HDR/Glare_Limits_HDRI.html\n\n\nTo wet your appetite, I recommend\nhttp://web.mac.com/mccanns/HDR/Glare_Limits_HDRI_files/07EI%206492-41_1.pdf\nTheir conclusion is that accurate HDR luminance measurements are not\nactually possible because veiling glare that is generated within the\nlens limits the dynamic range of the optical system. Apparently, there\nis actually an ISO standard (9358:1994) that comes to the same\nconclusion: The higher the dynamic range of the scene, the more\ninaccurate the HDR measurement.\n\n\nYou will be aware of the 'flare removal' option in hdrgen (-f switch).\nI'm not entirely sure where 'flare' sits between 'point spread\nfunction' and 'veiling glare', but I believe it to be closer to the\nformer. The PSF is a funciton of any optical system that results in\nthe image to become 'smudged' out. Back a few years ago when the\nmegapixel race was in full swing, many observers correctly stated that\nthe lenses on cheap digital cameras can't actually provide a\nresolution that a would justify, say, 12MP on a digital snap shot\ncamera. This is the PSF they were talking about--it's how a pixel\naffects the neighbouring pixels.\n\n\nWhile the PSF can be estimated (or even calculated, given enough\ninformation about the lenses and their optical properties? Not\nsure...), veiling glare, on the other hand, cannot because it depends\non the scene. Every 'pixel' of the scene affects every pixel of the\nimage. It's even worse than that: Even scene objects outside of the\nfield of view of the optical system have an impact on the sensor\nimage.\n\n\nHoefflinger (Ed.) \"High-Dynamic-Range (HDR) Vision\" (Springer, 2007)\nhas an entire section dedicated to HDR lenses. While true HDR low-res\n(video-) cameras are actually becoming commercially available (they\nhave a logarithmic response, with a dynamic range far exceeding that\nof the human vision), the problem is that they require special HDR\nlenses that have to be carefully designed to minimise veiling glare.\nDigial camera lenses (even pro-level DSLR ones) are not optimised for\nthis.\n\n\nSo there is nothing wrong with the camera calibration that you carried\nout with a LDR scene. This is how it should be done. The problem\nyou're facing is not specific to Photosphere or the Mitsunaga RSP\nrecovery algorithm. The RSP is not compressed at the upper end--it's\njust Physics that you're up against.\n\n\n> It seems like calibration point is critical here. I\u2019ve decided to try to\n> capture a different scene for deriving RC with a wider range. It would make\n> sense that camera has to see higher luminance values in order to accurately\n> measure them later. The dynamic range has to cover measured values.\n>\n> 1.\u00a0 \u00a01. How does Photosphere deals/approximates/calculates the upper end of\n> the curve? I assume it gives more weight to mid tone values? But what\n> happens with high luminance values?\n\n\n> 2.\u00a0\u00a0\u00a0\u00a0 I assumed when CF is applied, it does not equally change all values,\n> but does it proportionally to RC (since it is not linear). \u00a0Why does it do\n> it equally for the whole range?\n>\n> Lsun=80*106 cd/m2. And of course CF is very big 391.\n\n\n> 3.\u00a0\u00a0\u00a0\u00a0 Does photosphere compress the response curve, so at the upper end all\n> values above certain threshold will have the same number?\n>\n> 4.\u00a0\u00a0\u00a0\u00a0 Any additional suggestions on properly obtaining and calibrating HDRI\n> for this purpose?\n\n\nI'm afraid you have to lower your expectations with regards to the\nachievable accuracy when it comes to HDR scenes that include bright\nlight sources.\n\n\nLight modulation ('flicker') is another problem with HDR measurements\nof electric light sources. Unless you are certain that your light\nsource is driven by a HF driver or ballast, I recommend you actually\nmeasure the modulation of the light source. If the LEDs are mains\ndriven, they will flicker with 100 or 120 Hz, depending on your mains\nfrequency. If the modulation factor is high, e.g. if the LEDs\neffectively switch on and off with this frequency, HDR measurements at\nshort exposure times will be unpredictable. You can test this by\ntaking a number of photographs of the same scene (with light source in\nit) at short exposure times. There is no need to go HDR. If all images\nhave the same overall 'brightness', you're all right. If the images\nare noticeably different, you've got yet another problem.\n\n\nCheers\n\n\nAxel\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/hdri/2012-February/000356.html).</sup>", "attachments": [], "created_by_name": "Axel Jacobs", "created_at": "February 20, 2012 at 03:08AM", "created_by": "Axel_Jacobs", "parent_id": "hdri_000401", "id": "hdri_000356"}