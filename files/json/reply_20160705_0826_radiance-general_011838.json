{"body": "Since it seems that the attachment was stripped from my original\nmessage, here are the contents of the 3d360.cal file that I used:\n\n\n{\n  3d360.cal\n\n\n  Definitions for full 360 over-under stereo equirectangular projection\n\n\n  (c)2014 Mark J. Stock\n\n\n  Use it like this:\n  X=2048; Y=2048; cnt $Y $X | rcalc -f 3d360.cal -e\n\"XD=$X;YD=$Y;X=0;Y=0;Z=-0.1;IPD=0.06;EX=0;EZ=0\" | rtrace [rpict\noptions] -x $X -y $Y -fac scene.oct > out.hdr\n\n\n  Parameters defined externally:\n  X : neck rotation origin x\n  Y : neck rotation origin y\n  Z : neck rotation origin z\n  XD : horizontal picture dimension ( pixels )\n  YD : vertical picture dimension ( pixels )\n  IPD : inter-pupillary distance\n       this is between 0.055m and 0.07m on most humans\n  These don't seem to work all that well:\n  EX : forward distance between neck rotation center and bridge of\nnose (between eyes)\n       this is between 0.05m and 0.07m on most humans\n  EZ : vertical distance between neck rotation center and eye\nelevation when altitude is 0 degrees\n       this is around 0.1m on most humans\n}\n\n\n{ Direction of the current pixel (both angles in radians) }\npx = $2;\npy = YD - $1;\nfrac(x) : x - floor(x);\naltitude = (frac((py-0.5)/(YD/2)) - 0.5) * PI;\n{ to do over-under stereo, azimuth is easy }\nazimut = px * 2 * PI / XD;\n\n\n{ Transformation into a direction vector }\nxdir = cos(azimut) * cos(altitude);\nydir = sin(azimut) * cos(altitude);\nzdir = sin(altitude);\n\n\n{ Transform the viewpoint to account for the eye position }\ndx = EX;\ndy = if($1 - YD/2, 0.5*IPD, -0.5*IPD);\ndz = EZ;\nxpos = X + xdir*dx - sin(azimut)*dy + cos(azimut)*zdir*dz;\nypos = Y + ydir*dx + cos(azimut)*dy + sin(azimut)*zdir*dz;\nzpos = Z - zdir*dx +           0*dy + cos(altitude)   *dz;\n\n\n{ Output line to rtrace; each ray needs: xorg yorg zorg xdir ydir zdir }\n$1 = xpos; $2 = ypos; $3 = zpos;\n$4 = xdir; $5 = ydir; $6 = zdir;\n\n\n{ EOF }\n\n\nNote that the above will generate a 1:1 ratio final image, with left\non the top half and right on the bottom. To knock that down to 16:9\nfor Youtube, I used the following mencoder command:\n\n\nmencoder \"mf://@allframes.txt\" -mf w=3840:h=3840:type=png:fps=30 -o\nMarkStock_SmokeWaterFire_UHD_360_TB.mp4 -sws 9 -of lavf -lavfopts\nformat=mp4 -nosub -vf softskip,dsize=16/9,scale=3840:2160,harddup\n-nosound -ovc x264 -x264encopts\ncrf=24:nointerlaced:force_cfr:frameref=3:mixed_refs:bframes=1:b_adapt=2:weightp=1:direct_pred=auto:aq_mode=1:me=umh:me_range=16:subq=6:mbtree:psy_rd=0.8,0.2:chroma_me:trellis=1:nocabac:deblock:partitions=p8x8,b8x8,i8x8,i4x4:nofast_pskip:nodct_decimate:threads=auto:ssim:psnr:keyint=300:keyint_min=30:level_idc=30:global_header\n\n\nAlso, two piece of advice for makers of 360 or 3D-360 videos from\nOculus and Youtube:\n\n\nhttps://support.oculus.com/help/oculus/1044498395609952/?ref=hc_fnav\nhttps://support.google.com/youtube/answer/6178631?hl=en\n\n\nMark\n\n\nOn 7/1/16, Andy McNeil <mcneil.andrew at gmail.com> wrote:\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/radiance-general/2016-July/011838.html).</sup>", "attachments": [], "created_by_name": "Mark Stock", "created_at": "July 05, 2016 at 08:26AM", "created_by": "Mark_Stock", "parent_id": "radiance-general_011824", "id": "radiance-general_011838"}