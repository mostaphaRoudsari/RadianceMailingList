{"topic": "primitive plan for meshes", "category": "radiance-dev", "attachments": [], "created_by_name": "Greg Ward", "created_at": "February 28, 2003 at 07:51AM", "body": "I am thinking about adding a \"mesh\" primitive to Radiance, which would \nbe the first new geometric primitive since the system's inception.  The \npurpose is to facilitate arbitrary shapes that are inherently complex, \nminimize the associated memory costs, and improve rendering quality and \nefficiency.  Currently, meshes are represented in memory as individual \npolygons, each of which incurs an overhead of 76 bytes, plus the space \nrequired by N double-precision 3-points, which is 76+3*3*8, or 124 \nbytes in the typical case of a triangle.\n\n\nIn a well-constructed t-mesh, each non-boundary vertex has a valence of \n6, which means that we can save a lot of memory by sharing vertices \nrather than repeating them in individual triangles.  Furthermore, mesh \nvertices can be constrained to fit within a bounding box, permitting \nthem to be represented by 32-bit integers rather than 64-bit doubles, \nwhich saves another factor of two.  We have to add back in some \noverhead for vertex indexing, but I think I can reduce this to one byte \nper reference using face grouping -- I'll have to think about it some \nmore.  The biggest memory savings, though, comes when we specify vertex \nnormals, which currently requires a separate texfunc primitive with 13 \nreal arguments for each face (132 bytes with overhead).\n\n\nAdding it all together, a smoothed t-mesh with 10,000 vertices (small \nby today's standards) occupies about 5 Mbytes of memory.  Moving to a \nmesh primitive, I should be able to fit the same mesh into about 150K, \nincluding acceleration data structures.  This means we should be able \nto render objects over 30 times as complex as before.\n\n\nOne of the main reasons I never implemented meshes in Radiance is that \ndoing so makes it nearly impossible to leverage the existing ray \nintersection machinery.  With the current arrangement, all the mesh \ntriangles end up in the scene octree (or a local octree if the mesh is \ninstanced), so rays find mesh polygons the same way they find other \nscene geometry, by traversing an octree.  Introducing meshes means \ninstead of encountering of a polygon in the octree, we encounter a mesh \ncomprised of many, many polygons, and we have no idea which of these \ntriangles to test for intersection.  Testing them all would is a really \nbad idea from an efficiency standpoint.\n\n\nI've given this a little thought, and I think I've come up with an \nefficient acceleration structure that I can compute quickly on object \nload that will enable both mesh/octree and mesh/ray intersection \ntesting.  All I need to store is 3 orthonormal images on the mesh \nbounding box, where each image pixel contains the set of triangles that \nproject onto that position (without hidden surface removal).  We \ntraverse the mesh bounding box with a ray using a 3DDA (3-diminetional \ndifferential analyzer), computing the intersection of the three \northonormal pixel sets at each 3-D voxel.  If a triangle is in all \nthree sets, that means we are within its local bounding box, and should \ntest it for intersection with the ray.\n\n\nAnother bonus we'll get with this implementation is something Radiance \nhas never had -- local (u,v) coordinates!  These can be stored wtih our \nvertices and made available for patterns and textures through the \nfunction language as new variables, Lu and Lv.  Their values will be \nset in the mesh input file, for which I plan to use Wavefront .OBJ, \nsince it already contains pretty much everything we need to specify a \nmesh without a lot of fluff.  Here's the primitive specification I have \nin mind:\n\n\nmod mesh id\n1+ mesh_file.obj [xf ..]\n0\n0+ [smoothing_angle]\n\n\nThe same mesh file may be used by multiple primitives, and all data \nwill be shared as it is with the instance primitive that bears close \nresemblance.  The optional smoothing_angle parameter sets the angle \nbelow which faces with unspecified normals will be automatically \nsmoothed.  The default value of 0 means that faces will not be \nsmoothed.  A value of 5 would smooth faces with initial surface normals \nless than 5 degrees apart.  Values of 90 or greater would even smooth \nover sharp corners, which probably isn't a good idea.\n\n\nSo, why am I writing all this?  Well, mostly because I wanted to get \nsome feedback from people before I went to all this trouble.  Do we \nneed meshes or not?  Is what we have perfectly adequate, or has it been \na nuisance all along?  Am I going about it all wrong -- e.g., should I \nbe using subdivision surfaces instead of t-meshes?  Smoothed meshes are \nnotorious for creating reflection and refraction problems due to \ninconsistent normals, which was my other excuse for avoiding them all \nthese years.\n\n\nPlease share your thoughts.  I almost posted this to the general \nmailing list, but thought better of it.  If you think it would benefit \nfrom a larger forum, I'll reconsider.\n\n\n-Greg\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/radiance-dev/2003-February/000056.html).</sup>", "id": "radiance-dev_000056", "created_by": "Greg_Ward"}