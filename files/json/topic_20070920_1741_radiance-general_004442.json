{"topic": "Radiance 2007 Scientific Workshop - SCHEDULE", "category": "radiance-general", "attachments": [], "created_by_name": "Katja Doerschner", "created_at": "September 20, 2007 at 05:41PM", "body": "Radiance 2007 Scientific Workshop - SCHEDULE\n01-02 (Mon-Tues) October 2007, Digital Technology Center, University  \nof Minnesota, Minneapolis, USA.\n\n\n\n\nDear All,\n\n\nHere is the tentative schedule for this year's Radiance workshop.  \nTomorrow you will also be able to view it online at http:// \nwww.dtc.umn.edu/cgi-bin/seminars/symposia/radiance.php.\n\n\nIn general, we will have presentations (talks) in the mornings and  \ntutorial sections in the afternoons.\n\n\nIf you haven't registered yet, please try to do so sooner rather than  \nlater, as it will help us to get a proper head count for the tour,  \nreception and banquet.\n\n\nSee below what you can look forward to/ what you are missing out on  \n(if you don't attend!).\n\n\nLooking forward to see you at the workshop!\n\n\nGreg,\n& Katja\n\n\n\n\nMEETING SCHEDULE\n\n\nOctober 1:\n\n\n8:30-9:30 Meet & Greet / Coffee\n\n\n9:30-9:45 Greg Ward & Katja Doerschner,  Introduction\t\n\n\n9:45-10:25\nRoland Fleming, Max Planck Institute for Biological Cybernetics,  \nTuebingen, Germany\n\n\n\u201cVisual Perception of Surface Material\u201d\nDifferent materials such as silk, bronze and marmalade have  \ndistinctive visual appearances.  Human observers are remarkably adept  \nat recognizing materials across a wide range of viewing conditions  \nand we are only just beginning to work out how.  What gives a  \nmaterial its characteristic \u2018look\u2019?  What cues does the visual system  \nuse to identify materials?  How can we leverage the assumptions made  \nby the visual system to improve computer graphics?  I will review  \nsome of our research on the perception of material properties such as  \ngloss, translucency and refractive index that attempts to shed some  \nlight on these questions.  I\u2019ll talk about how illumination and 3D  \ngeometry interact with material perception, and discuss the role of  \nvarious image statistics (e.g. intensity histogram, amplitude  \nspectrum) in the visual estimation of material attributes.  I\u2019ll then  \nshow one application in which we exploit the heuristics made by the  \nvisual system to enable illusory modifications of material appearance  \nin photographs.\n\n\n10.30-10.50 Coffee Break\n\n\n10:50-11:20\nYu Sheng, Rensselaer Polytechnic Institute, Troy, NY\t\n\n\n\"Comparing an interactive hybrid global illumination method with  \nRadiance\"\nComplex fenestration systems (CFS) can be used to redirect intense  \nillumination from the sun to more evenly illuminate an architectural  \nspace and thus reduce the lighting needs of buildings. However,  \nstandard distribution of Radiance does not support rendering of CFS  \nor arbitrary BRDF/BTDF material data. In this talk, we present an  \ninteractive rendering system for architectural design which simulates  \na CFS based on 4D Bidirectional Transmission Distribution Function  \n(BTDF) data. We use a hybrid method of shadow volumes for direct  \nillumination and radiosity for indirect illumination to achieve  \ninteractive rendering rates.\nOur system is appropriate for use in schematic design: an early stage  \nof the architectural design process where scale, appearance, and  \nadjacencies of an evolving design are explored. We demonstrate our  \nsystem on several models inspired by field observations and the  \ndesigns of architecture students we have consulted during the  \ndevelopment of this project.\n\n\n11:20-11:50\nBei Xiao, University of Pennsylvania, Philadelphia, PA\n\n\n\u201cEffect of test patch location on color appearance, in the context of  \n3D objects\u201d\nBei Xiao (1) and David Brainard (2)\n(1) Department of Neuroscience, School of Medicine, University of  \nPennsylvania, Philadelphia, PA, 19104, USA. (2) Department of  \nPsychology, University of Pennsylvania, Philadelphia, PA, 19104, USA.\n\n\nThe light reflected from different locations on a single object can  \nvary enormously.  This variation is enhanced when the material  \nproperties of the object are changed from matte to glossy.  Yet  \nhumans have no trouble perceiving an object as having a unified  \ncolor.  We conducted a psychophysical experiment to study how people  \nperceive the color of different parts of an object.  Observers viewed  \ngraphics simulations of a three-dimensional scene containing two  \nobjects, test and match (generated with Radiance in conjunction with  \ncustom software that provided full spectral rendering).  The test  \nobject was a soccer ball that had one colored hexagonal face (test  \npatch).  Observers were asked to adjust the color appearance of a  \nmatch sphere to the test patch.  The match sphere was always matte,  \nwhile we varied the surface gloss of the entire soccer ball  \n(including the test patch).  The test patch could be located at  \neither an upper or lower location on the soccer ball.  The data show  \nthat there is an effect of test patch location on observers\u2019 color  \nmatching, but this effect is small compared to the physical change in  \nthe average light reflected from the test patch across the two  \nlocations.  In addition, we found that observers exhibit stability of  \ncolor perception of the test patch in the face of variation of  \nsurface gloss.\n\n\n12:00-1:30 Lunch\t\n\n\n1:30 -2:30\nGary Meyer, Victoria Interrante, University of Minnesota, Department  \nof Computer Science\nDigital Design Consortium and VR lab tour/demos\n\n\n2:30-3:15\nGreg Ward, Anyhere Software, Albany, CA\n\n\nTutorial: \u201cImage-based Lighting\u201d\nImage-based lighting (IBL) is a set of techniques originated by Paul  \nDebevec for incorporating synthetic objects into real-world scenery  \n<www.debevec.org>.  IBL is widely used by the movie industry for  \nspecial effects production, and offers some interesting possibilities  \nfor daylight simulation as well.  In this tutorial, Greg will  \ndemonstrate how easy it is to capture a high dynamic-range  \nenvironment map (a.k.a. a \"light probe\") using a standard digital  \ncamera and use it to render synthetic objects into a background plate  \nwith the help of Photosphere and the \"mksource\" program.  We will  \ndiscuss how other researchers, such as Santiago Torres, have employed  \nIBL and Radiance for daylighting simulation.\n\n\n3.15-3:30 Coffee Break\n\n\n3:30-4:00\nZack Rogers, Architectural  Energy Corporation, Boulder, CO\n\n\nTutorial: \u201cSensor Placement + Optimization Tool (SPOT) Update\u201d\nZack Rogers, Jennifer Scheib, Architectural Energy Corporation\n\n\nThis talk will present recent updates to the Sensor Placement +  \nOptimization Tool software that acts as a front-end interface to  \nRadiance. SPOT has grown to provide more detailed electric lighting  \nand annual daylighting analysis as well as providing photosensor  \ncontrol analysis. The focus of the presentation will be on the new  \nfeatures of the software and a case study will be presented of a  \nproject in which we used SPOT to help design a daylight responsive  \ncontrol system. The talk will be 25 minutes followed by a question  \nand answer period.\n\n\n6:30-7.30 Reception\n\n\n7.30-10:30 Banquet\n\n\n\n\n\n\nOctober 2:\n\n\n9:00-10:00\nZack Rogers, Architectural  Energy Corporation, Boulder, CO\n\n\n\u201cExperiences with Radiance in Daylighting Design, Part III\u201d\nZack Rogers, Galen Burrell and Jennifer Scheib, Architectural Energy  \nCorporation\n\n\nThis talk will present some of the Radiance modeling Architectural  \nEnergy Corporation has done in support of our Daylighting Design  \nConsulting work, focusing on the various ways we have used Radiance  \nto guide the design process.\nRadiance has proved to be extremely effective in analyzing and  \nvisualizing daylighting designs, allowing numerous daylighting design  \nalternatives to be explored beforehand, informing and guiding the  \ndaylighting design decisions of a project.  The types of daylighting  \ndesign projects that will be highlighted vary widely and include  \nschools, laboratories, offices, museums, atriums, and others.  The  \nfocus of the presentation will be on new work that has occurred since  \nthe Montreal radiance conference in 2005.\n\n\nThe talk will be broken into three-20 minute sections, one section  \ngiven by each of the presenters followed by a brief question and  \nanswer period.\n\n\n10:00-10:25 Coffee break\n\n\n10:25-10:50\nGreg Ward, Anyhere Software, Albany, CA\n\n\n\u201cUtilizing BTDF Window Data\u201d\nThis talk presents some new ideas and software for exploiting  \nmeasured and simulated bidirectional transmittance distribution  \nfunction (BTDF) data in Radiance.  Programs and standards for  \nproviding BTDF data are emerging (e.g., LBNL Window 6), and we wish  \nto take advantage of it in our simulations.  Two approaches will be  \npresented, one geared towards traditional daylight simulation and  \nrendering and the other towards annual calculations.  The first  \napproach resembles mkillum but without the usual restrictions, since  \nBTDFs can represent virtually any complex fenestration type.  The  \nsecond approach requires two passes of rtcontrib, one to account for  \nthe building exterior, and the other for the interior.  This fully  \nseparates illumination from geometry and permits time-based  \nfenestration controls to be simulated efficiently.  As this  \nconstitutes work in progress, suggestions will be most appreciated.\n\n\n10:50-11:20\nDaniel Lichtman, University of Pennsylvania, Philadelphia, PA\n\n\n\u201cRenderToolbox: A MATLAB Toolkit for Hyperspectral Rendering with  \nRadiance and PBRT\u201d\nDaniel P. Lichtman, Bei Xiao, David H. Brainard\n\n\nWe describe a set of Matlab software tools, the RenderToolbox, that  \naid in the modeling and rendering of images for use in psychophysical  \nexperiments. The toolbox, which we are making freely available, has  \nseveral important features. First, it allows the user to model scenes  \nin the popular Maya software package and export these into the  \nremainder of the rendering pipeline. Second, although the toolbox  \ninherits the scene geometry from the Maya modeler, it allows the user  \nto associate full spectral reflectance functions and parametric BRDFs  \nwith each object, and full spectral power distributions with each  \nilluminant. The toolbox then parses the scenes and associated  \nreflectance/illuminant parameters and passes these to either of two  \nrenderers. These are Radiance and Physically Based Rendering Tools  \n(PBRT). It invokes the renderers on a wavelength-by-wavelength basis  \nto produce a hyperspectral image of the scene. The fact that the  \ntoolbox transparently supports two renderers allows easy comparison  \nof their performance. In addition, the toolbox is configured to make  \nit easy to re-render the same scene geometry with different choices  \nof reflectance/illuminant parameters. Fourth, the package provides  \nsupport for converting the hyperspectral image to standard color  \nrepresentations. Finally, the package supports parallel rendering of  \nthe separate wavelength images if a computer cluster is available.  \nSeveral example scenes are included with the toolbox to demonstrate  \nits use and to compare the two renderers\u2019 performance. The simplest  \nexample, a uniformly reflective surface and a single point-light  \nsource, yields two nearly identical images. Each of these matches an  \nanalytical prediction based on the light's spectral power  \ndistribution and surface's reflectance function. A second example  \nscene includes a single sphere with uniform reflectance under a  \ndistant point-light source. Again, images rendered by Radiance and  \nPBRT are well-matched to each other and to the directly calculated  \nimage based on the Ward model of surface reflectance. The close  \nagreement of the two renderers with each other and with direct  \ncalculations for simple scenes provides added confidence that each  \nrenderer is doing a good job simulating physical light flow.\n\n\n11:20-12:00\nSusan Ubbelohde, Loisos + Ubbelohde Associates, Oakland, CA\n\n\n\u201cDaylighting in Practice: Radiance and the Design Process\u201d\nLoisos + Ubbelohde is a consulting and design firm specializing in  \nsustainable architecture.  Our consulting work focuses on advanced  \ndaylighting design and performance, energy modeling and alternative  \nenergy sources. In practice, the use of tools such as Radiance and  \nphysical models is never as direct and linear as theory might  \nassume.  Rather, our use of design and evaluation tools is  \ncontinually adapted to the design direction of the project, the  \nquestions posed by the architects, the tradeoffs and negotiations  \nnecessary with mechanical, structural, electrical engineers, lighting  \ndesigners and interior designers on the design team, and the goals  \nand concerns of the building owners and the requirements of outside  \nagencies such as the US Green Building Council. We will present a  \nrange of recent projects, both consulting projects and design  \nprojects, discussing our use of modeling tools in the projects.\n\n\n12:00-1:30 Lunch\t\n\n\n1:30-2:30\nGreg Ward, Anyhere Software, Albany, CA\n\n\nTutorial: \u201cImproved Color Rendering with RGB\u201d\nAccurate color rendering requires the consideration of many samples  \nover the visible spectrum, and advanced rendering tools developed by  \nthe research community offer multispectral sampling towards this  \ngoal. However, for practical reasons including efficiency, white  \nbalance, and data demands, Radiance still employs a simple RGB model  \nin its lighting calculations. Applied naively, this can result in  \ncolors that are qualitatively different from the correct ones. In  \nthis tutorial, we demonstrate two independent and complementary  \ntechniques for improving RGB rendering accuracy in Radiance without  \nimpacting calculation time: spectral prefiltering and color space  \nselection. Spectral prefiltering is an obvious but overlooked method  \nof preparing input colors for a conventional RGB rendering  \ncalculation, which achieves exact results for the direct component,  \nand very accurate results for the interreflected component when  \ncompared with full-spectral rendering.  In particular, we demonstrate  \nthe merits of a particular color space transform that has emerged  \nfrom the research community as the best performer in computing white  \npoint adaptation under changing illuminants: the Sharp RGB space.\n\n\n2:30-2:45 Coffee\n\n\n2:45-3:45 Tutorial, to be announced\n\n\nEnd of workshop\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKatja Doerschner\nUniversity of Minnesota\nPsychology Department\n218 Elliott Hall\n75 East River Road\nMinneapolis, MN 55455-0344\nPhone:+1 612 626-8551\nhttp://vision.psych.umn.edu/~doerschner\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/radiance-general/2007-September/004442.html).</sup>", "id": "radiance-general_004442", "created_by": "Katja_Doerschner"}