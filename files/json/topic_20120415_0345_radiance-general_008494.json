{"topic": "Optimizing Radiance for cluster rendering", "category": "radiance-general", "attachments": [], "created_by_name": "Iebele", "created_at": "April 15, 2012 at 03:45AM", "body": "Hi All, \n\n\nNobody responded to the mail below yet. In the meanwhile I tried to build Radiance with Intels icc compiler. Binaries compiled with icc (many warnings) work for a simple scene, but fail when I render complex scenes (Segmentation fault). So I went back to gcc compiled binaries, but still I wonder if somebody can give me hints on what compiler to use, which flags, etc..\n\n\nSupport from the cluster engineers suggested I should make local copies of my files to the scratch discs of the nodes where I start Radiance processes. This, because otherwise networked i/o would slow down the process, and the cluster in general. Concerning the output of the rpict/ranimate process I understand what to do. But concerning the input files, I always thought that Radiance loads all input files (geometry, image patters etc) in memory only one time for each input file.  If the latter is true, I think it does not make much difference to load scene data from my home directory over the network, or first copy the input files (about 3 GB) to scratch disc and load them in rpict/ranimate thereafter.  The input files have to be copied over the network anyways. Or am I wrong here?  \n\n\nConcerning the binaries, I have a question alike: would it be better to make a local install of the binaries for each node?   \n\n\nAny hints are most appreciated\n\n\nIebele\n\n\n\n\n\n\noconv.c(322): (col. 5) remark: PARTIAL LOOP WAS VECTORIZED.\n\n\n\n\n\n\nOp 7 apr. 2012, om 01:20 heeft Iebele het volgende geschreven:\n___\n<sup>Automatically generated content from [radiance mailing-list](https://radiance-online.org/pipermail/radiance-general/2012-April/008494.html).</sup>", "id": "radiance-general_008494", "created_by": "Iebele"}