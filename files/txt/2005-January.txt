From apian at www.radiance-online.org  Sat Jan  1 00:01:00 2005
From: apian at www.radiance-online.org (Peter Apian-Bennewitz)
Date: Sat Jan  1 00:01:04 2005
Subject: [Radiance-general] Radiance feedback-form now online
Message-ID: <E1CkVlU-0001JP-FL@localhost>

Dear coworkers,

hope you all got through the wintertime holiday period well !

Those of you already back at the PC, - you could be the first to try the
new online feedback form at

    http://www.radiance-online.org/survey1/

My motivation for it was to get more info on the Radiance community,
especially from the silent majority of users who read the mailing list,
use Radiance and may have some views and ideas just below their level of
active posting to the list.
E.g.: There's got to be a couple of students at Universities worldwide
who are confronted with Radiance each course and from which we never
hear. Especially when they _don't_ liked it.
Likewise there are probably consultants using Radiance, whose opinion is
valuable and should influence Radiance future.

Whether the idea works out, depends on your input. Which in turn may
give the folks at the research labs and universities some indication as
to what is needed next.
The number of questions is kept at a minimum (8) and the answers are
selectable multiple choice. So the entry is fast and further more, it's
anonymous.

The whole thing is planned to be used continuously over the next years,
rather than being a one-time snapshot. The current state of the survey
is listed on a second webpage, so anyone can monitor its progress.

Technically each entry is stored in a MySQL database, together with a
time stamp and the client IP number. The latter is handy in case some
bored bad guy on the Internet floods the entry form, otherwise it won't
be made public. The time stamp allows for analysis over the next years,
while the database structure allows for correlations like "what do
architects see as missing".

a happy start into 2005 to all of you

-Peter Apian-Bennewitz

From Christoph.Reinhart at nrc-cnrc.gc.ca  Sun Jan  2 19:17:17 2005
From: Christoph.Reinhart at nrc-cnrc.gc.ca (Reinhart, Christoph)
Date: Sun Jan  2 19:17:42 2005
Subject: [Radiance-general] Radiance feedback-form now online
Message-ID: <10C94843061E094A98C02EB77CFC328710DE9F80@nrcmrdex1d.imsb.nrc.ca>

Superinitiative Peter! Diana und ich wuenschen Dir ein Frohens Neues Jahr.
Hast Du vor im August nach Montreal zu kommen? Liebe Gruesse,

Tito

-----Original Message-----
From: radiance-general-bounces@radiance-online.org
[mailto:radiance-general-bounces@radiance-online.org] On Behalf Of Peter
Apian-Bennewitz
Sent: Friday, December 31, 2004 6:01 PM
To: radiance-general@radiance-online.org
Subject: [Radiance-general] Radiance feedback-form now online

Dear coworkers,

hope you all got through the wintertime holiday period well !

Those of you already back at the PC, - you could be the first to try the new
online feedback form at

    http://www.radiance-online.org/survey1/

My motivation for it was to get more info on the Radiance community,
especially from the silent majority of users who read the mailing list, use
Radiance and may have some views and ideas just below their level of active
posting to the list.
E.g.: There's got to be a couple of students at Universities worldwide who
are confronted with Radiance each course and from which we never hear.
Especially when they _don't_ liked it.
Likewise there are probably consultants using Radiance, whose opinion is
valuable and should influence Radiance future.

Whether the idea works out, depends on your input. Which in turn may give
the folks at the research labs and universities some indication as to what
is needed next.
The number of questions is kept at a minimum (8) and the answers are
selectable multiple choice. So the entry is fast and further more, it's
anonymous.

The whole thing is planned to be used continuously over the next years,
rather than being a one-time snapshot. The current state of the survey is
listed on a second webpage, so anyone can monitor its progress.

Technically each entry is stored in a MySQL database, together with a time
stamp and the client IP number. The latter is handy in case some bored bad
guy on the Internet floods the entry form, otherwise it won't be made
public. The time stamp allows for analysis over the next years, while the
database structure allows for correlations like "what do architects see as
missing".

a happy start into 2005 to all of you

-Peter Apian-Bennewitz

_______________________________________________
Radiance-general mailing list
Radiance-general@radiance-online.org
http://www.radiance-online.org/mailman/listinfo/radiance-general

From pisuke at blueyonder.co.uk  Wed Jan  5 00:46:00 2005
From: pisuke at blueyonder.co.uk (Francesco Anselmo)
Date: Wed Jan  5 00:46:23 2005
Subject: [Radiance-general] brad etc.
Message-ID: <1104882360.2522.60.camel@leviathan>

Hi all!

I've finally decided to release "brad". :)

I still consider it at a very early development stage,
(so please be patient with crashes and bugs :( )
and anybody who wants to help is very welcome!

It is available through my new "radiance tools" website
http://www.bozzograo.net/radiance/
(the website needs a lot of work, too!)

or from the CVS server at savannah
https://savannah.nongnu.org/cvs/?group=brad

I haven't checked yet if it works correctly under windows,
and I still need to write some documentation ...

Hope it can be useful ...

A happy new year to the Radiance community!

-- 
Francesco 


From cbauer- at t-online.de  Wed Jan  5 20:06:24 2005
From: cbauer- at t-online.de (Carsten Bauer)
Date: Wed Jan  5 18:56:49 2005
Subject: [Radiance-general] brad etc.
References: <1104882360.2522.60.camel@leviathan>
Message-ID: <41DC3AB0.8070602@t-online.de>

Francesco Anselmo wrote:
> Hi all!
> 
> I've finally decided to release "brad". :)
> 
Yeah, this is good news for all the folks who can't afford
(or don't want to..) to spend $$$$ on Autocad or whatever else..

thanx and greetz

-Carsten











From rpg at rumblestrip.org  Wed Jan  5 20:23:44 2005
From: rpg at rumblestrip.org (Rob Guglielmetti)
Date: Wed Jan  5 20:23:47 2005
Subject: [Radiance-general] brad etc.
In-Reply-To: <1104882360.2522.60.camel@leviathan>
References: <1104882360.2522.60.camel@leviathan>
Message-ID: <61999.209.212.87.250.1104953024.squirrel@209.212.87.250>


> Hi all!
>
> I've finally decided to release "brad". :)

> It is available through my new "radiance tools" website
> http://www.bozzograo.net/radiance/
> (the website needs a lot of work, too!)

Totally snowed under here at work, no time to look, but I am psyched about
this news, Francesco!!  I registered right away, but alas, lack the time
for a proper look-see.  But I will.  It would be *great* to be able to
play with this on the Mac (of course my Mac is on the way to Apple for
repairs, perhaps this gives you an idea of my crazy life around here right
now)!

> A happy new year to the Radiance community!

Right back at ya!

- Rob Guglielmetti
www.rumblestrip.org

From jelle.feringa at ezct.net  Thu Jan  6 15:07:03 2005
From: jelle.feringa at ezct.net (Jelle Feringa // EZCT / Paris)
Date: Thu Jan  6 15:06:28 2005
Subject: [Radiance-general] scripting genprism | no explicit holes problem
Message-ID: <20050106140608.6453A1C0024E@mwinf0603.wanadoo.fr>

Dear All,

I'm working on a python script which I use to generate polygon description
to describe walls, in order to automate an architectural design process.
(building on the  http://www.dezentral.de/soft/Polygon/index.html module)

Using an excellent library, all my functions are in place... the data is
ready to be shipped to genprism... if it wasn't for No Explicit Holes
Problem

Here you see (simplified) version of a polygon I'd like genprism to produce
a wall from...

[(4.059, 4.0599), (3.939, 4.059), (3.93, 3.93), (4.059, 3.99), (8.0, 0.0),
(0.0, 0.0), (0.0, 8.0), (8.0, 8.0)]

Nothing special, except I need to find a way to produce the Invisible Seams,
since holes aren't supported explicitly.

I'm almost sure some of you have been running into this problem as well, and
so far I haven't been able to find a suitable solution for my problem so far
(I'm learning programming... so please go easy on me ;-)

If you're as fortunate as me and also have a copy of the excellent Rendering
with Radiance, this problem is described at page 52 / 145.

#described, there's no suggestion of dealing with the problem...

Your help is appreciated!

Cheers,

Jelle




From schorsch at schorsch.com  Thu Jan  6 16:08:27 2005
From: schorsch at schorsch.com (Georg Mischler)
Date: Thu Jan  6 16:08:50 2005
Subject: [Radiance-general] scripting genprism | no explicit holes problem
In-Reply-To: <20050106140608.6453A1C0024E@mwinf0603.wanadoo.fr>
References: <20050106140608.6453A1C0024E@mwinf0603.wanadoo.fr>
Message-ID: <Pine.BSF.4.58.0501060948510.78081@emancholl.pair.com>

Jelle Feringa // EZCT / Paris wrote:

> Dear All,
>
> I'm working on a python script which I use to generate polygon description
> to describe walls, in order to automate an architectural design process.
> (building on the  http://www.dezentral.de/soft/Polygon/index.html module)
>
> Using an excellent library, all my functions are in place... the data is
> ready to be shipped to genprism... if it wasn't for No Explicit Holes
> Problem


As far as I understand, a general solution is non-trivial.
I tried something like that in AutoLisp more than ten years ago,
but I'm not sure if the code to that still exists. In any case,
it hat quite a few problems when there were multiple holes in odd
shapes.

But the best solution to this entirely depends on the way your
input data is structured. The more you know about what kinds of
polygons you're going to see, the easier it becomes.

One alternative approach would be to cut the outer polygon apart
instead of keeping it intact. Just sort the corner points of all
the holes eg. vertically, and make a horizontal cut at each
height. You need to be careful to combine equal hights (allow for
some numeric rounding error), and not to cut through tall holes
sitting next to short ones. This method should work particularly
well if the wall and hole polygons are orthogonal to each other,
which happens to often be the case in architectural models.


-schorsch

-- 
Georg Mischler  --  simulations developer  --  schorsch at schorsch com
+schorsch.com+  --  lighting design tools  --  http://www.schorsch.com/

From marcdevon at hotmail.com  Thu Jan  6 17:00:39 2005
From: marcdevon at hotmail.com (Marcus Jacobs)
Date: Thu Jan  6 17:02:22 2005
Subject: [Radiance-general] Sun Color
Message-ID: <BAY102-F16FA1A4FDF2EB6425A9881A4930@phx.gbl>

Dear Group

Does anyone here know how to alter or adjust gensky's sun color?  I guess 
what I am looking for is a color that is warmer that the color that I am 
achieving now. This is for asthetic purposes but I want a solution that is 
physically accurate. I have tried altering the day and time of day to 
achieve this but it seems that only the angle, height, and intensity of the 
sunlight is changed and not the color. I don't mind hard coding it in the 
application if it necessasary if it isn't too messy. Any suggestions?

Marcus



From gregoryjward at gmail.com  Thu Jan  6 17:22:15 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Thu Jan  6 17:22:53 2005
Subject: [Radiance-general] Re: scripting genprism | no explicit holes
	problem
In-Reply-To: <Pine.BSF.4.58.0501060948510.78081@emancholl.pair.com>
References: <20050106140608.6453A1C0024E@mwinf0603.wanadoo.fr>
	<Pine.BSF.4.58.0501060948510.78081@emancholl.pair.com>
Message-ID: <2086B090-5FFF-11D9-B581-000A95BB392A@gmail.com>

Maybe I'm being naive, but I've had good luck creating connecting seams 
between arbitrary vertices in holey polygons.  Make sure the outer 
vertices are in counter-clockwise order around the normal, and the 
interior (hole) vertices are clockwise.  Then, the algorithm goes 
something like this:

	First N vertices are N vertices of outer contour
		Next M1 vertices are M1 vertices of hole 1
		Close hole loop with vertex that is copy of the first hole vertex
		Close seam by adding copy of last outer contour vertex
		Repeat 3 steps above for each hole contour

In Radiance, polygon seams can cross all over each other and it doesn't 
create any artifacts.  This is how fonts are rendered, for example.  
This is also why I never bothered implementing holes in polygons; I 
never found where seams caused a problem, and I couldn't think of any 
way besides seams for implementing holes.

-Greg

> From: "Jelle Feringa // EZCT / Paris" <jelle.feringa@ezct.net>
> Date: January 6, 2005 6:07:03 AM PST
>
> Dear All,
>
> I'm working on a python script which I use to generate polygon 
> description
> to describe walls, in order to automate an architectural design 
> process.
> (building on the  http://www.dezentral.de/soft/Polygon/index.html 
> module)
>
> Using an excellent library, all my functions are in place... the data 
> is
> ready to be shipped to genprism... if it wasn't for No Explicit Holes
> Problem
>
> Here you see (simplified) version of a polygon I'd like genprism to 
> produce
> a wall from...
>
> [(4.059, 4.0599), (3.939, 4.059), (3.93, 3.93), (4.059, 3.99), (8.0, 
> 0.0),
> (0.0, 0.0), (0.0, 8.0), (8.0, 8.0)]
>
> Nothing special, except I need to find a way to produce the Invisible 
> Seams,
> since holes aren't supported explicitly.
>
> I'm almost sure some of you have been running into this problem as 
> well, and
> so far I haven't been able to find a suitable solution for my problem 
> so far
> (I'm learning programming... so please go easy on me ;-)
>
> If you're as fortunate as me and also have a copy of the excellent 
> Rendering
> with Radiance, this problem is described at page 52 / 145.
>
> #described, there's no suggestion of dealing with the problem...
>
> Your help is appreciated!
>
> Cheers,
> Jelle


From gregoryjward at gmail.com  Thu Jan  6 17:37:30 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Thu Jan  6 17:38:09 2005
Subject: [Radiance-general] Sun Color
In-Reply-To: <BAY102-F16FA1A4FDF2EB6425A9881A4930@phx.gbl>
References: <BAY102-F16FA1A4FDF2EB6425A9881A4930@phx.gbl>
Message-ID: <4230790E-6001-11D9-B581-000A95BB392A@gmail.com>

Hi Marcus,

This can be done with an appropriate insertion of rcalc in your 
Radiance command.  In the scene file, you would modify your gensky line 
to read:

!gensky 6 21 12 | rcalc -p -i sunlight.fmt \
	-e 'sr=1.035*si;sg=1.003*si;sb=0.826*si' \
	-o 'void light solar 0 0 3 ${sr} ${sg} ${sb}'

The color for the sun is converted from the CIE (x,y) chromaticity for 
standard illuminant B, which is (0.3485,0.3517).  The file 
"sunlight.fmt" must contain the following:

void light solar
0
0
3 ${si} ${si} ${si}

You'll need the latest version of rcalc (3.6.1 release), as previous 
versions did not have the -p option.

Hope this works for you.
-Greg

> From: "Marcus Jacobs" <marcdevon@hotmail.com>
> Date: January 6, 2005 8:00:39 AM PST
>
> Dear Group
>
> Does anyone here know how to alter or adjust gensky's sun color?  I 
> guess what I am looking for is a color that is warmer that the color 
> that I am achieving now. This is for asthetic purposes but I want a 
> solution that is physically accurate. I have tried altering the day 
> and time of day to achieve this but it seems that only the angle, 
> height, and intensity of the sunlight is changed and not the color. I 
> don't mind hard coding it in the application if it necessasary if it 
> isn't too messy. Any suggestions?
>
> Marcus


From despina_m81 at hotmail.com  Thu Jan  6 18:07:46 2005
From: despina_m81 at hotmail.com (Despina Michael)
Date: Thu Jan  6 18:08:33 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
Message-ID: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>

Hi all,

I am a student and I am new to hdri generation or processing so I need your help:)

I am trying to use hdrgen (for linux) for generating an hdr image from a series of photographs with different exposure each, of a static scene . 
I faced some problems and I have some questions for the whole process..

1) First of all, I would like to know which is the best way to take photographs with different exposure. 
If I understand correctly there are two ways. Either by changing F-number and let fixed the shutter speed or either by varying shutter speed and let the f-number fixed.
I would like to know witch of two ways is the best?

2) Are "Lens Aperture", "F-number" and "F-stop" same thing? 
Are "exposure time" and "shutter speed" same thing?
I know that these questions may seem to be "stupid" to most of you.. but as I said I am not familiar at all, with all these ...


The following questions are for hdrgen software..
I used it with different combinations of image... 
Some times the hdr image is generated but it's not clear at all and "scene" are not aligned... and some other times the hdr image is not generated at all..

3) Where is the fault 
when there is a warning:  Trouble finding HDR patches***** ?
when ther is a warning: Poor convergence for order 1 fit? (is 1 or any other number X appear there refers to a problem with the Xth image in command arguments?)

4) Where is the fault when there is an error:
"Cannot solve for response function" ?
Is that because it can not generate file for response function of camera, with specific series of photographs?

5) One problem of resulting hdr images (in cases that there was a generation of image)
was that they were somehow "green". What can cause that?

6) My photographs are not perfectly aligned. 
As I understood, the hdrgen uses an algorithm to align the photographs.
But as I noticed when the uses of alighnment algorithm is enable (NOT use of -a option) the "alignment" getting worst..
and when I disabled it (Using -a option) the result is better.. but still no good (I guess because that original photographs are not aligned)

Is there anything I can do for that???
Does the algorithm has "limits" on how much dis-aligned can the original images be?

I would appreciate it if you can answer some (or all;-)  ), of these questions.
Regards,
Despina
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://radiance-online.org/pipermail/radiance-general/attachments/20050106/68d50ee9/attachment.htm
From Giulio.Antonutto at arup.com  Thu Jan  6 18:34:08 2005
From: Giulio.Antonutto at arup.com (Giulio Antonutto)
Date: Thu Jan  6 18:34:32 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
Message-ID: <DC0CAEEA090E984C911D3B85B16C3F900302C338@l-gnts05>

Hi,
here something:
 
-1- you need to change time and NOT aperture, since depth of field changes
with aperture settings.
(depth of field could be simply explained as the parameter that indicates
how we are able to see more things in focus other than just the foreground)
furthermore close apertures eliminate some lens artefacts like coma (light
sources are elongated when close to the frame of the picture, expensive
lenses have not this problem though)...  
as a general suggestion for luminance measurement I would recommend to use
big F numbers.
 
-2- aperture=F stop=F number   <> time, exposure time,shutter speed
 
basically there is a curtain inside the camera that moves:
this is the shutter and takes care of let in the light
(speed is indicated in seconds and fraction of seconds, 1/60 is 1/60 of
second sometimes it is written as 60)
 
there is a diaphragm inside lenses,
this close  when the picture is being taken, leaving just an hole in the
middle, the hole dimension is the aperture.
the smaller the hole the bigger is aperture number (it's a fraction 1/1.4
1/2 1/2.8 .... 1/16 1/22 1/32 ... 1/64)
the smaller the hole the bigger depth of field
 
 
 
-3a- 'trouble about HDR patches' doesn't seem to be a problem, it is a
warning and results are always fine... sounds like 'warning no light source
found' and you are calculating a DF... ;-))
 
-3b- this happens when images have not enough data to create the camera
calibration curves... 
may be others can explain in depth....
 
-4- this could be because the images are too different or some exif data are
missing (sometimes this happens because the software that imports images
overwrite exif data)
 
-5- no idea
 
-6- I found the same thing, however a good tripod 'fixed' all my problems
;-))
 
Hope it helps,
cheers,
pillo
 
 


 
 -----Original Message-----
From: radiance-general-bounces@radiance-online.org
[mailto:radiance-general-bounces@radiance-online.org]On Behalf Of Despina
Michael
Sent: 06 January 2005 17:08
To: radiance-general@radiance-online.org
Subject: [Radiance-general] Problems using hdrgen for hdri generation


Hi all,
 
I am a student and I am new to hdri generation or processing so I need your
help:)
 
I am trying to use hdrgen (for linux) for generating an hdr image from a
series of photographs with different exposure each, of a static scene . 
I faced some problems and I have some questions for the whole process..
 
1) First of all, I would like to know which is the best way to take
photographs with different exposure. 
If I understand correctly there are two ways. Either by changing F-number
and let fixed the shutter speed or either by varying shutter speed and let
the f-number fixed.
I would like to know witch of two ways is the best?
 
2) Are "Lens Aperture", "F-number" and "F-stop" same thing? 
Are "exposure time" and "shutter speed" same thing?
I know that these questions may seem to be "stupid" to most of you.. but as
I said I am not familiar at all, with all these ..
 
 
The following questions are for hdrgen software..
I used it with different combinations of image... 
Some times the hdr image is generated but it's not clear at all and "scene"
are not aligned... and some other times the hdr image is not generated at
all..
 
3) Where is the fault 
when there is a warning:  Trouble finding HDR patches***** ?
when ther is a warning: Poor convergence for order 1 fit? (is 1 or any other
number X appear there refers to a problem with the Xth image in command
arguments?)
 
4) Where is the fault when there is an error:
"Cannot solve for response function" ?
Is that because it can not generate file for response function of camera,
with specific series of photographs?
 
5) One problem of resulting hdr images (in cases that there was a generation
of image)
was that they were somehow "green". What can cause that?
 
6) My photographs are not perfectly aligned. 
As I understood, the hdrgen uses an algorithm to align the photographs.
But as I noticed when the uses of alighnment algorithm is enable (NOT use of
-a option) the "alignment" getting worst..
and when I disabled it (Using -a option) the result is better.. but still no
good (I guess because that original photographs are not aligned)
 
Is there anything I can do for that???
Does the algorithm has "limits" on how much dis-aligned can the original
images be?
 
I would appreciate it if you can answer some (or all;-)  ), of these
questions.
Regards,
Despina
 


___________________________________________________________________
Electronic mail messages entering and leaving Arup business
systems are scanned for acceptability of content and viruses.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://radiance-online.org/pipermail/radiance-general/attachments/20050106/bb1c7429/attachment-0001.html
From kthibault at biomechanicsinc.com  Thu Jan  6 19:03:29 2005
From: kthibault at biomechanicsinc.com (Kirk Thibault)
Date: Thu Jan  6 19:04:10 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
In-Reply-To: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
Message-ID: <4549EE1D-600D-11D9-BE1E-000A956A0F62@biomechanicsinc.com>


On Jan 6, 2005, at 12:07 PM, Despina Michael wrote:

> Hi all,
> ?
> I am a student and I am new to hdri generation or processing so I need 
> your help:)
> ?
> I am trying to use hdrgen (for linux) for generating an hdr image from 
> a series of photographs with different exposure each, of a static 
> scene .
>  I faced some problems and I have some questions for the whole 
> process..
> ?
> 1) First of all, I would like to know which is the best way to take 
> photographs with different exposure.
>  If I understand correctly there are two ways. Either by changing 
> F-number and let fixed the shutter speed or either by varying shutter 
> speed and let the f-number fixed.
> I would like to know witch of two ways is the best?
> ?

Depends on the camera you use as to which method is easiest.  I use a 
Canon 300D digital SLR with Auto Exposure Bracketing (AEB).  I set a 
fixed aperture and shoot a sequence of three images, one at the base 
shutter speed, one at the shutter speed which produces +1 stop of 
exposure and one that produces an image with -1 stop exposure.  I 
repeat this process to get the range I'm looking for (say, 7 or 8 stops 
worth.)  I use overlapping exposures so that I can compare the lighting 
conditions in identical exposures to make sure that the light is not 
changing radically throughout the picture taking process.

I use a fixed aperture so that the Depth of Field does not change 
throughout the image sequence.  I shoot "mirror ball" images and choose 
an aperture and focal length that produce sharp focus of the ball and 
very blurred focus on the distant background so that the edges of the 
mirror ball are easy to see and define.

For example:

I would shoot a mirror ball on a stand using my camera fixed to a 
tripod.  I use the timer on my camera to expose the 3 image AEB 
sequence so that the image registration is as close as possible (i.e., 
i don't touch the shutter release, to minimize camera shake) and also 
so that i do not appear in the images.  I set the desired aperture, say 
f/8 and let the metered exposure tell me which shutter speed 
"correctly" exposes the FIRST base image - here let's say it is 1/60 
second,

I would then set the AEB for +/- 1 stop, the aperture to f/8 and shoot 
the following sequence:

1) FIRST base exposure =  @ 1/60, -1 = @1/125 (faster shutter, less 
light), +1 = @ 1/30 (slower shutter, more light)

then i would manually reset the shutter speed to 1/15 and shoot
2) NEXT base exposure = @ 1/15, -1 = @1/30, +1 = @ 1/8

then set the shutter speed manually to 1/250
3) NEXT base exposure = @ 1/250, -1 = @1/500, +1 =@1/125

etc. to cover the dynamic range you want to expose.  Each image is 1 
stop away from its neighbor.  In this example I have:

MOST EXPOSURE < 1/8, 1/15, 1/30, 1/60, 1/125, 1/250, 1/500 > LEAST 
EXPOSURE

seven exposures worth of images, which may be an acceptable dynamic 
range for certain lighting conditions.

Notice the "overlap" at 1/30 and 1/125 - I would compare the two images 
generated at identical exposures to make sure they are not drastically 
different - if they are, that means the lighting is changing and the 
exposures likely are not really 1 stop apart.


> 2) Are "Lens Aperture", "F-number" and "F-stop" same thing?
>  Are "exposure time" and "shutter speed" same thing?
> I know that these questions may seem to be "stupid" to most of you.. 
> but as I said I am not familiar at all, with all?these ..
> ?

Do a google on these terms or see one of the many sites about basic 
photographic principles.  These terms are not identical but in general 
describe the parameters one may vary to determine how much light hits 
the film or sensor (exposure).  A "stop" is essentially an increment of 
exposure, with successive stops being related by half or twice as much 
light as its lower or higher neighbor.

> ?
> The following questions are for hdrgen software..
> I used it with different combinations of image...
>  Some times the hdr image is generated but it's not clear at all and 
> "scene" are not aligned... and some other times the hdr image is not 
> generated at all..
> ?
> 3) Where is the fault
>  when there is a warning:? Trouble finding HDR patches***** ?
> when ther is a warning: Poor convergence for order 1 fit? (is 1 or any 
> other number X appear there refers to a problem with the Xth image in 
> command arguments?)
> ?
> 4) Where is the fault when there is an error:
> "Cannot solve for response function" ?
> Is that because it can not generate file for response function of 
> camera, with specific series of photographs?
> ?
> 5) One problem of resulting hdr images (in cases that there was a 
> generation of image)
> was that they were somehow "green". What can cause that?
> ?
> 6) My photographs are not perfectly aligned.
>  As I understood, the hdrgen uses an algorithm to align the 
> photographs.
> But as I noticed when the uses of alighnment algorithm is enable (NOT 
> use of -a option) the "alignment" getting worst..
> and when I disabled it (Using -a option) the result is better.. but 
> still no good (I guess because that original photographs are not 
> aligned)
> ?
> Is there anything I can do for that???
> Does the algorithm has "limits" on how much dis-aligned can the 
> original images be?
> ?
> I would appreciate it if you can answer some (or all;-)? ), of these 
> questions.
> Regards,
> Despina
> ?
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: text/enriched
Size: 7450 bytes
Desc: not available
Url : http://radiance-online.org/pipermail/radiance-general/attachments/20050106/f7b084bf/attachment.bin
From MMoeck at engr.psu.edu  Thu Jan  6 21:04:08 2005
From: MMoeck at engr.psu.edu (Martin Moeck)
Date: Thu Jan  6 21:04:45 2005
Subject: [Radiance-general] Sun Color
Message-ID: <84F05BA9118BBD4A8FC6409808CE266C234080@ENGRMAIL2.engr.psu.edu>

Here is tcl code to convert the sun color from a blackbody temperature "T" to Radiance RGB:

_______________________________________________

# input = 

proc Kelvin_to_sun_RGB {T YL solar_radiance} {


# converts a color temperature of degrees Kelvin into RGB
# given: color temp. T and the luminance YL of the source

# convert the blackbody temperature T into "RGB" 
# Both fits have R^2= 1.000 over the range from 2000K
# to 11000K. Both look ill behaved above 11000K

set x [expr 0.8405 - 2.1783*pow(10,-4) *$T  \
		   + 3.5254*pow(10,-8) *$T*$T \
		   - 2.7046*pow(10,-12)*$T*$T*$T \
		   + 7.9696*pow(10,-17)*$T*$T*$T*$T]

set y [expr 0.30587 + 1.3655*pow(10,-4) *$T \
		    - 5.6154*pow(10,-8) *$T*$T \
		    + 8.9484*pow(10,-12)*$T*$T*$T \
		    - 6.5352*pow(10,-16)*$T*$T*$T*$T \
		    + 1.8158*pow(10,-20)*$T*$T*$T*$T*$T]


set z [expr 1.00000000 -$x-$y]

set X [expr $x*$YL/$y]
set Z [expr $z*$YL/$y]
# X, YL, Z are the spectral tristimulus values

# the following formulae assume the monitor alignments given in the book :
# "procedural elements for computer graphics" by David F. Rogers, 1985 McGraw-Hill; pp. 397

set R [expr  2.739*$X - 1.145*$YL - 0.424*$Z]
set G [expr -1.119*$X + 2.029*$YL + 0.033*$Z]
set B [expr 0.138 *$X - 0.333*$YL + 1.105*$Z]
if {$B<0} {set B 0.0}

set k1 [expr (0.3*$R+0.59*$G+0.11*$B)]
# fact*k1=solar$radiance; correct RGB to actual values given in "void light solar" 
# from the gensky output
set fact [expr $solar_radiance/$k1]
set R [expr $R*$fact]; set G [expr $G*$fact]; set B [expr $B*$fact]
return "$R $G $B"

}

_______________________________________________________________________

Martin Moeck, Penn State





-----Original Message-----
From:	Marcus Jacobs [mailto:marcdevon@hotmail.com]
Sent:	Thu 1/6/2005 11:00 AM
To:	radiance-general@radiance-online.org
Cc:	
Subject:	[Radiance-general] Sun Color
Dear Group

Does anyone here know how to alter or adjust gensky's sun color?  I guess 
what I am looking for is a color that is warmer that the color that I am 
achieving now. This is for asthetic purposes but I want a solution that is 
physically accurate. I have tried altering the day and time of day to 
achieve this but it seems that only the angle, height, and intensity of the 
sunlight is changed and not the color. I don't mind hard coding it in the 
application if it necessasary if it isn't too messy. Any suggestions?

Marcus



_______________________________________________
Radiance-general mailing list
Radiance-general@radiance-online.org
http://www.radiance-online.org/mailman/listinfo/radiance-general



-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/ms-tnef
Size: 3789 bytes
Desc: not available
Url : http://radiance-online.org/pipermail/radiance-general/attachments/20050106/881de31d/attachment.bin
From despina_m81 at hotmail.com  Thu Jan  6 22:44:55 2005
From: despina_m81 at hotmail.com (Despina Michael)
Date: Thu Jan  6 22:46:09 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<4549EE1D-600D-11D9-BE1E-000A956A0F62@biomechanicsinc.com>
Message-ID: <BAY22-DAV6ECEB37B040666D37E77090930@phx.gbl>

Thank you for your answers. Both are really very useful!

. I am still a little bit confused about aperture...
Does big aperture number (big depth of field) mean that you "focus" (if i can use this term) on the whole scene?
and does small aperture (small debth of field) mean that you focus only on the foreground?

In my case I take photos of a mirrored ball in order to create a light probe.
What I really need to use for aperture? Small or big values as aperture number?

Thanks,
Despina
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://radiance-online.org/pipermail/radiance-general/attachments/20050106/fee18cae/attachment-0001.htm
From Rob.Fitzsimmons at Summit.Fiserv.com  Thu Jan  6 22:57:35 2005
From: Rob.Fitzsimmons at Summit.Fiserv.com (Fitzsimmons, Rob)
Date: Thu Jan  6 22:58:00 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
Message-ID: <B8DD8375FCE2C94B9F170D9277C1FA2B8C56EA@corvallis>

 

-----Original Message-----
From: Despina Michael
To: Radiance general discussion
Sent: 1/6/2005 1:44 PM
Subject: Re: [Radiance-general] Problems using hdrgen for hdri generation

Thank you for your answers. Both are really very useful!
 
.. I am still a little bit confused about aperture...
Does big aperture number (big depth of field) mean that you "focus" (if
i can use this term) on the whole scene?

the opposite - the bigger the number (f 16), the smaller the aperture, and
yet, 
the larger the depth of field

and does small aperture (small debth of field) mean that you focus only
on the foreground?
big aperture (f 2.8) = more light / less depth of field
small aperture (f 11) = less light / more depth of field

Look at this page - gives a decent demonstation of the relationships
http://www.photonhead.com/exposure/exposure.php

HTH
Rob
 
In my case I take photos of a mirrored ball in order to create a light
probe.
What I really need to use for aperture? Small or big values as aperture
number?
 
Thanks,
Despina
 <<ATT476996.txt>> 

From gregoryjward at gmail.com  Fri Jan  7 01:53:57 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Fri Jan  7 01:54:33 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
In-Reply-To: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
Message-ID: <9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>

Hi Despina,

Thanks to the helpful folks on the mailing list, most of your questions 
have already been answered, but I'll try to add a few points...

> From: "Despina Michael" <despina_m81@hotmail.com>
> Date: January 6, 2005 9:07:46 AM PST
>
> 1) First of all, I would like to know which is the best way to take 
> photographs with different exposure.
>  If I understand correctly there are two ways. Either by changing 
> F-number and let fixed the shutter speed or either by varying shutter 
> speed and let the f-number fixed.
> I would like to know witch of two ways is the best?

You should definitely vary the shutter speed (i.e., exposure time) 
rather than the aperture (i.e., f-number, f-stop).  You should read the 
attached tips, taken from the quickstart_pf.txt file distributed with 
Photosphere from <www.anyhere.com>.

> 3) Where is the fault
>  when there is a warning:? Trouble finding HDR patches***** ?
> when ther is a warning: Poor convergence for order 1 fit? (is 1 or any 
> other number X appear there refers to a problem with the Xth image in 
> command arguments?)

Warnings are mostly there as a kind of excuse for when things don't 
turn out.  If they turn out, then you shouldn't lose any sleep over 
them.

> ?4) Where is the fault when there is an error:
> "Cannot solve for response function" ?
> Is that because it can not generate file for response function of 
> camera, with specific series of photographs?

It's probably because the sequence didn't capture enough dynamic range, 
or there were no smooth gradients.  The best strategy is to use a good 
sequence to get the camera response, then store it and reuse it via 
hdrgen's -r option.  (See the related tips in the attachment.)

> ?5) One problem of resulting hdr images (in cases that there was a 
> generation of image)
> was that they were somehow "green". What can cause that?

I don't know.  I would have to see the source sequence, but there's 
probably not much I could do to fix it.

> ?6) My photographs are not perfectly aligned.
>  As I understood, the hdrgen uses an algorithm to align the 
> photographs.
> But as I noticed when the uses of alighnment algorithm is enable (NOT 
> use of -a option) the "alignment" getting worst..
> and when I disabled it (Using -a option) the result is better.. but 
> still no good (I guess because that original photographs are not 
> aligned)

The automatic alignment algorithm is not fool-proof, but I don't know 
of one that is.  It does not take care of rotation, and images that are 
very far out of alignment will not work, either.  (The maximum computed 
shift between adjacent exposures is +/-64 pixels in X and Y.)  The 
final solution is to use a tripod.  Using a tripod AND performing 
automatic alignment usually gives the best results.  I have good luck 
myself with auto-bracketed hand-held exposures, and practice does help. 
  I still get bad sequences, though -- usually in portrait mode, as I 
have a hard time not leaning during the exposures....

-Greg

Tips on HDR image creation taken from Photosphere quickstart blurb:

12) To create a high dynamic-range image, you need to start with
a set of "bracketed" exposures of a static scene.  It is best if
you take a series of 10 or so exposures of an interior scene looking
out a window and containing some large, smooth gradients both inside
and outside, to determine the camera's natural response function.
Be sure to fix the camera white balance so it doesn't change, and
use aperture-priority or manual exposure mode to ensure that only
the speed is changing from one exposure to the next.  For calibration,
you should place your camera on a tripod, and use a small aperature
(high f-number) to minimize vignetting.  Take your exposure series
starting from the longest shutter time and working to the shortest in
one-stop increments.  Make sure the longest exposure is not all white
and the darkest exposure is not all black.  Once you have created your
image series, load it into Photosphere directly -- DO NOT PROCESS THE
IMAGES WITH PHOTOSHOP or any other program.  Select the thumbnails,
then go to the "File -> Make HDR..." menu.  Check the box that says
"Save New Response", and click "OK".  The HDR building process
should take a few minutes, and Photosphere will record the computed
response function for your camera into its preferences file, which
will save time and the risk of error in subsequent HDR images.
You will also have the option of setting an absolute calibration
for the camera if you have a measured luminance value in the scene.
This option is provided by the "Apply" button submenu when the
measured area is selected in the image.  (Click and drag to select.)
Once an HDR image has been computed, it is stored as a temporary
file in 96-bit floating-point TIFF format.  This file is quite
large, but the data will only be saved in this format if you
select maximum quality and save as TIFF.  Otherwise, the 32-bit
LogLuv TIFF format will be preferred (or the 24-bit LogLuv format
if you set quality to minimum).  You also have the option of saving
to the more common Radiance file format (a.k.a.  HDR format), or
ILM's 48-bit OpenEXR format.  If you choose not to save the
image in high dynamic-range, the tone-mapped display image can be
written out as a 24-bit TIFF or JPEG image.


From rpg at rumblestrip.org  Fri Jan  7 02:53:15 2005
From: rpg at rumblestrip.org (Rob Guglielmetti)
Date: Fri Jan  7 02:53:23 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
In-Reply-To: <9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
Message-ID: <1126.68.36.127.169.1105062795.squirrel@68.36.127.169>


Greg Ward wrote:

> It's probably because the sequence didn't capture enough dynamic range,
> or there were no smooth gradients.  The best strategy is to use a good
> sequence to get the camera response, then store it and reuse it via
> hdrgen's -r option.  (See the related tips in the attachment.)

Hi Greg and everyone,

Greg, I've been meaning to ask you about this.  I have been shopping for a
new digital camera lately, and one of the criteria I have is the ability
to easily capture workable HDR images.  Now, at the Berkeley workshop you
demonstrated doing this wth your Olympus 3030, which has the ability to
take a 5-image autobracketed sequence, all separated by a stop.  This
gives you the ability to shoot a rough HDR sequence, handheld.  This is
what I was looking for, and I recall you saying that for these kind of
quickie HDR sequences one needed to make sure the midrange exposure was
separated by at least two stops from the endpoints.  I assumed this was to
ensure capturing the "entire range" of a "typical scene" (we have
discussed the limitations of this method in capturing the immense dynamic
range of a scene with direct sun, etc).

Of course when one looks at the current crop of digicams, the field
quickly gets thinned out when applying this criteria.  All too often a
nice camera (like the new Sony V3) is eliminated because its autobracket
function consists of a three shot maximum, separated by a single stop --
not enough.  At work, we have a Canon Rebel, which also only does three
shots for an autobracket sequence, but can separate them by two stops a
piece.

So, I'm wondering.  If I got a camera like the V3, which only goes one
stop to either side of the ideal exposure, but *first* use a tripod and
create an excelent HDR sequence as per your (excellent) quickstart guide,
and create and save a camera response curve for my V3 from that sequence,
would my crude handheld three-shot/1-stop HDR sequences be reasonably
accurate (assuming again, moderate dynamic range scenes)?

That was a long and winding sentence, but I hope you get the idea. (?)

P.S.
Just today I saw your camera for $225 on a closeout special at a store in
Manhattan that's not even known for low camera prices.  Ahh, technology.

P.P.S.
I was in the aforementioned store looking to purchase a power supply for
my work computer because the cooling fan in its power supply rolled over
and died 30 minutes into my workday this morning, a morning when I was
just finally getting caught up.  Ahh, technology.  =8-)

- Rob Guglielmetti
www.rumblestrip.org

From gregoryjward at gmail.com  Fri Jan  7 04:58:37 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Fri Jan  7 04:59:16 2005
Subject: [Radiance-general] Re: Problems using hdrgen for hdri generation
In-Reply-To: <1126.68.36.127.169.1105062795.squirrel@68.36.127.169>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<1126.68.36.127.169.1105062795.squirrel@68.36.127.169>
Message-ID: <68C6BE20-6060-11D9-93E8-000A95BB392A@gmail.com>

Hi Rob,

Short answer to your long question:  3 exposures separated by 1 f-stop 
each is not enough for an HDR image, in my opinion.

I find that 2 stops on either side is often less than I need for 
outdoor shots that include bright clouds.  Also, I wish the shortest 
exposure on my Olympus 4040 was faster than 1/800th sec., as that still 
leaves bright areas saturated.  (I used to have an Olympus 3030 and it 
was the same.)  The manufacturers do seem to be headed the wrong 
direction when it comes to HDR these days.  I've also noticed that they 
like to add all kinds of auto exposure curves and crap like that which 
totally screws me up.  To be honest, you're better off getting a C-3040 
from some discount place than a newer, fancier cameras.  That goes for 
SLRs as well.  I honestly don't think they're worth the extra bucks, 
unless you happen to have a slew of lenses you have to justify owning.

-Greg


From jelle.feringa at ezct.net  Fri Jan  7 12:25:17 2005
From: jelle.feringa at ezct.net (Jelle Feringa // EZCT / Paris)
Date: Fri Jan  7 12:25:25 2005
Subject: [Radiance-general] genprism | no explicit hole
Message-ID: <20050107112506.1D1941C0038F@mwinf0603.wanadoo.fr>

Dear George, Greg,

Thank you both for your feedback, most helpful!


> One alternative approach would be to cut the outer polygon apart
> instead of keeping it intact. Just sort the corner points of all
> the holes eg. vertically, and make a horizontal cut at each
> height. You need to be careful to combine equal hights (allow for
> some numeric rounding error), and not to cut through tall holes
> sitting next to short ones. This method should work particularly
> well if the wall and hole polygons are orthogonal to each other,
> which happens to often be the case in architectural models.

George,

The solution proposed by the author of the python Polygon package does
exactly this; the complex polygon is split into a list of simple polygons,
using the center of gravity of the polygon. After the split it isn't
difficult to write it out to a .rad format!

> Maybe I'm being naive, but I've had good luck creating connecting seams
> between arbitrary vertices in holey polygons.  Make sure the outer
> vertices are in counter-clockwise order around the normal, and the
> interior (hole) vertices are clockwise.  Then, the algorithm goes
> something like this:
> 
> 	First N vertices are N vertices of outer contour
> 		Next M1 vertices are M1 vertices of hole 1
> 		Close hole loop with vertex that is copy of the first hole
> vertex
> 		Close seam by adding copy of last outer contour vertex
> 		Repeat 3 steps above for each hole contour
> 
> In Radiance, polygon seams can cross all over each other and it doesn't
> create any artifacts.  This is how fonts are rendered, for example.
> This is also why I never bothered implementing holes in polygons; I
> never found where seams caused a problem, and I couldn't think of any
> way besides seams for implementing holes.
> 
> -Greg

Greg,

Thanks for the sketched out algorithm, I was hoping for that kind of
response! By no means was my mail intended as criticism for the lack of
explicit holes, just hoping for a way to get passed the problem!
I'm sure your suggested algorithm will be helpful in further development of
my project.

Cheers,

Jelle.





From despina_m81 at hotmail.com  Fri Jan  7 13:48:11 2005
From: despina_m81 at hotmail.com (Despina Michael)
Date: Fri Jan  7 13:49:57 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
References: <B8DD8375FCE2C94B9F170D9277C1FA2B8C56EA@corvallis>
Message-ID: <BAY22-DAV255CFBB5CEC220C18EAEF90940@phx.gbl>

Greg, Rob thanks for your answers!

> Look at this page - gives a decent demonstation of the relationships
> http://www.photonhead.com/exposure/exposure.php
>
The link is exactly what I need!!

>> 5) One problem of resulting hdr images (in cases that there was a
>> generation of image)
>> was that they were somehow "green". What can cause that?

>
>I don't know.  I would have to see the source sequence, but there's
>probably not much I could do to fix it.

There is no point in to attach my current photos. From the information I 
learned from your replies, I understood that my photos are very bad...

I'll take new ones, taking in account all you said. Hopefully results will 
be better. If I found out what's the problem with "green" in generated hdri 
I will let  you know!
Thanks again,
Despina


From marcdevon at hotmail.com  Sat Jan  8 02:10:00 2005
From: marcdevon at hotmail.com (Marcus Jacobs)
Date: Sat Jan  8 02:11:58 2005
Subject: [Radiance-general] RE: Sun Color
In-Reply-To: <MC9-F412TUSzbAUfKRf00000260@mc9-f41.hotmail.com>
Message-ID: <BAY102-F27C9BC2F25793527E13CD9A4950@phx.gbl>

Thanks Martin and Greg for the help for my question about the sun color.


I have done some light research on of the sun's color temperature. I think 
Martin's may be the method that I would prefer in converting a color 
temperature and luminance of the sun to the RGB used with the light 
primative. I have had some problems running the script. In a comment line it 
states:


converts a color temperature of degrees Kelvin into RGB given: color temp. T 
and the luminance YL of the source


My problem is that this script takes three variables (T, YL, and 
solar_radiance) but the comment only mentions two variables (T and YL). What 
is the solar_radiance and how does it differ from the luminance of the 
source (the source I am assuming is the sun)? Also, what are the units of 
measurement for the 3 variables? Do you have an example for this?

Thanks

Marcus Jacobs



From MMoeck at engr.psu.edu  Sat Jan  8 14:46:01 2005
From: MMoeck at engr.psu.edu (Martin Moeck)
Date: Sat Jan  8 14:46:46 2005
Subject: [Radiance-general] RE: Sun Color
Message-ID: <84F05BA9118BBD4A8FC6409808CE266C234092@ENGRMAIL2.engr.psu.edu>

I modified the script.Use it as follows:
 
# generate a radiance sun:  gensky 3 21 8
...
void light solar
0
0
3 5.18e+006 5.18e+006 5.18e+006
...
YL=179*(5.18e+006 *.265+5.18e+006 *.67+5.18e+006*.0648)= 927034556
 
 
proc Kelvin_to_sun_RGB {T YL} {

# converts a color temperature of degrees Kelvin into RGB
# given: color temp. T and the luminance YL of the source
# convert the blackbody temperature T into "RGB"
# Both fits have R^2= 1.000 over the range from 2000K
# to 11000K. Both look ill behaved above 11000K
set x [expr 0.8405 - 2.17834e-04 *$T  \
                   + 3.52544e-08 *$T*$T \
                   - 2.7046e-12*$T*$T*$T \
                   + 7.9696e-17*$T*$T*$T*$T]
set y [expr 0.30587 + 1.3655e-4 *$T \
                    - 5.6154e-8 *$T*$T \
                    + 8.9484e-12*$T*$T*$T \
                    - 6.5352e-16*$T*$T*$T*$T \
                    + 1.8158e-20*$T*$T*$T*$T*$T]

set z [expr 1.0-$x-$y]
set X [expr $x*$YL/$y]
set Z [expr $z*$YL/$y]
# X, YL, Z are the spectral tristimulus values
# the following formulae assume the monitor alignments given in the book :
# "procedural elements for computer graphics" by David F. Rogers, 1985 McGraw-Hill; pp. 397
set R [expr  2.739*$X - 1.145*$YL - 0.424*$Z]
set G [expr -1.119*$X + 2.029*$YL + 0.033*$Z]
set B [expr 0.138 *$X - 0.333*$YL + 1.105*$Z]
if {$B<0} {set B 0.0}
return "$R $G $B"
}
__________________________________
Kelvin_to_sun_RGB 2100.0 $YL
...
# a sun with a color temperature of 2100 K and a luminance of YL
void light solar
0 0 3
2017646607     601412803   19892974
...

The script does not work for very low sun angles, as the sun changes to pink orange, which cannot be represented by a blackbody. Use some filter colors from Lee or Rosco for that. 
 
Martin Moeck
 
 

	-----Original Message----- 
	From: Marcus Jacobs [mailto:marcdevon@hotmail.com] 
	Sent: Fri 1/7/2005 8:10 PM 
	To: radiance-general@radiance-online.org 
	Cc: 
	Subject: [Radiance-general] RE: Sun Color
	
	

	Thanks Martin and Greg for the help for my question about the sun color.
	
	
	I have done some light research on of the sun's color temperature. I think
	Martin's may be the method that I would prefer in converting a color
	temperature and luminance of the sun to the RGB used with the light
	primative. I have had some problems running the script. In a comment line it
	states:
	
	
	converts a color temperature of degrees Kelvin into RGB given: color temp. T
	and the luminance YL of the source
	
	
	My problem is that this script takes three variables (T, YL, and
	solar_radiance) but the comment only mentions two variables (T and YL). What
	is the solar_radiance and how does it differ from the luminance of the
	source (the source I am assuming is the sun)? Also, what are the units of
	measurement for the 3 variables? Do you have an example for this?
	
	Thanks
	
	Marcus Jacobs
	
	
	
	_______________________________________________
	Radiance-general mailing list
	Radiance-general@radiance-online.org
	http://www.radiance-online.org/mailman/listinfo/radiance-general
	

-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/ms-tnef
Size: 7506 bytes
Desc: not available
Url : http://radiance-online.org/pipermail/radiance-general/attachments/20050108/44e7f9e2/attachment.bin
From despina_m81 at hotmail.com  Tue Jan 11 00:09:37 2005
From: despina_m81 at hotmail.com (Despina Michael)
Date: Tue Jan 11 00:10:59 2005
Subject: [Radiance-general] Problems using hdrgen for hdri generation
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
Message-ID: <BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>

Hi all,

I am trying to calibrate camera response function.
(unfortunately withh no good results - i belief still problems with 
alignment although I used a tripod)

I would like to ask you if  the scene in the photo
www2.cs.ucy.ac.cy/~cs99dm1/calib.zip
is appropriate for that purpose.

According to Photosphere quickstart... is an inside scene looking out a 
window.
Of course I took a series of photos of this scene with different exposures.

Thanks,
Despina

----- Original Message ----- 
From: "Greg Ward" <gregoryjward@gmail.com>
To: "Radiance general discussion" <radiance-general@radiance-online.org>
Sent: Friday, January 07, 2005 2:53 AM
Subject: Re: [Radiance-general] Problems using hdrgen for hdri generation


Hi Despina,

Thanks to the helpful folks on the mailing list, most of your questions
have already been answered, but I'll try to add a few points...

> From: "Despina Michael" <despina_m81@hotmail.com>
> Date: January 6, 2005 9:07:46 AM PST
>
> 1) First of all, I would like to know which is the best way to take 
> photographs with different exposure.
>  If I understand correctly there are two ways. Either by changing F-number 
> and let fixed the shutter speed or either by varying shutter speed and let 
> the f-number fixed.
> I would like to know witch of two ways is the best?

You should definitely vary the shutter speed (i.e., exposure time)
rather than the aperture (i.e., f-number, f-stop).  You should read the
attached tips, taken from the quickstart_pf.txt file distributed with
Photosphere from <www.anyhere.com>.

> 3) Where is the fault
>  when there is a warning: Trouble finding HDR patches***** ?
> when ther is a warning: Poor convergence for order 1 fit? (is 1 or any 
> other number X appear there refers to a problem with the Xth image in 
> command arguments?)

Warnings are mostly there as a kind of excuse for when things don't
turn out.  If they turn out, then you shouldn't lose any sleep over
them.

> 4) Where is the fault when there is an error:
> "Cannot solve for response function" ?
> Is that because it can not generate file for response function of camera, 
> with specific series of photographs?

It's probably because the sequence didn't capture enough dynamic range,
or there were no smooth gradients.  The best strategy is to use a good
sequence to get the camera response, then store it and reuse it via
hdrgen's -r option.  (See the related tips in the attachment.)

> 5) One problem of resulting hdr images (in cases that there was a 
> generation of image)
> was that they were somehow "green". What can cause that?

I don't know.  I would have to see the source sequence, but there's
probably not much I could do to fix it.

> 6) My photographs are not perfectly aligned.
>  As I understood, the hdrgen uses an algorithm to align the photographs.
> But as I noticed when the uses of alighnment algorithm is enable (NOT use 
> of -a option) the "alignment" getting worst..
> and when I disabled it (Using -a option) the result is better.. but still 
> no good (I guess because that original photographs are not aligned)

The automatic alignment algorithm is not fool-proof, but I don't know
of one that is.  It does not take care of rotation, and images that are
very far out of alignment will not work, either.  (The maximum computed
shift between adjacent exposures is +/-64 pixels in X and Y.)  The
final solution is to use a tripod.  Using a tripod AND performing
automatic alignment usually gives the best results.  I have good luck
myself with auto-bracketed hand-held exposures, and practice does help.
  I still get bad sequences, though -- usually in portrait mode, as I
have a hard time not leaning during the exposures....

-Greg

Tips on HDR image creation taken from Photosphere quickstart blurb:

12) To create a high dynamic-range image, you need to start with
a set of "bracketed" exposures of a static scene.  It is best if
you take a series of 10 or so exposures of an interior scene looking
out a window and containing some large, smooth gradients both inside
and outside, to determine the camera's natural response function.
Be sure to fix the camera white balance so it doesn't change, and
use aperture-priority or manual exposure mode to ensure that only
the speed is changing from one exposure to the next.  For calibration,
you should place your camera on a tripod, and use a small aperature
(high f-number) to minimize vignetting.  Take your exposure series
starting from the longest shutter time and working to the shortest in
one-stop increments.  Make sure the longest exposure is not all white
and the darkest exposure is not all black.  Once you have created your
image series, load it into Photosphere directly -- DO NOT PROCESS THE
IMAGES WITH PHOTOSHOP or any other program.  Select the thumbnails,
then go to the "File -> Make HDR..." menu.  Check the box that says
"Save New Response", and click "OK".  The HDR building process
should take a few minutes, and Photosphere will record the computed
response function for your camera into its preferences file, which
will save time and the risk of error in subsequent HDR images.
You will also have the option of setting an absolute calibration
for the camera if you have a measured luminance value in the scene.
This option is provided by the "Apply" button submenu when the
measured area is selected in the image.  (Click and drag to select.)
Once an HDR image has been computed, it is stored as a temporary
file in 96-bit floating-point TIFF format.  This file is quite
large, but the data will only be saved in this format if you
select maximum quality and save as TIFF.  Otherwise, the 32-bit
LogLuv TIFF format will be preferred (or the 24-bit LogLuv format
if you set quality to minimum).  You also have the option of saving
to the more common Radiance file format (a.k.a.  HDR format), or
ILM's 48-bit OpenEXR format.  If you choose not to save the
image in high dynamic-range, the tone-mapped display image can be
written out as a 24-bit TIFF or JPEG image.


_______________________________________________
Radiance-general mailing list
Radiance-general@radiance-online.org
http://www.radiance-online.org/mailman/listinfo/radiance-general

From jlai at lbl.gov  Tue Jan 11 09:25:23 2005
From: jlai at lbl.gov (judy lai)
Date: Tue Jan 11 09:21:13 2005
Subject: [Radiance-general] xglaresrc
Message-ID: <41E38D73.2020604@lbl.gov>

hallo List,
Please go easy on me, I'm a newbie.  :-/

Is there a way to save the xglaresrc output images (the pics with the 
red circles) without doing some sort of screen capture?
I tried  'xglaresrc image.pic image.glr | tee image.out', which I was so 
hoping would work but of course didn't.

Thanks,

judy

From tarik.rahman at ed.ac.uk  Tue Jan 11 16:05:40 2005
From: tarik.rahman at ed.ac.uk (Tarik Rahman)
Date: Tue Jan 11 16:06:05 2005
Subject: [Radiance-general] implementing Radiance reflection model
In-Reply-To: <BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
Message-ID: <1105455940.41e3eb4464405@sms.ed.ac.uk>

Hi there
I'm still trying to get the correct values for the Radiance reflection model,
they're close but not quite right. So for isotropic reflectance I get K as below


			             [ exp(-tan^2(delta/alpha^2)]
			  K =     -----------------------------------
			         cos(theta_i)*cos(theta_r) *4pi*alpha^2


and use the formula to get the returned colour as
Li = Ii*projected_solid_angle(rho_diffuse/pi + rho_specular*K) where

				cos(theta_i)*PI*r^2
projected_solid_angle =		-------------------								         dist_to_light^2

and r is the radius of my spherical light source.
when I do rview -vf view.vp -av .5 .5 .5 file.oct do I just add this -av value
for ambient light as below?
Li = light.colour*projected_solid_angle*(rho_diffuse/pi +rho_specular*K)
+ ambient;

Thanks for any help

Tarik
--
Tarik Rahman
PhD student, Institue of Perception, Action and Behaviour
School of Informatics
University of Edinburgh

From gregoryjward at gmail.com  Tue Jan 11 17:40:12 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Tue Jan 11 17:41:01 2005
Subject: [Radiance-general] xglaresrc
In-Reply-To: <41E38D73.2020604@lbl.gov>
References: <41E38D73.2020604@lbl.gov>
Message-ID: <76E6FBF1-63EF-11D9-9372-000A95BB392A@gmail.com>

Hi Judy,

In what way do you qualify as a "newbie??"

Unfortunately, there is no output facility from ximage.  The only way 
to get the image is with a window capture.  Fortunately, X11 has a 
utility for this, called xwd.  If your image file were named "35b3", 
you could call the following command once it was up:

	% xwd -name 35b3 -out 35b3.xwd

The xwd program looks up the window by name, then dumps its contents to 
the file 35b3.xwd.  Unfortunately, none of the mainstream programs will 
recognize the little-used "X-window dump" format, so you'll have to 
load it into GraphicConverter or somesuch and save it out in a more 
conventional format.

-Greg
(Definite oldbie)

> From: judy lai <jlai@lbl.gov>
> Date: January 11, 2005 12:25:23 AM PST
>
> hallo List,
> Please go easy on me, I'm a newbie.  :-/
>
> Is there a way to save the xglaresrc output images (the pics with the 
> red circles) without doing some sort of screen capture?
> I tried  'xglaresrc image.pic image.glr | tee image.out', which I was 
> so hoping would work but of course didn't.
>
> Thanks,
>
> judy


From Giulio.Antonutto at arup.com  Tue Jan 11 18:01:35 2005
From: Giulio.Antonutto at arup.com (Giulio Antonutto)
Date: Tue Jan 11 18:02:01 2005
Subject: [Radiance-general] xglaresrc
Message-ID: <DC0CAEEA090E984C911D3B85B16C3F900302C35E@l-gnts05>

you may try THE GIMP, there is a quick screen capture utility,
just click on the X11 window and the image is captured to Gimp.
Hope it works!
Regards
giulio


-----Original Message-----
From: radiance-general-bounces@radiance-online.org
[mailto:radiance-general-bounces@radiance-online.org]On Behalf Of Greg
Ward
Sent: 11 January 2005 16:40
To: Radiance general discussion
Subject: Re: [Radiance-general] xglaresrc


Hi Judy,

In what way do you qualify as a "newbie??"

Unfortunately, there is no output facility from ximage.  The only way 
to get the image is with a window capture.  Fortunately, X11 has a 
utility for this, called xwd.  If your image file were named "35b3", 
you could call the following command once it was up:

	% xwd -name 35b3 -out 35b3.xwd

The xwd program looks up the window by name, then dumps its contents to 
the file 35b3.xwd.  Unfortunately, none of the mainstream programs will 
recognize the little-used "X-window dump" format, so you'll have to 
load it into GraphicConverter or somesuch and save it out in a more 
conventional format.

-Greg
(Definite oldbie)

> From: judy lai <jlai@lbl.gov>
> Date: January 11, 2005 12:25:23 AM PST
>
> hallo List,
> Please go easy on me, I'm a newbie.  :-/
>
> Is there a way to save the xglaresrc output images (the pics with the 
> red circles) without doing some sort of screen capture?
> I tried  'xglaresrc image.pic image.glr | tee image.out', which I was 
> so hoping would work but of course didn't.
>
> Thanks,
>
> judy


_______________________________________________
Radiance-general mailing list
Radiance-general@radiance-online.org
http://www.radiance-online.org/mailman/listinfo/radiance-general

___________________________________________________________________
Electronic mail messages entering and leaving Arup business
systems are scanned for acceptability of content and viruses.

From tarik.rahman at ed.ac.uk  Tue Jan 11 18:43:06 2005
From: tarik.rahman at ed.ac.uk (Tarik Rahman)
Date: Tue Jan 11 18:43:25 2005
Subject: [Radiance-general] Problems with polygonal light source
In-Reply-To: <1105455940.41e3eb4464405@sms.ed.ac.uk>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
	<1105455940.41e3eb4464405@sms.ed.ac.uk>
Message-ID: <1105465386.41e4102aeb56b@sms.ed.ac.uk>

I'm trying to create a rectangular light positioned on the ceiling of a room so
I use
void light bright
0
0
3  100  100  100

bright polygon rectangular_light
0
0
12      2.25	0.05	2
	2.25	0.05	3
	2.75	0.05	3
	2.75	0.05	2

but I have to position the light just below the ceiling (at height 0) so that
it's not obstructed by it and also the light only radiates from the bottom of
it's polygonal shape leaving the ceiling completely black. Can anyone advise me
what to do?

Thanks

Tarik

--
Tarik Rahman
PhD student, Institue of Perception, Action and Behaviour
School of Informatics
University of Edinburgh

From gregoryjward at gmail.com  Tue Jan 11 20:20:15 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Tue Jan 11 20:20:59 2005
Subject: [Radiance-general] Re: implementing Radiance reflection model
In-Reply-To: <1105455940.41e3eb4464405@sms.ed.ac.uk>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
	<1105455940.41e3eb4464405@sms.ed.ac.uk>
Message-ID: <D29B9CB8-6405-11D9-A2A3-000A95BB392A@gmail.com>

Hi Tarik,

The formula for K should be:

			             exp(-tan^2(delta)/alpha^2)
			  K =     -----------------------------------
			         cos(theta_i)*cos(theta_r) *4pi*alpha^2

How are you computing delta?  It is the angle between the half-vector 
and the normal.

Also, for large disk sources, the exact calculation for solid angle is:

	2pi*(1 - cos(theta_s/2))

Where theta_s is the subtended angle of the light source.  This is a 
insignificant correction to what you have for distant sources.

-Greg

> From: Tarik Rahman <tarik.rahman@ed.ac.uk>
> Date: January 11, 2005 7:05:40 AM PST
>
> Hi there
> I'm still trying to get the correct values for the Radiance reflection 
> model,
> they're close but not quite right. So for isotropic reflectance I get 
> K as below
>
>
> 			             [ exp(-tan^2(delta/alpha^2)]
> 			  K =     -----------------------------------
> 			         cos(theta_i)*cos(theta_r) *4pi*alpha^2
>
>
> and use the formula to get the returned colour as
> Li = Ii*projected_solid_angle(rho_diffuse/pi + rho_specular*K) where
>
> 				cos(theta_i)*PI*r^2
> projected_solid_angle =		-------------------								         
> dist_to_light^2
>
> and r is the radius of my spherical light source.
> when I do rview -vf view.vp -av .5 .5 .5 file.oct do I just add this 
> -av value
> for ambient light as below?
> Li = light.colour*projected_solid_angle*(rho_diffuse/pi 
> +rho_specular*K)
> + ambient;
>
> Thanks for any help
>
> Tarik
> --
> Tarik Rahman
> PhD student, Institue of Perception, Action and Behaviour
> School of Informatics
> University of Edinburgh


From gregoryjward at gmail.com  Tue Jan 11 20:21:44 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Tue Jan 11 20:22:26 2005
Subject: [Radiance-general] Problems with polygonal light source
In-Reply-To: <1105465386.41e4102aeb56b@sms.ed.ac.uk>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
	<1105455940.41e3eb4464405@sms.ed.ac.uk>
	<1105465386.41e4102aeb56b@sms.ed.ac.uk>
Message-ID: <0765B86D-6406-11D9-A2A3-000A95BB392A@gmail.com>

Hi Tarik,

For a downward-directed light source, the ceiling is illuminated by 
interreflected light, which is approximated (to zeroeth order) with the 
-av setting in Radiance.  Better approximations may be obtained by 
setting -ab to 1 or greater.

-Greg

> From: Tarik Rahman <tarik.rahman@ed.ac.uk>
> Date: January 11, 2005 9:43:06 AM PST
>
> I'm trying to create a rectangular light positioned on the ceiling of 
> a room so
> I use
> void light bright
> 0
> 0
> 3  100  100  100
>
> bright polygon rectangular_light
> 0
> 0
> 12      2.25	0.05	2
> 	2.25	0.05	3
> 	2.75	0.05	3
> 	2.75	0.05	2
>
> but I have to position the light just below the ceiling (at height 0) 
> so that
> it's not obstructed by it and also the light only radiates from the 
> bottom of
> it's polygonal shape leaving the ceiling completely black. Can anyone 
> advise me
> what to do?
>
> Thanks
>
> Tarik


From apian at pab-opto.de  Tue Jan 11 23:51:05 2005
From: apian at pab-opto.de (Peter Apian-Bennewitz)
Date: Tue Jan 11 23:51:44 2005
Subject: [Radiance-general] xglaresrc
In-Reply-To: <76E6FBF1-63EF-11D9-9372-000A95BB392A@gmail.com>
References: <41E38D73.2020604@lbl.gov>
	<76E6FBF1-63EF-11D9-9372-000A95BB392A@gmail.com>
Message-ID: <41E45859.6070306@pab-opto.de>

Greg Ward wrote:

> Hi Judy,
>
> In what way do you qualify as a "newbie??"
>
> Unfortunately, there is no output facility from ximage.  The only way 
> to get the image is with a window capture.  Fortunately, X11 has a 
> utility for this, called xwd.  If your image file were named "35b3", 
> you could call the following command once it was up:
>
>     % xwd -name 35b3 -out 35b3.xwd
>
> The xwd program looks up the window by name, then dumps its contents 
> to the file 35b3.xwd.  Unfortunately, none of the mainstream programs 
> will recognize the little-used "X-window dump" format, so you'll have 
> to load it into GraphicConverter or somesuch and save it out in a more 
> conventional format.
>
> -Greg
> (Definite oldbie)
>
xwd -name 35b3 | xwdtopnm | ra_ppm -r > 35b3.pic

-Peter
(middlebie)

-- 
 pab-opto, Freiburg, Germany, http://www.pab-opto.de
 [see web page to check digital email signature]



From jlai at lbl.gov  Wed Jan 12 14:22:33 2005
From: jlai at lbl.gov (judy lai)
Date: Wed Jan 12 14:07:59 2005
Subject: [Radiance-general] re: xglaresrc
Message-ID: <41E52499.2070000@lbl.gov>

Thanks folks.
I'll try xwdtopnm.  More glare questions are coming, as soon as I figure 
out what I need to ask....


judy


From tarik.rahman at ed.ac.uk  Wed Jan 12 17:34:14 2005
From: tarik.rahman at ed.ac.uk (Tarik Rahman)
Date: Wed Jan 12 17:34:38 2005
Subject: [Radiance-general] Re: implementing Radiance reflection model
In-Reply-To: <D29B9CB8-6405-11D9-A2A3-000A95BB392A@gmail.com>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
	<1105455940.41e3eb4464405@sms.ed.ac.uk>
	<D29B9CB8-6405-11D9-A2A3-000A95BB392A@gmail.com>
Message-ID: <1105547654.41e551867226d@sms.ed.ac.uk>

Thanks for that, made the correction for tan^2(delta) and delta is as you say
delta = normal.dotProduct(halfwayVectorUnit);
where
halfwayVector = point_to_lightUnit  - point_to_camUnit;
halfwayVectorUnit = halfwayVector.normalize();


So for the ambient light of .5 .5 .5 I just add it at the end? I don't need to
multiply by the diffuse component rho_diffuse?

Tarik


Quoting Greg Ward <gregoryjward@gmail.com>:

> Hi Tarik,
>
> The formula for K should be:
>
> 			             exp(-tan^2(delta)/alpha^2)
> 			  K =     -----------------------------------
> 			         cos(theta_i)*cos(theta_r) *4pi*alpha^2
>
> How are you computing delta?  It is the angle between the half-vector
> and the normal.
>
> Also, for large disk sources, the exact calculation for solid angle is:
>
> 	2pi*(1 - cos(theta_s/2))
>
> Where theta_s is the subtended angle of the light source.  This is a
> insignificant correction to what you have for distant sources.
>
> -Greg
>
> > From: Tarik Rahman <tarik.rahman@ed.ac.uk>
> > Date: January 11, 2005 7:05:40 AM PST
> >
> > Hi there
> > I'm still trying to get the correct values for the Radiance reflection
> > model,
> > they're close but not quite right. So for isotropic reflectance I get
> > K as below
> >
> >
> > 			             [ exp(-tan^2(delta/alpha^2)]
> > 			  K =     -----------------------------------
> > 			         cos(theta_i)*cos(theta_r) *4pi*alpha^2
> >
> >
> > and use the formula to get the returned colour as
> > Li = Ii*projected_solid_angle(rho_diffuse/pi + rho_specular*K) where
> >
> > 				cos(theta_i)*PI*r^2
> > projected_solid_angle =		-------------------
> > dist_to_light^2
> >
> > and r is the radius of my spherical light source.
> > when I do rview -vf view.vp -av .5 .5 .5 file.oct do I just add this
> > -av value
> > for ambient light as below?
> > Li = light.colour*projected_solid_angle*(rho_diffuse/pi
> > +rho_specular*K)
> > + ambient;
> >
> > Thanks for any help
> >
> > Tarik
> > --
> > Tarik Rahman
> > PhD student, Institue of Perception, Action and Behaviour
> > School of Informatics
> > University of Edinburgh
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>


--
Tarik Rahman
PhD student, Institue of Perception, Action and Behaviour
School of Informatics
University of Edinburgh

From johannes at itara.org  Thu Jan 13 22:51:21 2005
From: johannes at itara.org (J. Sienknecht)
Date: Thu Jan 13 22:51:41 2005
Subject: [Radiance-general] [Radiance and Brad] MacosX and X11 and brad an
	blender
In-Reply-To: <41E45859.6070306@pab-opto.de>
Message-ID: <BE0CABE9.52B3%johannes@itara.org>

Hello everyone! I'm really new to radiance and first I have to say:

Thank You Very Much For Developing And Supporting This Free Software!!

Radiance is running fine on my system (far as i can see) with macos 10.3.7,
blender 2.3.6, python 2.3.

My question is more about blender and brad because

everything seems to work in general, but if i try the sky preview
i get the following in the console window:

" ximage 
/Applications/Blender/blender.app/Contents/MacOS/.blender/scripts/brad/tmp/
mph.pic: cannot open display"

I've edited my bash_profile like it was explained from pillo:

--------
if someone is interested in using x11 as graphical output for the built
in panther terminal this is what is required:

1) launch x11, launch terminal (keep X11  always open when the terminal
is open, otherwise it doesn't work!)

2) edit your .bash_profile as follows, just add these lines:

if [ -z "${DISPLAY}" ];then echo -n
export DISPLAY=':0'
fi 
---------

but sadley it has not the desired (display-) effect to applications
controlled via brad/blender, too.

would it be possible to open x-window-radiance-applications like ximage out
of blender/python in a way that they use x-darwin and its display?

thank you very much and all the best

johannes



From gregoryjward at gmail.com  Fri Jan 14 06:16:10 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Fri Jan 14 06:16:58 2005
Subject: [Radiance-general] Re: implementing Radiance reflection model
In-Reply-To: <1105547654.41e551867226d@sms.ed.ac.uk>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
	<1105455940.41e3eb4464405@sms.ed.ac.uk>
	<D29B9CB8-6405-11D9-A2A3-000A95BB392A@gmail.com>
	<1105547654.41e551867226d@sms.ed.ac.uk>
Message-ID: <67531B22-65EB-11D9-A117-000A95BB392A@gmail.com>

Hi Tarik,

> So for the ambient light of .5 .5 .5 I just add it at the end? I don't 
> need to
> multiply by the diffuse component rho_diffuse?

That's correct -- Radiance handles multiplication of the ambient with 
the various surfaces.  (It would have to for any scene containing more 
than one surface type.)

-Greg

> From: Tarik Rahman <tarik.rahman@ed.ac.uk>
> Date: January 12, 2005 8:34:14 AM PST
>
> Thanks for that, made the correction for tan^2(delta) and delta is as 
> you say
> delta = normal.dotProduct(halfwayVectorUnit);
> where
> halfwayVector = point_to_lightUnit  - point_to_camUnit;
> halfwayVectorUnit = halfwayVector.normalize();
>
>
> So for the ambient light of .5 .5 .5 I just add it at the end? I don't 
> need to
> multiply by the diffuse component rho_diffuse?
>
> Tarik


From Giulio.Antonutto at arup.com  Fri Jan 14 10:42:00 2005
From: Giulio.Antonutto at arup.com (Giulio Antonutto)
Date: Fri Jan 14 10:45:09 2005
Subject: [Radiance-general] [Radiance and Brad] MacosX and X11 and bra
	d  anblender
Message-ID: <DC0CAEEA090E984C911D3B85B16C3F900302C37B@l-gnts05>

just have a morning chat with the main brad guru:
Francesco itself ;-)))
we tried different things and we think to have identified the problem:

-1- make sure that ximage works at all on your system (just a silly check,
but you never know)
-2- if ximage works, the solution is then to start blender from the
terminal.

to do that you need to go into: 
blender.app/contents/macos

in fact blender.app is a folder folder as all macosx applications
(to browse it you need to ctlr+click on it and ask for 'show contents' in
the contextual menu)

when you are into 
blender.app/contents/macos
just type: 
./blender

the GUI starts and everything works.
plus you are able to see error messages in the terminal window (good if you
need to fix a problem)
only small problem is that the window is larger than the screen, but you can
adjust the menu position by dragging them.


hope it works now
cheers
giulio
&
francesco


-----Original Message-----
From: radiance-general-bounces@radiance-online.org
[mailto:radiance-general-bounces@radiance-online.org]On Behalf Of J.
Sienknecht
Sent: 13 January 2005 21:51
To: radiance
Subject: [Radiance-general] [Radiance and Brad] MacosX and X11 and brad
anblender


Hello everyone! I'm really new to radiance and first I have to say:

Thank You Very Much For Developing And Supporting This Free Software!!

Radiance is running fine on my system (far as i can see) with macos 10.3.7,
blender 2.3.6, python 2.3.

My question is more about blender and brad because

everything seems to work in general, but if i try the sky preview
i get the following in the console window:

" ximage 
/Applications/Blender/blender.app/Contents/MacOS/.blender/scripts/brad/tmp/
mph.pic: cannot open display"

I've edited my bash_profile like it was explained from pillo:

--------
if someone is interested in using x11 as graphical output for the built
in panther terminal this is what is required:

1) launch x11, launch terminal (keep X11  always open when the terminal
is open, otherwise it doesn't work!)

2) edit your .bash_profile as follows, just add these lines:

if [ -z "${DISPLAY}" ];then echo -n
export DISPLAY=':0'
fi 
---------

but sadley it has not the desired (display-) effect to applications
controlled via brad/blender, too.

would it be possible to open x-window-radiance-applications like ximage out
of blender/python in a way that they use x-darwin and its display?

thank you very much and all the best

johannes



_______________________________________________
Radiance-general mailing list
Radiance-general@radiance-online.org
http://www.radiance-online.org/mailman/listinfo/radiance-general

___________________________________________________________________
Electronic mail messages entering and leaving Arup business
systems are scanned for acceptability of content and viruses.

From tarik.rahman at ed.ac.uk  Fri Jan 14 13:11:13 2005
From: tarik.rahman at ed.ac.uk (Tarik Rahman)
Date: Fri Jan 14 13:11:36 2005
Subject: [Radiance-general] Re: implementing Radiance reflection model
In-Reply-To: <67531B22-65EB-11D9-A117-000A95BB392A@gmail.com>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
	<1105455940.41e3eb4464405@sms.ed.ac.uk>
	<D29B9CB8-6405-11D9-A2A3-000A95BB392A@gmail.com>
	<1105547654.41e551867226d@sms.ed.ac.uk>
	<67531B22-65EB-11D9-A117-000A95BB392A@gmail.com>
Message-ID: <1105704673.41e7b6e196c19@sms.ed.ac.uk>

Oh, I know that Radiance handles the ambient term but say I wanted to write my
own code implementing the Radiance model, which terms would I need to multiply
the ambient value by?

Tarik

Quoting Greg Ward <gregoryjward@gmail.com>:

> Hi Tarik,
>
> > So for the ambient light of .5 .5 .5 I just add it at the end? I don't
> > need to
> > multiply by the diffuse component rho_diffuse?
>
> That's correct -- Radiance handles multiplication of the ambient with
> the various surfaces.  (It would have to for any scene containing more
> than one surface type.)
>
> -Greg
>
> > From: Tarik Rahman <tarik.rahman@ed.ac.uk>
> > Date: January 12, 2005 8:34:14 AM PST
> >
> > Thanks for that, made the correction for tan^2(delta) and delta is as
> > you say
> > delta = normal.dotProduct(halfwayVectorUnit);
> > where
> > halfwayVector = point_to_lightUnit  - point_to_camUnit;
> > halfwayVectorUnit = halfwayVector.normalize();
> >
> >
> > So for the ambient light of .5 .5 .5 I just add it at the end? I don't
> > need to
> > multiply by the diffuse component rho_diffuse?
> >
> > Tarik
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>


--
Tarik Rahman
PhD student, Institue of Perception, Action and Behaviour
School of Informatics
University of Edinburgh

From johannes at itara.org  Fri Jan 14 16:07:22 2005
From: johannes at itara.org (J. Sienknecht)
Date: Fri Jan 14 16:07:49 2005
Subject: [Radiance-general] MacosX and X11 and radiance and blender
	and brad
In-Reply-To: <DC0CAEEA090E984C911D3B85B16C3F900302C37B@l-gnts05>
Message-ID: <BE0D9EBA.52CC%johannes@itara.org>

yes it works! ((-: 
thank you very much!

btw: is there a list like "recommended readings" for people who are starting
to learn radiance? I would like to know, as an example, what kind of math
and physics people (really) have to know, and which books are recommended
therefor etc.
I have orderd the "The Art And Science Of Lighting Visualization" - is
everything (and more...) I (will) ask about inside this book?

all the best

johannes


> just have a morning chat with the main brad guru:
> Francesco itself ;-)))
> we tried different things and we think to have identified the problem:
> 
> -1- make sure that ximage works at all on your system (just a silly check,
> but you never know)
> -2- if ximage works, the solution is then to start blender from the
> terminal.
> 
> to do that you need to go into:
> blender.app/contents/macos
> 
> in fact blender.app is a folder folder as all macosx applications
> (to browse it you need to ctlr+click on it and ask for 'show contents' in
> the contextual menu)
> 
> when you are into
> blender.app/contents/macos
> just type: 
> ./blender
> 
> the GUI starts and everything works.
> plus you are able to see error messages in the terminal window (good if you
> need to fix a problem)
> only small problem is that the window is larger than the screen, but you can
> adjust the menu position by dragging them.
> 
> 
> hope it works now
> cheers
> giulio
> &
> francesco
> 
> 
> -----Original Message-----
> From: radiance-general-bounces@radiance-online.org
> [mailto:radiance-general-bounces@radiance-online.org]On Behalf Of J.
> Sienknecht
> Sent: 13 January 2005 21:51
> To: radiance
> Subject: [Radiance-general] [Radiance and Brad] MacosX and X11 and brad
> anblender
> 
> 
> Hello everyone! I'm really new to radiance and first I have to say:
> 
> Thank You Very Much For Developing And Supporting This Free Software!!
> 
> Radiance is running fine on my system (far as i can see) with macos 10.3.7,
> blender 2.3.6, python 2.3.
> 
> My question is more about blender and brad because
> 
> everything seems to work in general, but if i try the sky preview
> i get the following in the console window:
> 
> " ximage 
> /Applications/Blender/blender.app/Contents/MacOS/.blender/scripts/brad/tmp/
> mph.pic: cannot open display"
> 
> I've edited my bash_profile like it was explained from pillo:
> 
> --------
> if someone is interested in using x11 as graphical output for the built
> in panther terminal this is what is required:
> 
> 1) launch x11, launch terminal (keep X11  always open when the terminal
> is open, otherwise it doesn't work!)
> 
> 2) edit your .bash_profile as follows, just add these lines:
> 
> if [ -z "${DISPLAY}" ];then echo -n
> export DISPLAY=':0'
> fi 
> ---------
> 
> but sadley it has not the desired (display-) effect to applications
> controlled via brad/blender, too.
> 
> would it be possible to open x-window-radiance-applications like ximage out
> of blender/python in a way that they use x-darwin and its display?
> 
> thank you very much and all the best
> 
> johannes
> 
> 
> 
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
> 
> ___________________________________________________________________
> Electronic mail messages entering and leaving Arup business
> systems are scanned for acceptability of content and viruses.
> 
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general



From rpg at rumblestrip.org  Fri Jan 14 16:23:40 2005
From: rpg at rumblestrip.org (Rob Guglielmetti)
Date: Fri Jan 14 16:24:01 2005
Subject: [Radiance-general] MacosX and X11 and radiance and blender and 
	brad
In-Reply-To: <BE0D9EBA.52CC%johannes@itara.org>
References: <DC0CAEEA090E984C911D3B85B16C3F900302C37B@l-gnts05>
	<BE0D9EBA.52CC%johannes@itara.org>
Message-ID: <41968.209.212.87.250.1105716220.squirrel@209.212.87.250>


> btw: is there a list like "recommended readings" for people who are
> starting
> to learn radiance? I would like to know, as an example, what kind of math
> and physics people (really) have to know, and which books are recommended
> therefor etc.
> I have orderd the "The Art And Science Of Lighting Visualization" - is
> everything (and more...) I (will) ask about inside this book?

Hi Johannes, welcome.

Ah, the two best resources for learning & using Radiance are:

1) The book "Rendering with Radiance", and:
2) This list.

Rendering with Radiance recently became available again for purchase, and
if you search this list's archives you will find the ordering information
for that.  It is truly the bible for this software.  As Brad Hamilton said
to Jeff Spicoli in "Fast Times at Ridgemont High" when referring to the
rules of the restaurant, "read it, know it, live it".

As for math & physics, well, this former theatre major is using Radiance
on a fairly regular basis.  Oh yes, there are conversations on this list
that go sailing clear over my head, but that just shows the enormous
flexibility of the software and the diversity of the user base.  That
said, you *should* have a grounding in the basics of the physics of light
& illumination.  I'd assume you have an interest in that or you wouldn't
be looking to get involved with this bunch of wackos in the first place.

Have fun...

- Rob Guglielmetti
www.rumblestrip.org

From gregoryjward at gmail.com  Fri Jan 14 21:38:49 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Fri Jan 14 21:39:38 2005
Subject: [Radiance-general] Re: implementing Radiance reflection model
In-Reply-To: <1105704673.41e7b6e196c19@sms.ed.ac.uk>
References: <BAY22-DAV7A0E5D631C9A893588A5990930@phx.gbl>
	<9C6043CE-6046-11D9-9BBB-000A95BB392A@gmail.com>
	<BAY22-DAV11BD621460E9C98D176CC90970@phx.gbl>
	<1105455940.41e3eb4464405@sms.ed.ac.uk>
	<D29B9CB8-6405-11D9-A2A3-000A95BB392A@gmail.com>
	<1105547654.41e551867226d@sms.ed.ac.uk>
	<67531B22-65EB-11D9-A117-000A95BB392A@gmail.com>
	<1105704673.41e7b6e196c19@sms.ed.ac.uk>
Message-ID: <4BE5AB42-666C-11D9-988F-000A95BB392A@gmail.com>

Hi Tarik,

This is explained pretty well in section 4 of the materials.pdf 
document.  I assume you are reading this:

	http://radsite.lbl.gov/radiance/refer/materials.pdf

You multiply the ambient by the rho_a parameter of the reflectance 
model, which is the same as rho_d in most cases.

-Greg

> From: Tarik Rahman <tarik.rahman@ed.ac.uk>
> Date: January 14, 2005 4:11:13 AM PST
>
> Oh, I know that Radiance handles the ambient term but say I wanted to 
> write my
> own code implementing the Radiance model, which terms would I need to 
> multiply
> the ambient value by?
>
> Tarik


From a.jacobs at londonmet.ac.uk  Mon Jan 17 17:39:24 2005
From: a.jacobs at londonmet.ac.uk (Axel Jacobs)
Date: Mon Jan 17 17:39:59 2005
Subject: [Radiance-general] Radiance tutorial (Was: MacosX and X11 and
 radiance and blender and brad)
In-Reply-To: <BE0D9EBA.52CC%johannes@itara.org>
References: <DC0CAEEA090E984C911D3B85B16C3F900302C37B@l-gnts05>
	<BE0D9EBA.52CC%johannes@itara.org>
Message-ID: <35089.193.137.43.137.1105979964.squirrel@193.137.43.137>

Johannes,

> btw: is there a list like "recommended readings" for people who are
> starting
> to learn radiance? I would like to know, as an example, what kind of math
> and physics people (really) have to know, and which books are recommended
> therefor etc.
> I have orderd the "The Art And Science Of Lighting Visualization" - is
> everything (and more...) I (will) ask about inside this book?

Make sure you also take a look at the LEARNIX web site:
http://luminance.londonmet.ac.uk/learnix/

Under "Documentation", you?ll find our course notes from the simulation
module we teach on our masters course. We teach RADIANCE for lighting,
ESP-r for thermal simulations.

Oh, and DO give LEARNIX a spin!

Cheers

Axel



From gregoryjward at gmail.com  Mon Jan 17 19:21:05 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Mon Jan 17 19:21:53 2005
Subject: [Radiance-general] Radiance tutorial (Was: MacosX and X11 and
	radiance and blender and brad)
In-Reply-To: <35089.193.137.43.137.1105979964.squirrel@193.137.43.137>
References: <DC0CAEEA090E984C911D3B85B16C3F900302C37B@l-gnts05>
	<BE0D9EBA.52CC%johannes@itara.org>
	<35089.193.137.43.137.1105979964.squirrel@193.137.43.137>
Message-ID: <8D2429F2-68B4-11D9-B6F0-000A95BB392A@gmail.com>

Wow, Axel.  I hadn't seen these tutorials before.  They're amazing!  
With your permission, I'd like to add them to the list of documents on 
radsite, which is unfortunately down at the moment.  This also 
dovetails with a discussion we've been having on the dev list about 
providing an interactive repository (or Wiki) for Radiance user 
documentation.  I know a lot of people don't subscribe to that list, so 
I'll summarize:

It started as a rehash of why Radiance authorship is restricted, and if 
there were any decent guidelines for code modifications, which is how 
it got on the dev list.  Then, people started suggesting things about 
how to set up documentation for the software, and it eventually came 
back to some kind of FAQ service for beginners.  The general feeling is 
that a lot of people who might otherwise be interested in Radiance are 
put off by the command-line structure, the scattered documentation, and 
the lack of any clear place to begin (aside from the book of course).  
After all, not everyone wants to order a book and wait for it to be 
shipped to their door just to decide whether or not it's worth the 
effort to learn something.

The current line of reasoning is to provide a forum where more 
experienced users could answer beginner's questions and have their 
answers continually available and editable.  There would also be a 
place for people to write essays on how they got started with Radiance, 
things to avoid, and things to pay attention to.  How-to manuals and 
tutorials such as Axel's would be a perfect jumping off point for a lot 
of newbies, I would think.  The current set of tutorials on radsite are 
getting a little "long in the tooth" so to speak, even if they still 
have a lot of useful information.

I think we're going back and forth right now trying to come up with the 
best way to set this up.  Some people have already set up their own 
resource centers, and we could either link to them or take some of 
their content into our own organization.  (See Georg Mischler's 
Lighting Wiki example at <http://lightingwiki.com/> as an example of 
what's already out there.)  Probably the best way to start is to write 
to me if you have some materials to offer, and I'll talk with Peter A-B 
about setting something up at radiance-online.

Thanks,
-Greg

> From: "Axel Jacobs" <a.jacobs@londonmet.ac.uk>
> Date: January 17, 2005 8:39:24 AM PST
>
> Johannes,
>
>> btw: is there a list like "recommended readings" for people who are
>> starting
>> to learn radiance? I would like to know, as an example, what kind of 
>> math
>> and physics people (really) have to know, and which books are 
>> recommended
>> therefor etc.
>> I have orderd the "The Art And Science Of Lighting Visualization" - is
>> everything (and more...) I (will) ask about inside this book?
>
> Make sure you also take a look at the LEARNIX web site:
> http://luminance.londonmet.ac.uk/learnix/
>
> Under "Documentation", you?ll find our course notes from the simulation
> module we teach on our masters course. We teach RADIANCE for lighting,
> ESP-r for thermal simulations.
>
> Oh, and DO give LEARNIX a spin!
>
> Cheers
>
> Axel


From mike at cityscape3d.com  Tue Jan 18 13:23:42 2005
From: mike at cityscape3d.com (Michael Kruger)
Date: Tue Jan 18 13:25:04 2005
Subject: [Radiance-general] RE: Axel's tutorials
In-Reply-To: <200501181040.j0IAeZ5l072118@server.cityscape3d.com>
Message-ID: <200501181204.j0IC4rfW073484@server.cityscape3d.com>

I strongly second greg's "wow!" My first introduction to radiance was 
thru a training session run by Axel & his tutorials are the best I've seen
so far wrt radiance.

Axel: Would you mind if I added your tutorial to www.radiance-wiki.org?

mike

> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Mon, 17 Jan 2005 16:39:24 -0000 (GMT)
> From: "Axel Jacobs" <a.jacobs@londonmet.ac.uk>
> Subject: [Radiance-general] Radiance tutorial (Was: MacosX and X11 and
> 	radiance and blender and brad)
> To: "Radiance general discussion"
> 	<radiance-general@radiance-online.org>
> Message-ID: <35089.193.137.43.137.1105979964.squirrel@193.137.43.137>
> Content-Type: text/plain;charset=iso-8859-1
> 
> Johannes,
> 
> > btw: is there a list like "recommended readings" for people who are 
> > starting to learn radiance? I would like to know, as an 
> example, what 
> > kind of math and physics people (really) have to know, and 
> which books 
> > are recommended therefor etc.
> > I have orderd the "The Art And Science Of Lighting 
> Visualization" - is 
> > everything (and more...) I (will) ask about inside this book?
> 
> Make sure you also take a look at the LEARNIX web site:
> http://luminance.londonmet.ac.uk/learnix/
> 
> Under "Documentation", you4ll find our course notes from the 
> simulation module we teach on our masters course. We teach 
> RADIANCE for lighting, ESP-r for thermal simulations.
> 
> Oh, and DO give LEARNIX a spin!
> 
> Cheers
> 
> Axel
> 
> 
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Mon, 17 Jan 2005 10:21:05 -0800
> From: Greg Ward <gregoryjward@gmail.com>
> Subject: Re: [Radiance-general] Radiance tutorial (Was: MacosX and X11
> 	and	radiance and blender and brad)
> To: Radiance general discussion <radiance-general@radiance-online.org>
> Cc: code development <radiance-dev@radiance-online.org>
> Message-ID: <8D2429F2-68B4-11D9-B6F0-000A95BB392A@gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> Wow, Axel.  I hadn't seen these tutorials before.  They're amazing!  
> With your permission, I'd like to add them to the list of 
> documents on radsite, which is unfortunately down at the 
> moment.  This also dovetails with a discussion we've been 
> having on the dev list about providing an interactive 
> repository (or Wiki) for Radiance user documentation.  I know 
> a lot of people don't subscribe to that list, so I'll summarize:
> 
> It started as a rehash of why Radiance authorship is 
> restricted, and if there were any decent guidelines for code 
> modifications, which is how it got on the dev list.  Then, 
> people started suggesting things about how to set up 
> documentation for the software, and it eventually came back 
> to some kind of FAQ service for beginners.  The general 
> feeling is that a lot of people who might otherwise be 
> interested in Radiance are put off by the command-line 
> structure, the scattered documentation, and the lack of any 
> clear place to begin (aside from the book of course).  
> After all, not everyone wants to order a book and wait for it 
> to be shipped to their door just to decide whether or not 
> it's worth the effort to learn something.
> 
> The current line of reasoning is to provide a forum where 
> more experienced users could answer beginner's questions and 
> have their answers continually available and editable.  There 
> would also be a place for people to write essays on how they 
> got started with Radiance, things to avoid, and things to pay 
> attention to.  How-to manuals and tutorials such as Axel's 
> would be a perfect jumping off point for a lot of newbies, I 
> would think.  The current set of tutorials on radsite are 
> getting a little "long in the tooth" so to speak, even if 
> they still have a lot of useful information.
> 
> I think we're going back and forth right now trying to come 
> up with the best way to set this up.  Some people have 
> already set up their own resource centers, and we could 
> either link to them or take some of their content into our 
> own organization.  (See Georg Mischler's Lighting Wiki 
> example at <http://lightingwiki.com/> as an example of what's 
> already out there.)  Probably the best way to start is to 
> write to me if you have some materials to offer, and I'll 
> talk with Peter A-B about setting something up at radiance-online.
> 
> Thanks,
> -Greg
> 
> > From: "Axel Jacobs" <a.jacobs@londonmet.ac.uk>
> > Date: January 17, 2005 8:39:24 AM PST
> >
> > Johannes,
> >
> >> btw: is there a list like "recommended readings" for 
> people who are 
> >> starting to learn radiance? I would like to know, as an 
> example, what 
> >> kind of math and physics people (really) have to know, and which 
> >> books are recommended therefor etc.
> >> I have orderd the "The Art And Science Of Lighting 
> Visualization" - 
> >> is everything (and more...) I (will) ask about inside this book?
> >
> > Make sure you also take a look at the LEARNIX web site:
> > http://luminance.londonmet.ac.uk/learnix/
> >
> > Under "Documentation", you4ll find our course notes from the 
> > simulation module we teach on our masters course. We teach RADIANCE 
> > for lighting, ESP-r for thermal simulations.
> >
> > Oh, and DO give LEARNIX a spin!
> >
> > Cheers
> >
> > Axel
> 
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
> 
> 
> End of Radiance-general Digest, Vol 11, Issue 15
> ************************************************


From kbaker at syska.com  Tue Jan 18 16:56:11 2005
From: kbaker at syska.com (Baker, Kristopher)
Date: Tue Jan 18 16:56:35 2005
Subject: [Radiance-general] Specular Reflections from Plastic?
Message-ID: <9532C91A4A8A954683A3CF2C59AF889F01BE68C8@sh-srv-mail1.syskamail.syska.net>

Hello,

I have a fundamental question about Radiance that I can't figure out.  
What is the best way to get Source specular reflections from a plastic,
metal, or trans material? 

In my model, setting the specular component of the material at or near
1.0 correctly provides view reflections in the material (reflections of
the window on the other end of the room).  However, there are no
reflected solar patches, as is expected with direct sun landing on the
reflective material.

Using the material type mirror, the virtual light source is created and
the solar patch shows up, but when a plastic, metal, or trans material
is specified with a specularity at or near 1.0, there isn't even a
glimpse of the expected reflected solar patch.

As an example, imagine a window with a partition perpendicular to that
window.  The sun is out and shining through the window onto that
partition. 

-If I make that partition a mirror material type, I see this wonderful
reflected solar patch on the floor.

-If I make that partition a plastic, trans, or metal with a specular
component of 1.0, there is no reflected solar patch on the floor.

>From my understanding, the mirror treats the reflected solar patch as a
virtual light source and all is good, but it does not do this for
plastic, metal, trans.

When the plastic, metal, or trans is set as specular, Radiance
accurately shows the reflection of the view in the partition (in this
case the window), but the direct solar flux that entered and hit the
partition is gone, or at least transferred to the indirect or ambient
component. 

All parameters are defaulted at the medium level and I have bumped
direct relays to 3 (lr=6, lw=.002, dr=3, st=0.1)

This is simple and a most fundamental calculation, but alas no dice. 

Any ideas?  Thanks.


KB
Kristopher S. Baker

From gregoryjward at gmail.com  Tue Jan 18 17:27:29 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Tue Jan 18 17:27:51 2005
Subject: [Radiance-general] Specular Reflections from Plastic?
In-Reply-To: <9532C91A4A8A954683A3CF2C59AF889F01BE68C8@sh-srv-mail1.syskamail.syska.net>
References: <9532C91A4A8A954683A3CF2C59AF889F01BE68C8@sh-srv-mail1.syskamail.syska.net>
Message-ID: <856a6c2e050118082767437155@mail.gmail.com>

Hi Kristopher,

The reason ordinary materials do not create virtual light sources the
way mirror and the prism types do is because it would be too
expensive.  If you had two such surfaces facing each other with
a light source between them, they would potentially create an
infinite number of virtual light sources.  (This is why the -dr
option is there, to prevent such a calamity when using facing
"mirror" surfaces.)

If you want to have the material properties of plastic or metal,
with the virtual light sources of mirror, then use your plastic
or metal as the alternate type in your mirror specification.

What is the problem?  Is it simply not what you expected?
Did you expect it to create an infinite set of virtual sources
for you?  Then you should also expect the simulation to 
take forever.

-Greg

On Tue, 18 Jan 2005 09:56:11 -0600, Baker, Kristopher <kbaker@syska.com> wrote:
> Hello,
> 
> I have a fundamental question about Radiance that I can't figure out.
> What is the best way to get Source specular reflections from a plastic,
> metal, or trans material?
> 
> In my model, setting the specular component of the material at or near
> 1.0 correctly provides view reflections in the material (reflections of
> the window on the other end of the room).  However, there are no
> reflected solar patches, as is expected with direct sun landing on the
> reflective material.
> 
> Using the material type mirror, the virtual light source is created and
> the solar patch shows up, but when a plastic, metal, or trans material
> is specified with a specularity at or near 1.0, there isn't even a
> glimpse of the expected reflected solar patch.
> 
> As an example, imagine a window with a partition perpendicular to that
> window.  The sun is out and shining through the window onto that
> partition.
> 
> -If I make that partition a mirror material type, I see this wonderful
> reflected solar patch on the floor.
> 
> -If I make that partition a plastic, trans, or metal with a specular
> component of 1.0, there is no reflected solar patch on the floor.
> 
> >From my understanding, the mirror treats the reflected solar patch as a
> virtual light source and all is good, but it does not do this for
> plastic, metal, trans.
> 
> When the plastic, metal, or trans is set as specular, Radiance
> accurately shows the reflection of the view in the partition (in this
> case the window), but the direct solar flux that entered and hit the
> partition is gone, or at least transferred to the indirect or ambient
> component.
> 
> All parameters are defaulted at the medium level and I have bumped
> direct relays to 3 (lr=6, lw=.002, dr=3, st=0.1)
> 
> This is simple and a most fundamental calculation, but alas no dice.
> 
> Any ideas?  Thanks.
> 
> KB
> Kristopher S. Baker

From a.jacobs at londonmet.ac.uk  Tue Jan 18 19:37:53 2005
From: a.jacobs at londonmet.ac.uk (Axel Jacobs)
Date: Tue Jan 18 19:38:14 2005
Subject: [Radiance-general] RE: Axel's tutorials
In-Reply-To: <200501181204.j0IC4rfW073484@server.cityscape3d.com>
References: <200501181040.j0IAeZ5l072118@server.cityscape3d.com>
	<200501181204.j0IC4rfW073484@server.cityscape3d.com>
Message-ID: <32990.195.23.160.104.1106073473.squirrel@195.23.160.104>

> I strongly second greg's "wow!" My first introduction to radiance was
> thru a training session run by Axel & his tutorials are the best I've seen
> so far wrt radiance.

Thanks for the flowers.

> Axel: Would you mind if I added your tutorial to www.radiance-wiki.org?

I'd be delighted. Thanks a lot.

All
---

While I would like to keep the BASICs tutorial as it is (it's my teaching
notes, after all -- but please tell me if there are any mistakes), I would
be very happy to donate the ADVANCED one to whatever central docu
repository might come up
a) as they are, with additional contributions from you guys (I am happy to
maintain them), or
b) converted to HTML pages/Wiki/(Not DOC!!!)/whatever-but-open, gutted
out, broken apart, re-formatted etc. At the moment, they're in LyX/LaTeX
format.

Glad you like them.

Cheers

Axel



From rpg at rumblestrip.org  Tue Jan 18 19:46:09 2005
From: rpg at rumblestrip.org (Rob Guglielmetti)
Date: Tue Jan 18 19:46:29 2005
Subject: [Radiance-general] RE: Axel's tutorials
In-Reply-To: <32990.195.23.160.104.1106073473.squirrel@195.23.160.104>
References: <200501181040.j0IAeZ5l072118@server.cityscape3d.com>
	<200501181204.j0IC4rfW073484@server.cityscape3d.com>
	<32990.195.23.160.104.1106073473.squirrel@195.23.160.104>
Message-ID: <11503.209.212.87.250.1106073969.squirrel@209.212.87.250>


> Thanks for the flowers.

Yeah, sorry for the late flower delivery myself, but I've been busy
reading your tutorial and following the many good links!  Good stuff,
Axel.  Here, have a rose.

> While I would like to keep the BASICs tutorial as it is (it's my teaching
> notes, after all -- but please tell me if there are any mistakes), I would
> be very happy to donate the ADVANCED one to whatever central docu
> repository might come up
> a) as they are, with additional contributions from you guys (I am happy to
> maintain them), or
> b) converted to HTML pages/Wiki/(Not DOC!!!)/whatever-but-open, gutted
> out, broken apart, re-formatted etc. At the moment, they're in LyX/LaTeX
> format.

I think this is an excellent quality bit of material for the newly
emerging document repository, wiki, FAQ, FAQwa, whatever it becomes. 
Broken apart, your advanced tutorial fills a bunch of the topics being
batted around by folks the last day or so (on the Dev list).

Thanks for sharing these, and for writing them in the first place!

- Rob Guglielmetti
www.rumblestrip.org

From furry at ihug.com.au  Tue Jan 18 23:26:21 2005
From: furry at ihug.com.au (furry@ihug.com.au)
Date: Tue Jan 18 23:26:59 2005
Subject: [Radiance-general] Discomfort Glare - How do I evaluate
Message-ID: <E1Cr1np-0005nj-00@noir.ihug.com.au>

Hi all,

I working on a glare study with reflected sunlight through a skylight causing 
glare and we are evaluating different glass, laminates and meshes to mitigate 
problems from the glare.

When I use Radiance to evaluate each view, I can get the results for:
- Guth Visual Comfort Probability,
- CIE Glare Index (Einhorn)
- Unified Glare Rating.

What I would appreciate some advice on is which is the most appropriate in this 
case for determining when glare has been reduced to a generally acceptable 
level.  Also, I am wondering what values would be considered acceptable for 
each of these 3 methods of determining glare (ie. VCP > 70% or 50% ??? .. what 
is generally considered acceptable?).

Thanks for your help,
Richard




From MMoeck at engr.psu.edu  Tue Jan 18 23:58:44 2005
From: MMoeck at engr.psu.edu (Martin Moeck)
Date: Tue Jan 18 23:59:15 2005
Subject: [Radiance-general] Discomfort Glare - How do I evaluate
Message-ID: <84F05BA9118BBD4A8FC6409808CE266C23411C@ENGRMAIL2.engr.psu.edu>

UGR should be <=20
VCP >= 67

All glare ratings are related. 

UGR is most widely used. It would be appropriate for small skylights.
The Glare Index System was used in Great Britain, Belgium, South Africa and (slightly modified) in Scandinavia. As a recommendation, nowhere in the visual field should the luminance of any bright area exceed 40 times the luminance of  the visual task. 


Martin Moeck


-----Original Message-----
From:	furry@ihug.com.au [mailto:furry@ihug.com.au]
Sent:	Tue 1/18/2005 5:26 PM
To:	radiance-general@radiance-online.org
Cc:	
Subject:	[Radiance-general] Discomfort Glare - How do I evaluate
Hi all,

I working on a glare study with reflected sunlight through a skylight causing 
glare and we are evaluating different glass, laminates and meshes to mitigate 
problems from the glare.

When I use Radiance to evaluate each view, I can get the results for:
- Guth Visual Comfort Probability,
- CIE Glare Index (Einhorn)
- Unified Glare Rating.

What I would appreciate some advice on is which is the most appropriate in this 
case for determining when glare has been reduced to a generally acceptable 
level.  Also, I am wondering what values would be considered acceptable for 
each of these 3 methods of determining glare (ie. VCP > 70% or 50% ??? .. what 
is generally considered acceptable?).

Thanks for your help,
Richard




_______________________________________________
Radiance-general mailing list
Radiance-general@radiance-online.org
http://www.radiance-online.org/mailman/listinfo/radiance-general



-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/ms-tnef
Size: 3348 bytes
Desc: not available
Url : http://radiance-online.org/pipermail/radiance-general/attachments/20050118/41dc977c/attachment-0001.bin
From grobe at gmx.net  Wed Jan 19 00:24:58 2005
From: grobe at gmx.net (Lars O. Grobe)
Date: Wed Jan 19 00:25:20 2005
Subject: [Radiance-general] G4-optimized binaries for Mac OS X
Message-ID: <2B7DCB34-69A8-11D9-A7B0-000A959DDB22@gmx.net>

Hi,

I compiled recent releases for OS X and used gcc's optimizations for G4  
processors. This gives about 10 % performance when I try the benchmark  
files provided on Mark Stock's pages. I also submitted the result to  
him. The opt-line in the makeall script here is as follows:

set opt="-O2 -DSPEED=200 -mcpu=7400 -mtune=7400 -malign-natural  
-funroll-loops -fstrict-aliasing -fsched-interblock -falign-loops=16  
-falign-jumps=16 -falign-functions=16 -falign-jumps-max-skip=15  
-falign-loops-max-skip=15 -ffast-math -mpowerpc-gpopt  
-fstrict-aliasing"

Those who want to try my binaries can get them directly from the  
following address:

3.6 patch 1 release:
http://130.83.168.34/lars/rad/bin/Radiance-Darwin-PPCG4-3.6.1.tar.bz2

HEAD release from 18th january:
http://130.83.168.34/lars/rad/bin/Radiance-Darwin-PPCG4- 
head20050118.tar.bz2

The files will be linked on the binary-pages I maintain on  
lgrobe.port5.com (those are linked from radiance-online.org), but the  
host is currently down and I have to wait that my provider brings it  
back ;-)

CU, and have fun, Lars.


From a.jacobs at londonmet.ac.uk  Wed Jan 19 01:23:27 2005
From: a.jacobs at londonmet.ac.uk (Axel Jacobs)
Date: Wed Jan 19 01:23:48 2005
Subject: [Radiance-general] Discomfort Glare - How do I evaluate
In-Reply-To: <E1Cr1np-0005nj-00@noir.ihug.com.au>
References: <E1Cr1np-0005nj-00@noir.ihug.com.au>
Message-ID: <33195.195.23.160.78.1106094207.squirrel@195.23.160.78>

Hi Richard,

o.k. then, let's open this can of worms:

Quoting from "Daylighting in Architecture - A European Reference Book",
the DGI is stepped as such:

Just imperceptible    16
                      18
Just acceptable       20
                      22
Just uncomfortable    24
                      26
Just intolarable      28

It seems to me that you definitely shouldn't be using the UGR or any other
non-DGI, because they are all derived for artificial light sources. Having
said that, although the DGI is the only GI available now for natural
lighting (windows, sky lights etc.), more recent research has shown that
it's hardly applicable. So while artificial GIs might hold true to some
extend, daylight GIs should be treated with much scepticism and asbestos
gloves. You are pretty much on your own here, there is no generally
accepted theory. The DGI is the best we have at the moment, but there is
much debate about it.

I would suggest that you look at the contrast ratios of the surrounding vs
the reflected sun light and try to make the best of it. Glare is also much
more tolerated when it's not directly in the direct field of view.
Although not true in your case, you'll find that DG is much more tolerated
and glare from artificial light sources because usually it goes
hand-in-hand with a view out of the window which causes glare, and this
can not be quantified in a formula. There are just too many physiological
and psychological aspects that play a role here to make this an "exact
science".

Sorry for giving such a hard time, but it ain't easy.

To bring up a more "holistic" point of view: if you have bright sun
patches, then it's more likely that you should be worried about
overheating than glare. The latter costs you money in terms of A/C, the
former is a nuisance, not a problem, if caused by daylight.

Cheers

Axel



From jan.wienold at ise.fraunhofer.de  Thu Jan 20 10:57:53 2005
From: jan.wienold at ise.fraunhofer.de (Jan Wienold)
Date: Thu Jan 20 10:58:14 2005
Subject: [Radiance-general] Discomfort Glare - How do I evaluate
In-Reply-To: <E1Cr1np-0005nj-00@noir.ihug.com.au>
References: <E1Cr1np-0005nj-00@noir.ihug.com.au>
Message-ID: <41EF80A1.6090400@ise.fraunhofer.de>

Hi Richard and rest of community,

we are actually working on a research project, dealing with user 
assessments with special focus on glare from daylight in office spaces.
We have already tested 100 subjects at two different locations under 
very different conditions (facade systems, window sizes, viewing 
directions...).

As a first result I can summarize, that all existing formula like dgi, 
ugr, cie, vcp show a pearson correlation less than 0.15. Values less 
than 0.5 can be also achieved by chance...
Therefore I can not advice you to use these indices.

I can already announce, that we will come up with a new, much more 
reliable index, which will be called " daylight glare probability dgp". 
This dgp will model the probability, that a person in an office will be 
disturbed by daylight glare. The publication on this will be submitted 
by me and Jens Christoffersen in few days to an special issue on 
daylighting in "energy and buildings" and will hopefully published end 
of this year.

Additionally, we will come up with a new tool called "evalglare" , which 
is based on the RADIANCE picture format and will be available in mid  of 
this year
This tool has some new features compared to findglare and will have the 
new index implemented, too. (see also 
http://www.radiance-online.org/radiance-workshop3/cd/Wienold_extabs.pdf). 
As soon as it will be available I will announce it.

In the meanwhile, I would chose the vertical eye illuminance as a 
measure for the glare - for this value we found reasonable results 
comparing this to the percentage of disturbed persons.

Jan


furry@ihug.com.au wrote:

>Hi all,
>
>I working on a glare study with reflected sunlight through a skylight causing 
>glare and we are evaluating different glass, laminates and meshes to mitigate 
>problems from the glare.
>
>When I use Radiance to evaluate each view, I can get the results for:
>- Guth Visual Comfort Probability,
>- CIE Glare Index (Einhorn)
>- Unified Glare Rating.
>
>What I would appreciate some advice on is which is the most appropriate in this 
>case for determining when glare has been reduced to a generally acceptable 
>level.  Also, I am wondering what values would be considered acceptable for 
>each of these 3 methods of determining glare (ie. VCP > 70% or 50% ??? .. what 
>is generally considered acceptable?).
>
>Thanks for your help,
>Richard
>
>
>
>
>_______________________________________________
>Radiance-general mailing list
>Radiance-general@radiance-online.org
>http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>
>  
>

-- 
-------------------------------------------------------------------
   o -           
  | \            Jan Wienold
                 Fraunhofer Institute for Solar Energy Systems
                 SOLAR BUILDING DESIGN GROUP - DAYLIGHTING
                 Heidenhofstr. 2 
                 79110 Freiburg
                 GERMANY
		 
		 In office: 
		 Mo, Tue: 9:00-18:00
		 We-Fr:  8:30-14:00
                 Phone: ++49 - (0) 761 - 4588 -5- 133
                 Fax:   ++49 - (0) 761 - 4588 -9- 133
                 Email: jan.wienold@ise.fraunhofer.de
                 
                 Internet:
                 http://www.ise.fraunhofer.de



From a.i.ruppertsberg at Bradford.ac.uk  Thu Jan 20 12:13:32 2005
From: a.i.ruppertsberg at Bradford.ac.uk (Alexa I. Ruppertsberg)
Date: Thu Jan 20 12:14:39 2005
Subject: [Radiance-general] Evaluation
In-Reply-To: <41EF80A1.6090400@ise.fraunhofer.de>
Message-ID: <41EF925C.6010306@bradford.ac.uk>

Hi,

triggered by Jan's and Richard's problem of evaluating glare, I was 
wondering how the architectual & lighting community (obviously I'm not a 
member of it) uses RADIANCE. I understand, you simulate your buildings 
and assess various lighting-related factors.

a) how do you know that the results you come up with 'reflect the true 
values' (I assume 'true' is +/- an error)? I agree the simulation 
results are not completely out of order in terms of luminance, otherwise 
people wouldn't use RADIANCE.

b) once a buliding has been built, has anyone gone back inside the 
office they simulated and obtained measurements to compare with their 
simulation results?

c) what magnitude of error is acceptable for your work?

d) I've come across two opposing views on the accuracy of lumenaire 
descriptor files provided by manufacturers. One states that these can be 
off quite a bit (I think I read that in the 'Rendering with Radiance' 
book) and other authors strut how careful and accurate their simulation 
is by using manufacturer-provided lumenaire descriptors.

Sorry, if these questions sound rather trivial, but answers are highly 
appreciated.

Cheers,
Alexa

Jan Wienold wrote:
> Hi Richard and rest of community,
> 
> we are actually working on a research project, dealing with user 
> assessments with special focus on glare from daylight in office spaces.
> We have already tested 100 subjects at two different locations under 
> very different conditions (facade systems, window sizes, viewing 
> directions...).
> 

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Dr. Alexa I. Ruppertsberg
Department of Optometry
University of Bradford
Bradford
BD7 1DP
UK
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


From rpg at rumblestrip.org  Thu Jan 20 18:31:30 2005
From: rpg at rumblestrip.org (Rob Guglielmetti)
Date: Thu Jan 20 18:31:50 2005
Subject: [Radiance-general] Evaluation
In-Reply-To: <41EF925C.6010306@bradford.ac.uk>
References: <41EF80A1.6090400@ise.fraunhofer.de>
	<41EF925C.6010306@bradford.ac.uk>
Message-ID: <38932.209.212.87.250.1106242290.squirrel@209.212.87.250>

Hi Alexa,

> triggered by Jan's and Richard's problem of evaluating glare, I was
> wondering how the architectual & lighting community (obviously I'm not a
> member of it) uses RADIANCE.

OK, so I guess I'll go first.  But I'm not standing out here all by
myself; I'd love to hear from the rest of you...

> a) how do you know that the results you come up with 'reflect the true
> values' (I assume 'true' is +/- an error)? I agree the simulation
> results are not completely out of order in terms of luminance, otherwise
> people wouldn't use RADIANCE.

Good question.  Radiance itself has been the subject of many validation
studies, and has been proven to be quite capable of coming up with the
"true values" for most scenes, assuming valid, high-quality input. 
There's the rub though; skies are variable, and every project brings with
it new materials -- often materials unavailable for accurate sampling at
the time of the simulation.  So, often I *don't* know I'm looking at "true
values", but I do know (hope) that the values are close enough with which
to make evaluations.  Many times, we are evaluating several different
schemes, and when they are all simulated in Radiance with the same kind of
what I call "accuracy settings" -- you know, the myriad values used for
rpict & rtrace -- I know for certain that I can say scheme-a is (insert
criteria here, brightness, uniformity, whathaveyou) than scheme-b.  Often
this is all that is needed, is for Radiance to guide us in a direction
that can be explored more fully, either with Radiance or with physical
mockups.

But yes, the temptation is there, to treat the numbers generated by
Radiance as THE numbers.  I have to fight it all the time; I submit a
report showing 290 Lux on a plan, and people go "oh, this doesn't work, we
can't have more than 270 Lux there."  That's my cue to ease into the
discussion of how a mathematical model of the sky's luminance distribution
is NOT /the sky's/ luminance distribution, etc.

> b) once a buliding has been built, has anyone gone back inside the
> office they simulated and obtained measurements to compare with their
> simulation results?

Many of the validation studies do just that.  My first big project
simulated with Radiance is still under construction, but we have done
similar tests with projects simulated with Lightscape and AGI and have
been generally pleased with the outcome.  Typically, the light levels are
not the same, but neither is the real space as compared to the simulation
model.  But the values are all in the ballpark and the clients have been
happy. Indeed, the last big museum project I did with Lightscape at my
previous firm was astonishingly accurate, I believe the light levels on
the day my boss measured them were within 5% of the caluclation.  But I
also know a thing or two about luck.  I don't tell clients to expect 5%
accuracy and neither should you.  Barring luck, the only way to get that
close is to do a simulation with measured sky data (and take readings of
the space under that same sky that you are measuring).  Right, John M.? 
This of course requires a finished building, which sorta misses the point
of the simulation!  But John's thesis work provides the basis for many of
us using Radiance to achieve real restful sleep at night. =8-)

> c) what magnitude of error is acceptable for your work?

Ian Ashdown says it better than I can, in his (excellent) "Thinking
Photometrically" coursenotes:

"As for daylighting calculations, it is likely that Jongewaard (1993) is
correct ? the results are only as accurate as the accuracy of the input
data. Done with care, it should be possible to obtain ?20 percent accuracy
in the photometric predictions. However, this requires detailed knowledge
and accurate modeling of both the indoor and outdoor environments. If this
cannot be done, it may be advisable to walk softly and carry a calibrated
photometer."

> d) I've come across two opposing views on the accuracy of lumenaire
> descriptor files provided by manufacturers. One states that these can be
> off quite a bit (I think I read that in the 'Rendering with Radiance'
> book) and other authors strut how careful and accurate their simulation
> is by using manufacturer-provided lumenaire descriptors.

Photometry data from the manufacturers is a far better way to describe the
performance of a luminaire than most of the built-in tools in simulation
programs.  But yes, there are still problems.  Primarily, the issue of
far-field photometry.  Linear cove fixtures are trated as point sources
when photometred, and misuse of these IES files in a simulation can lead
to very inaccurate simulations.  Of course in Radiance you can increase
the -ds value to at least help the situation, by taking that "point"
distribution and sort-of arraying it along the fixture's axis.  As long as
the distribution is the same along the length of the luminaire, and your
-ds is suitably fine, you can get good results this way with
manufacturer-supplied data.  The other big lighting simulation packages
like AGI & Lumen Micro (and dear departed Lightscape) also allow you to do
this, in their own ways.

But sometimes the boast of accuracy simply because manufacturer-supplied
photometry is being used should be a warning sign...  I recently received
a mailer from one of the manufacturers of a popular lighting simulation
program, featuring a rendering on it that was supposed to impress upon me
how amazing and accurate the software is.  The thing is, the linear
uplight pendants in the image were casting this ridiculous round spot on
the ceiling, bearing no resemblance to the linear nature of the fixture --
in fact, it looked a heck of a lot like the operator knew nothing about
far-field photometry and the workarounds one must use when using
photometry files based on that method.  And this was the featured
rendering for the product's promotional literature -- worse, the rendering
was created by one of the company's in-house tech support/training people.
(!)

I think there is a big naivete in the industry -- when you get beyond this
group, who is obviously much more concerned with accuracy -- when it comes
to these photometry files, many designers just download the files and plug
them into their programs and hit the "do my job" button. In fact, these
files are really just ASCII dumps of a test report, a test that used a
certain lamp, with a certain lumen depreciation factor, which may be
different than the one in your spec; other light loss factors need to be
considered, the orientation may not even be what you expected.  So I guess
it just goes back to garbage in, garbage out.  Those manufacturer-supplied
files are only as good as the person integrating them into the simulation.

- Rob Guglielmetti
www.rumblestrip.org

From jedev at visarc.com  Thu Jan 20 19:27:10 2005
From: jedev at visarc.com (Jack de Valpine)
Date: Thu Jan 20 19:27:40 2005
Subject: [Radiance-general] Evaluation
In-Reply-To: <38932.209.212.87.250.1106242290.squirrel@209.212.87.250>
References: <41EF80A1.6090400@ise.fraunhofer.de>	<41EF925C.6010306@bradford.ac.uk>
	<38932.209.212.87.250.1106242290.squirrel@209.212.87.250>
Message-ID: <41EFF7FE.9090306@visarc.com>

Hi Rob and Alexa,

I will follow-on Rob's excellent comments with a few thoughts of my own.

As  Rob has indicated the "accuracy" of a given simulation is highly 
dependent on the accuracy of the input data (geometry, materials and 
lighting). But I think that accuracy also has to be evaluated in terms 
of project scope/objectives. A simulation project early in the design 
process will necessarily have less resolved information to work with 
(i.e. decision have not been made on a lot of things), whereas a 
simulation later in the design process will potentially have a different 
degree of accuracy due to design decisions at that point.

Another thing to consider is what is being compared against, while the 
real world is what we ultimately try to measure against, studying design 
scenarios is another way to use a simulation tool such a radiance. In 
comparative studies, that is one design scenario to another, most things 
can be held as constant with a few things varying (geometry, materials, 
or lighting). The question I would be inclined to ask in this case is 
whether we can make reasonable judgments about design scenarios even 
though we may not be using the most accurate data (for a variety of 
reasons), for example if we are using a simple sky model (e.g. gensky) 
can we still make reasonable design judgments. I would suggest that even 
with unknowns or limited data performing a radiance based simulation is 
going to be far more useful from a design evaluation standpoint that 
using one of the multitude of shrink wrap renderers that are out in the 
market.

Best,

-Jack de Valpine


Rob Guglielmetti wrote:

>Hi Alexa,
>
>  
>
>>triggered by Jan's and Richard's problem of evaluating glare, I was
>>wondering how the architectual & lighting community (obviously I'm not a
>>member of it) uses RADIANCE.
>>    
>>
>
>OK, so I guess I'll go first.  But I'm not standing out here all by
>myself; I'd love to hear from the rest of you...
>
>  
>
>>a) how do you know that the results you come up with 'reflect the true
>>values' (I assume 'true' is +/- an error)? I agree the simulation
>>results are not completely out of order in terms of luminance, otherwise
>>people wouldn't use RADIANCE.
>>    
>>
>
>Good question.  Radiance itself has been the subject of many validation
>studies, and has been proven to be quite capable of coming up with the
>"true values" for most scenes, assuming valid, high-quality input. 
>There's the rub though; skies are variable, and every project brings with
>it new materials -- often materials unavailable for accurate sampling at
>the time of the simulation.  So, often I *don't* know I'm looking at "true
>values", but I do know (hope) that the values are close enough with which
>to make evaluations.  Many times, we are evaluating several different
>schemes, and when they are all simulated in Radiance with the same kind of
>what I call "accuracy settings" -- you know, the myriad values used for
>rpict & rtrace -- I know for certain that I can say scheme-a is (insert
>criteria here, brightness, uniformity, whathaveyou) than scheme-b.  Often
>this is all that is needed, is for Radiance to guide us in a direction
>that can be explored more fully, either with Radiance or with physical
>mockups.
>
>But yes, the temptation is there, to treat the numbers generated by
>Radiance as THE numbers.  I have to fight it all the time; I submit a
>report showing 290 Lux on a plan, and people go "oh, this doesn't work, we
>can't have more than 270 Lux there."  That's my cue to ease into the
>discussion of how a mathematical model of the sky's luminance distribution
>is NOT /the sky's/ luminance distribution, etc.
>
>  
>
>>b) once a buliding has been built, has anyone gone back inside the
>>office they simulated and obtained measurements to compare with their
>>simulation results?
>>    
>>
>
>Many of the validation studies do just that.  My first big project
>simulated with Radiance is still under construction, but we have done
>similar tests with projects simulated with Lightscape and AGI and have
>been generally pleased with the outcome.  Typically, the light levels are
>not the same, but neither is the real space as compared to the simulation
>model.  But the values are all in the ballpark and the clients have been
>happy. Indeed, the last big museum project I did with Lightscape at my
>previous firm was astonishingly accurate, I believe the light levels on
>the day my boss measured them were within 5% of the caluclation.  But I
>also know a thing or two about luck.  I don't tell clients to expect 5%
>accuracy and neither should you.  Barring luck, the only way to get that
>close is to do a simulation with measured sky data (and take readings of
>the space under that same sky that you are measuring).  Right, John M.? 
>This of course requires a finished building, which sorta misses the point
>of the simulation!  But John's thesis work provides the basis for many of
>us using Radiance to achieve real restful sleep at night. =8-)
>
>  
>
>>c) what magnitude of error is acceptable for your work?
>>    
>>
>
>Ian Ashdown says it better than I can, in his (excellent) "Thinking
>Photometrically" coursenotes:
>
>"As for daylighting calculations, it is likely that Jongewaard (1993) is
>correct - the results are only as accurate as the accuracy of the input
>data. Done with care, it should be possible to obtain ?20 percent accuracy
>in the photometric predictions. However, this requires detailed knowledge
>and accurate modeling of both the indoor and outdoor environments. If this
>cannot be done, it may be advisable to walk softly and carry a calibrated
>photometer."
>
>  
>
>>d) I've come across two opposing views on the accuracy of lumenaire
>>descriptor files provided by manufacturers. One states that these can be
>>off quite a bit (I think I read that in the 'Rendering with Radiance'
>>book) and other authors strut how careful and accurate their simulation
>>is by using manufacturer-provided lumenaire descriptors.
>>    
>>
>
>Photometry data from the manufacturers is a far better way to describe the
>performance of a luminaire than most of the built-in tools in simulation
>programs.  But yes, there are still problems.  Primarily, the issue of
>far-field photometry.  Linear cove fixtures are trated as point sources
>when photometred, and misuse of these IES files in a simulation can lead
>to very inaccurate simulations.  Of course in Radiance you can increase
>the -ds value to at least help the situation, by taking that "point"
>distribution and sort-of arraying it along the fixture's axis.  As long as
>the distribution is the same along the length of the luminaire, and your
>-ds is suitably fine, you can get good results this way with
>manufacturer-supplied data.  The other big lighting simulation packages
>like AGI & Lumen Micro (and dear departed Lightscape) also allow you to do
>this, in their own ways.
>
>But sometimes the boast of accuracy simply because manufacturer-supplied
>photometry is being used should be a warning sign...  I recently received
>a mailer from one of the manufacturers of a popular lighting simulation
>program, featuring a rendering on it that was supposed to impress upon me
>how amazing and accurate the software is.  The thing is, the linear
>uplight pendants in the image were casting this ridiculous round spot on
>the ceiling, bearing no resemblance to the linear nature of the fixture --
>in fact, it looked a heck of a lot like the operator knew nothing about
>far-field photometry and the workarounds one must use when using
>photometry files based on that method.  And this was the featured
>rendering for the product's promotional literature -- worse, the rendering
>was created by one of the company's in-house tech support/training people.
>(!)
>
>I think there is a big naivete in the industry -- when you get beyond this
>group, who is obviously much more concerned with accuracy -- when it comes
>to these photometry files, many designers just download the files and plug
>them into their programs and hit the "do my job" button. In fact, these
>files are really just ASCII dumps of a test report, a test that used a
>certain lamp, with a certain lumen depreciation factor, which may be
>different than the one in your spec; other light loss factors need to be
>considered, the orientation may not even be what you expected.  So I guess
>it just goes back to garbage in, garbage out.  Those manufacturer-supplied
>files are only as good as the person integrating them into the simulation.
>
>- Rob Guglielmetti
>www.rumblestrip.org
>
>_______________________________________________
>Radiance-general mailing list
>Radiance-general@radiance-online.org
>http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>
>  
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://radiance-online.org/pipermail/radiance-general/attachments/20050120/faa20928/attachment.html
From MMoeck at engr.psu.edu  Thu Jan 20 19:55:49 2005
From: MMoeck at engr.psu.edu (Martin Moeck)
Date: Thu Jan 20 19:56:13 2005
Subject: [Radiance-general] Evaluation
Message-ID: <84F05BA9118BBD4A8FC6409808CE266C234138@ENGRMAIL2.engr.psu.edu>

For me, the most important determinant of accuracy (besides accurate input) is the number of interreflections, the ambient density and extensive use of mkillum. 5 ambient bounces is pretty much a must. This has been known ever since people started writing lighting programs. -ad =4096 can't hurt, either. 

Martin Moeck


-----Original Message-----
From:	Jack de Valpine [mailto:jedev@visarc.com]
Sent:	Thu 1/20/2005 1:27 PM
To:	Radiance general discussion
Cc:	
Subject:	Re: [Radiance-general] Evaluation
Hi Rob and Alexa,

I will follow-on Rob's excellent comments with a few thoughts of my own.

As  Rob has indicated the "accuracy" of a given simulation is highly 
dependent on the accuracy of the input data (geometry, materials and 
lighting). But I think that accuracy also has to be evaluated in terms 
of project scope/objectives. A simulation project early in the design 
process will necessarily have less resolved information to work with 
(i.e. decision have not been made on a lot of things), whereas a 
simulation later in the design process will potentially have a different 
degree of accuracy due to design decisions at that point.

Another thing to consider is what is being compared against, while the 
real world is what we ultimately try to measure against, studying design 
scenarios is another way to use a simulation tool such a radiance. In 
comparative studies, that is one design scenario to another, most things 
can be held as constant with a few things varying (geometry, materials, 
or lighting). The question I would be inclined to ask in this case is 
whether we can make reasonable judgments about design scenarios even 
though we may not be using the most accurate data (for a variety of 
reasons), for example if we are using a simple sky model (e.g. gensky) 
can we still make reasonable design judgments. I would suggest that even 
with unknowns or limited data performing a radiance based simulation is 
going to be far more useful from a design evaluation standpoint that 
using one of the multitude of shrink wrap renderers that are out in the 
market.

Best,

-Jack de Valpine


Rob Guglielmetti wrote:

>Hi Alexa,
>
>  
>
>>triggered by Jan's and Richard's problem of evaluating glare, I was
>>wondering how the architectual & lighting community (obviously I'm not a
>>member of it) uses RADIANCE.
>>    
>>
>
>OK, so I guess I'll go first.  But I'm not standing out here all by
>myself; I'd love to hear from the rest of you...
>
>  
>
>>a) how do you know that the results you come up with 'reflect the true
>>values' (I assume 'true' is +/- an error)? I agree the simulation
>>results are not completely out of order in terms of luminance, otherwise
>>people wouldn't use RADIANCE.
>>    
>>
>
>Good question.  Radiance itself has been the subject of many validation
>studies, and has been proven to be quite capable of coming up with the
>"true values" for most scenes, assuming valid, high-quality input. 
>There's the rub though; skies are variable, and every project brings with
>it new materials -- often materials unavailable for accurate sampling at
>the time of the simulation.  So, often I *don't* know I'm looking at "true
>values", but I do know (hope) that the values are close enough with which
>to make evaluations.  Many times, we are evaluating several different
>schemes, and when they are all simulated in Radiance with the same kind of
>what I call "accuracy settings" -- you know, the myriad values used for
>rpict & rtrace -- I know for certain that I can say scheme-a is (insert
>criteria here, brightness, uniformity, whathaveyou) than scheme-b.  Often
>this is all that is needed, is for Radiance to guide us in a direction
>that can be explored more fully, either with Radiance or with physical
>mockups.
>
>But yes, the temptation is there, to treat the numbers generated by
>Radiance as THE numbers.  I have to fight it all the time; I submit a
>report showing 290 Lux on a plan, and people go "oh, this doesn't work, we
>can't have more than 270 Lux there."  That's my cue to ease into the
>discussion of how a mathematical model of the sky's luminance distribution
>is NOT /the sky's/ luminance distribution, etc.
>
>  
>
>>b) once a buliding has been built, has anyone gone back inside the
>>office they simulated and obtained measurements to compare with their
>>simulation results?
>>    
>>
>
>Many of the validation studies do just that.  My first big project
>simulated with Radiance is still under construction, but we have done
>similar tests with projects simulated with Lightscape and AGI and have
>been generally pleased with the outcome.  Typically, the light levels are
>not the same, but neither is the real space as compared to the simulation
>model.  But the values are all in the ballpark and the clients have been
>happy. Indeed, the last big museum project I did with Lightscape at my
>previous firm was astonishingly accurate, I believe the light levels on
>the day my boss measured them were within 5% of the caluclation.  But I
>also know a thing or two about luck.  I don't tell clients to expect 5%
>accuracy and neither should you.  Barring luck, the only way to get that
>close is to do a simulation with measured sky data (and take readings of
>the space under that same sky that you are measuring).  Right, John M.? 
>This of course requires a finished building, which sorta misses the point
>of the simulation!  But John's thesis work provides the basis for many of
>us using Radiance to achieve real restful sleep at night. =8-)
>
>  
>
>>c) what magnitude of error is acceptable for your work?
>>    
>>
>
>Ian Ashdown says it better than I can, in his (excellent) "Thinking
>Photometrically" coursenotes:
>
>"As for daylighting calculations, it is likely that Jongewaard (1993) is
>correct - the results are only as accurate as the accuracy of the input
>data. Done with care, it should be possible to obtain ?20 percent accuracy
>in the photometric predictions. However, this requires detailed knowledge
>and accurate modeling of both the indoor and outdoor environments. If this
>cannot be done, it may be advisable to walk softly and carry a calibrated
>photometer."
>
>  
>
>>d) I've come across two opposing views on the accuracy of lumenaire
>>descriptor files provided by manufacturers. One states that these can be
>>off quite a bit (I think I read that in the 'Rendering with Radiance'
>>book) and other authors strut how careful and accurate their simulation
>>is by using manufacturer-provided lumenaire descriptors.
>>    
>>
>
>Photometry data from the manufacturers is a far better way to describe the
>performance of a luminaire than most of the built-in tools in simulation
>programs.  But yes, there are still problems.  Primarily, the issue of
>far-field photometry.  Linear cove fixtures are trated as point sources
>when photometred, and misuse of these IES files in a simulation can lead
>to very inaccurate simulations.  Of course in Radiance you can increase
>the -ds value to at least help the situation, by taking that "point"
>distribution and sort-of arraying it along the fixture's axis.  As long as
>the distribution is the same along the length of the luminaire, and your
>-ds is suitably fine, you can get good results this way with
>manufacturer-supplied data.  The other big lighting simulation packages
>like AGI & Lumen Micro (and dear departed Lightscape) also allow you to do
>this, in their own ways.
>
>But sometimes the boast of accuracy simply because manufacturer-supplied
>photometry is being used should be a warning sign...  I recently received
>a mailer from one of the manufacturers of a popular lighting simulation
>program, featuring a rendering on it that was supposed to impress upon me
>how amazing and accurate the software is.  The thing is, the linear
>uplight pendants in the image were casting this ridiculous round spot on
>the ceiling, bearing no resemblance to the linear nature of the fixture --
>in fact, it looked a heck of a lot like the operator knew nothing about
>far-field photometry and the workarounds one must use when using
>photometry files based on that method.  And this was the featured
>rendering for the product's promotional literature -- worse, the rendering
>was created by one of the company's in-house tech support/training people.
>(!)
>
>I think there is a big naivete in the industry -- when you get beyond this
>group, who is obviously much more concerned with accuracy -- when it comes
>to these photometry files, many designers just download the files and plug
>them into their programs and hit the "do my job" button. In fact, these
>files are really just ASCII dumps of a test report, a test that used a
>certain lamp, with a certain lumen depreciation factor, which may be
>different than the one in your spec; other light loss factors need to be
>considered, the orientation may not even be what you expected.  So I guess
>it just goes back to garbage in, garbage out.  Those manufacturer-supplied
>files are only as good as the person integrating them into the simulation.
>
>- Rob Guglielmetti
>www.rumblestrip.org
>
>_______________________________________________
>Radiance-general mailing list
>Radiance-general@radiance-online.org
>http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>
>  
>



-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/ms-tnef
Size: 7474 bytes
Desc: not available
Url : http://radiance-online.org/pipermail/radiance-general/attachments/20050120/79918fac/attachment.bin
From jedev at visarc.com  Thu Jan 20 19:57:03 2005
From: jedev at visarc.com (Jack de Valpine)
Date: Thu Jan 20 19:57:40 2005
Subject: [Radiance-general] super high res images
Message-ID: <41EFFEFF.2030805@visarc.com>

Hi all,

What wisdom do people have about generating absurdely (IMHO) large 
images (for example 22,000 x 22,000 at 3 times over sample, eg running 
at 76,000 x 76,000). The best thing that I can think of is to render the 
images as a seriese of sub views (tiles) with appropriate shift and 
lifts so the final image can be composed from the sub pieces. If the 
tiles are all pfilted (using the same exposure settings) to their final 
size prior to composing the final image will there be problems at the 
tile edges?

Thanks for any input/guidance,

-Jack de Valpine



From Christoph.Reinhart at nrc-cnrc.gc.ca  Thu Jan 20 19:59:25 2005
From: Christoph.Reinhart at nrc-cnrc.gc.ca (Reinhart, Christoph)
Date: Thu Jan 20 19:59:50 2005
Subject: [Radiance-general] Evaluation
Message-ID: <10C94843061E094A98C02EB77CFC32871149CF5E@nrcmrdex1d.imsb.nrc.ca>

 
Dear Alexa,

>>..., I was wondering how the architectual & lighting community (obviously
I'm not a member of it) uses RADIANCE.

Within the framewor of IEA Task 31, Daylighting Buildings in the 21st
century NRC carried out an online survey last year on "the current use of
daylight simulations during building design". You can download a copy of the
report from http://irc.nrc-cnrc.gc.ca/ie/light/survey. Key information from
the abstract are: 

"... Survey participants worked predominantly on offices and schools...
Tools' complexity and insufficient documentation were identified as
weaknesses of existing programs. Self-training was the most common training
method. Tool usage was significantly higher during design development than
during schematic design. Most survey participants used daylighting software
for parameter studies and presented the results to their clients as a basis
for design decisions. While daylight factor and interior illuminances were
the most common simulation outputs, shading type and control were the most
common design aspects influenced by daylighting analysis... While
participants used a total of 42 different daylight simulation programs, over
50% of program selections were for tools that use RADIANCE... " (In case you
need a more detailed version of the repor, let me know.)

>>Ian Ashdown says it better than I can, in his (excellent) "Thinking
Photometrically" coursenotes: "As for daylighting calculations, it is likely
that Jongewaard (1993) is correct - the results are only as accurate as the
accuracy of the input data. Done with care, it should be possible to obtain
?20 percent accuracy in the photometric predictions. However, this requires
detailed knowledge and accurate modeling of both the indoor and outdoor
environments. If this cannot be done, it may be advisable to walk softly and
carry a calibrated photometer."

I completely agree with this estimate. It reflects the results from John's
validation study on a fa?ade with a clear glazing and our validation study
for a facade with venetian blinds. Finally, I am doing a validation study
right now for a translucent fa?ade using "trans" and "transdata" (with a lot
of help from maitre Greg) and again I find comparable numbers. 

Christoph

From apian at pab-opto.de  Thu Jan 20 19:58:31 2005
From: apian at pab-opto.de (Peter Apian-Bennewitz)
Date: Thu Jan 20 20:00:03 2005
Subject: [Radiance-general] modifications dates in HEAD tar archive
In-Reply-To: <348B896C-6A54-11D9-9E74-000A95BB392A@gmail.com>
References: <348B896C-6A54-11D9-9E74-000A95BB392A@gmail.com>
Message-ID: <41EFFF57.1000905@pab-opto.de>

Greg Ward wrote:

> Hi Peter,
>
> Can you explain why all the file dates on the HEAD dump are zeroed out 
> (set to 1970)?
>
> greg@www:/www/radiance-online.org/htdocs/software/snapshots$ tar tzvf 
> radiance-HEAD.tgz|more
> drwxr-xr-x apian/cvs         0 1971-01-10 16:23:05 ray
> ...

Hi Greg,
thanks for pointing that out.
Turned out to be a well known bug in cpio version 2.5 (see
http://lists.gnu.org/archive/html/bug-cpio/2004-01/msg00007.html), a
version which is still shipped with the current Debian 'sarge' release.
The cpio archive packer is used to generate both the tar and the cpio
archives, as it has features which tar doesn't offer. The two other HEAD
archive formats, cpio and zip,  had been unaffected by this.
Since this afternoon, the archives are generated by a locally compiled
cpio version 2.6, which has the above bug fixed.

-Peter

-- 
pab-opto, Freiburg, Germany, http://www.pab-opto.de
[see web page to check digital email signature]





From jedev at visarc.com  Thu Jan 20 20:03:43 2005
From: jedev at visarc.com (Jack de Valpine)
Date: Thu Jan 20 20:04:08 2005
Subject: [Radiance-general] super high res images
In-Reply-To: <41EFFEFF.2030805@visarc.com>
References: <41EFFEFF.2030805@visarc.com>
Message-ID: <41F0008F.7010502@visarc.com>

Ack, that is pretty bad!

    22,000x22,000 at 3X or 66,000x66,000


Jack de Valpine wrote:

> Hi all,
>
> What wisdom do people have about generating absurdely (IMHO) large 
> images (for example 22,000 x 22,000 at 3 times over sample, eg running 
> at 76,000 x 76,000). The best thing that I can think of is to render 
> the images as a seriese of sub views (tiles) with appropriate shift 
> and lifts so the final image can be composed from the sub pieces. If 
> the tiles are all pfilted (using the same exposure settings) to their 
> final size prior to composing the final image will there be problems 
> at the tile edges?
>
> Thanks for any input/guidance,
>
> -Jack de Valpine
>
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>

-- 
#	John E. de Valpine
#	president
#
#	visarc incorporated
#	http://www.visarc.com
#
#	channeling technology for superior design and construction

-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://radiance-online.org/pipermail/radiance-general/attachments/20050120/9e0bc367/attachment.html
From gregoryjward at gmail.com  Thu Jan 20 20:06:53 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Thu Jan 20 20:07:55 2005
Subject: [Radiance-general] super high res images
In-Reply-To: <41EFFEFF.2030805@visarc.com>
References: <41EFFEFF.2030805@visarc.com>
Message-ID: <7281715D-6B16-11D9-9998-000A95BB392A@gmail.com>

Hi Jack,

Is there any reason you can't just render your large image straight 
off?  It will come out uncompressed, as the RLE algorithm in Radiance 
doesn't work for scanlines longer than 32K, but otherwise everything 
should work.  Are you getting some error along the way?  I just ran a 
test with pcompos, creating a 50K by 50K image.  It took 9 GBytes of 
disk space and took a few minutes to write out, but seemed OK 
otherwise.

Compositing tiles after filtering them separately will result in 
visible lines at the tile boundaries in some cases.

-Greg

> From: Jack de Valpine <jedev@visarc.com>
> Date: January 20, 2005 10:57:03 AM PST
>
> Hi all,
>
> What wisdom do people have about generating absurdely (IMHO) large 
> images (for example 22,000 x 22,000 at 3 times over sample, eg running 
> at 76,000 x 76,000). The best thing that I can think of is to render 
> the images as a seriese of sub views (tiles) with appropriate shift 
> and lifts so the final image can be composed from the sub pieces. If 
> the tiles are all pfilted (using the same exposure settings) to their 
> final size prior to composing the final image will there be problems 
> at the tile edges?
>
> Thanks for any input/guidance,
>
> -Jack de Valpine


From mstock at umich.edu  Thu Jan 20 20:10:57 2005
From: mstock at umich.edu (Mark Stock)
Date: Thu Jan 20 20:11:20 2005
Subject: [Radiance-general] super high res images
In-Reply-To: <41EFFEFF.2030805@visarc.com>
References: <41EFFEFF.2030805@visarc.com>
Message-ID: <Pine.LNX.4.61.0501201405310.6869@smith.gpcc.itd.umich.edu>

Jack,

I have only done images up to 28800x28800 (3 GB file), and 
always by using rpiece or the method that you suggest. 
Unfortunately, I have always done pfilt on the whole image, so I 
have no experience with pfilting beforehand.

I can imagine that you could cobble together a script that would 
read data from the adjacent images and attach a thin border 
around each piece, allowing you to pfilt first. Then you could 
trim the extra border off and assemble the full image later.

You've probably thought of this, though.

Mark

On Thu, 20 Jan 2005, Jack de Valpine wrote:

> Hi all,
>
> What wisdom do people have about generating absurdely (IMHO) large images 
> (for example 22,000 x 22,000 at 3 times over sample, eg running at 76,000 x 
> 76,000). The best thing that I can think of is to render the images as a 
> seriese of sub views (tiles) with appropriate shift and lifts so the final 
> image can be composed from the sub pieces. If the tiles are all pfilted 
> (using the same exposure settings) to their final size prior to composing the 
> final image will there be problems at the tile edges?
>
> Thanks for any input/guidance,
>
> -Jack de Valpine
>
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>
>

From jedev at visarc.com  Thu Jan 20 20:16:32 2005
From: jedev at visarc.com (Jack de Valpine)
Date: Thu Jan 20 20:16:56 2005
Subject: [Radiance-general] super high res images
In-Reply-To: <7281715D-6B16-11D9-9998-000A95BB392A@gmail.com>
References: <41EFFEFF.2030805@visarc.com>
	<7281715D-6B16-11D9-9998-000A95BB392A@gmail.com>
Message-ID: <41F00390.5030207@visarc.com>

Hey Greg,

I could probably do the large image straight off. But since I have never 
tried it, I am trying to consider contingencies.

So alternatively, tiles could be generated seperately, pcomposed 
together and then filtered down to avoid tile boundaries.

-Jack

Greg Ward wrote:

> Hi Jack,
>
> Is there any reason you can't just render your large image straight 
> off?  It will come out uncompressed, as the RLE algorithm in Radiance 
> doesn't work for scanlines longer than 32K, but otherwise everything 
> should work.  Are you getting some error along the way?  I just ran a 
> test with pcompos, creating a 50K by 50K image.  It took 9 GBytes of 
> disk space and took a few minutes to write out, but seemed OK otherwise.
>
> Compositing tiles after filtering them separately will result in 
> visible lines at the tile boundaries in some cases.
>
> -Greg
>
>> From: Jack de Valpine <jedev@visarc.com>
>> Date: January 20, 2005 10:57:03 AM PST
>>
>> Hi all,
>>
>> What wisdom do people have about generating absurdely (IMHO) large 
>> images (for example 22,000 x 22,000 at 3 times over sample, eg 
>> running at 76,000 x 76,000). The best thing that I can think of is to 
>> render the images as a seriese of sub views (tiles) with appropriate 
>> shift and lifts so the final image can be composed from the sub 
>> pieces. If the tiles are all pfilted (using the same exposure 
>> settings) to their final size prior to composing the final image will 
>> there be problems at the tile edges?
>>
>> Thanks for any input/guidance,
>>
>> -Jack de Valpine
>
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>

-- 
#	John E. de Valpine
#	president
#
#	visarc incorporated
#	http://www.visarc.com
#
#	channeling technology for superior design and construction



From jedev at visarc.com  Thu Jan 20 20:19:46 2005
From: jedev at visarc.com (Jack de Valpine)
Date: Thu Jan 20 20:20:11 2005
Subject: [Radiance-general] super high res images
In-Reply-To: <Pine.LNX.4.61.0501201405310.6869@smith.gpcc.itd.umich.edu>
References: <41EFFEFF.2030805@visarc.com>
	<Pine.LNX.4.61.0501201405310.6869@smith.gpcc.itd.umich.edu>
Message-ID: <41F00452.1080604@visarc.com>

Hey Mark,

Thanks for the follow-up. I figured you might have some insight. I too 
had thought of putting together a script as well to "trim" the borders.

Have you run your large images renderings distributed over multiple 
machines? How has this worked for you?

-Jack

Mark Stock wrote:

> Jack,
>
> I have only done images up to 28800x28800 (3 GB file), and always by 
> using rpiece or the method that you suggest. Unfortunately, I have 
> always done pfilt on the whole image, so I have no experience with 
> pfilting beforehand.
>
> I can imagine that you could cobble together a script that would read 
> data from the adjacent images and attach a thin border around each 
> piece, allowing you to pfilt first. Then you could trim the extra 
> border off and assemble the full image later.
>
> You've probably thought of this, though.
>
> Mark
>
> On Thu, 20 Jan 2005, Jack de Valpine wrote:
>
>> Hi all,
>>
>> What wisdom do people have about generating absurdely (IMHO) large 
>> images (for example 22,000 x 22,000 at 3 times over sample, eg 
>> running at 76,000 x 76,000). The best thing that I can think of is to 
>> render the images as a seriese of sub views (tiles) with appropriate 
>> shift and lifts so the final image can be composed from the sub 
>> pieces. If the tiles are all pfilted (using the same exposure 
>> settings) to their final size prior to composing the final image will 
>> there be problems at the tile edges?
>>
>> Thanks for any input/guidance,
>>
>> -Jack de Valpine
>>
>>
>>
>> _______________________________________________
>> Radiance-general mailing list
>> Radiance-general@radiance-online.org
>> http://www.radiance-online.org/mailman/listinfo/radiance-general
>>
>>
>>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>

-- 
#	John E. de Valpine
#	president
#
#	visarc incorporated
#	http://www.visarc.com
#
#	channeling technology for superior design and construction



From mstock at umich.edu  Thu Jan 20 20:27:34 2005
From: mstock at umich.edu (Mark Stock)
Date: Thu Jan 20 20:27:56 2005
Subject: [Radiance-general] super high res images
In-Reply-To: <41F00452.1080604@visarc.com>
References: <41EFFEFF.2030805@visarc.com>
	<Pine.LNX.4.61.0501201405310.6869@smith.gpcc.itd.umich.edu>
	<41F00452.1080604@visarc.com>
Message-ID: <Pine.LNX.4.61.0501201420520.6869@smith.gpcc.itd.umich.edu>

Jack,

I usually break them up into 5-10 subimages, each one the entire 
width, but a fraction of the height. I typically have 2 to 10 
machines that I can render on (depending on whether work needs 
the 8-proc Opteron cluster). I'll write the rpict commands by 
hand, and "nohup ... -t 600 ... &" each command. Keep in mind 
that I don't use a global ambient cache. I do the "-aa 0 -ab 
[low] -ad [low] -as 0" trick to prevent the RAM requirements from 
getting too high (and to avoid having to deal with NFS).

Then I just use rsync/scp to put the completed portions on one 
machine, and pfilt there. pfilt uses only a very little bit of 
memory, but it can be slow on massive images, especially with -r 
and decent downsampling. Compared to the rendering, though, I'll 
sit around and wait for the pfilt.

M

On Thu, 20 Jan 2005, Jack de Valpine wrote:

> Hey Mark,
>
> Thanks for the follow-up. I figured you might have some insight. I too had 
> thought of putting together a script as well to "trim" the borders.
>
> Have you run your large images renderings distributed over multiple machines? 
> How has this worked for you?
>
> -Jack
>
> Mark Stock wrote:
>
>> Jack,
>> 
>> I have only done images up to 28800x28800 (3 GB file), and always by using 
>> rpiece or the method that you suggest. Unfortunately, I have always done 
>> pfilt on the whole image, so I have no experience with pfilting beforehand.
>> 
>> I can imagine that you could cobble together a script that would read data 
>> from the adjacent images and attach a thin border around each piece, 
>> allowing you to pfilt first. Then you could trim the extra border off and 
>> assemble the full image later.
>> 
>> You've probably thought of this, though.
>> 
>> Mark
>> 
>> On Thu, 20 Jan 2005, Jack de Valpine wrote:
>> 
>>> Hi all,
>>> 
>>> What wisdom do people have about generating absurdely (IMHO) large images 
>>> (for example 22,000 x 22,000 at 3 times over sample, eg running at 76,000 
>>> x 76,000). The best thing that I can think of is to render the images as a 
>>> seriese of sub views (tiles) with appropriate shift and lifts so the final 
>>> image can be composed from the sub pieces. If the tiles are all pfilted 
>>> (using the same exposure settings) to their final size prior to composing 
>>> the final image will there be problems at the tile edges?
>>> 
>>> Thanks for any input/guidance,
>>> 
>>> -Jack de Valpine
>>> 
>>> 
>>> 
>>> _______________________________________________
>>> Radiance-general mailing list
>>> Radiance-general@radiance-online.org
>>> http://www.radiance-online.org/mailman/listinfo/radiance-general
>>> 
>>> 
>>> 
>> 
>> _______________________________________________
>> Radiance-general mailing list
>> Radiance-general@radiance-online.org
>> http://www.radiance-online.org/mailman/listinfo/radiance-general
>> 
>> 
>
> -- 
> #	John E. de Valpine
> #	president
> #
> #	visarc incorporated
> #	http://www.visarc.com
> #
> #	channeling technology for superior design and construction
>
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>
>

From despina_m81 at hotmail.com  Fri Jan 21 13:56:11 2005
From: despina_m81 at hotmail.com (Despina Michael)
Date: Fri Jan 21 14:28:31 2005
Subject: [Radiance-general] softwares to compute light sources from hdr image
Message-ID: <BAY22-DAV16A7C6BBEAEE2FDACAAAB790820@phx.gbl>

Hi all,

I am not sure if this is the correct forum to ask for something like that.. or this forum only deals with radiance software... but i decided to post my question in case that you can help me.

I would like to know what softwares are there, which can found out/compute light sources (and probaply their direction) from hdr image.  Are there any other softwares doing this? If they are many, is there anywhere that I can find some information for their differences?

Does Radiance compute light sources from hdr images? 
The only software I know doing this is lightgen, a plugin for hdrshop.


Thanks,
Despina

p.s. By the way, is there a known problem with hdrgen (for linux) alignment algorithm? I captured perfectly aligned photos (using remote capturing - connect camera with computer) and using alignement with hdrgen (not use of -a option) results very bad hdr image. Althought when alignement was disable, the result was perfect!





-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://radiance-online.org/pipermail/radiance-general/attachments/20050121/f02f1b7f/attachment.htm
From a.i.ruppertsberg at Bradford.ac.uk  Fri Jan 21 17:09:17 2005
From: a.i.ruppertsberg at Bradford.ac.uk (Alexa I. Ruppertsberg)
Date: Fri Jan 21 17:09:57 2005
Subject: [Radiance-general] Evaluation
In-Reply-To: <38932.209.212.87.250.1106242290.squirrel@209.212.87.250>
Message-ID: <41F1292D.9070808@bradford.ac.uk>

Hi Rob, Jack, Martin and Christoph,

thanks very much for your replies. Together with Christoph's survey I 
have now a better understanding of the usage. I would term this more 
like a 'relative' use: how do two (or more) design solutions compare to 
each other. A will give you more light on the desk than B, e.g.

The other emerging topic seems to me that of 'nice' pictures for the 
clients. Once you have a tool with which you can simulate the building 
and can produce a picture, there is the danger that clients 
'over'-interprete the image ('this is how it's going to look like'). Or 
put the other way, the image they can see either on a CRT or in a 
printed version does not reflect truely what the building is probably 
going to look because of the limited dynamic range of the medium (CRT or 
paper).

> Good question.  Radiance itself has been the subject of many validation
> studies, 
May I challenge this? Validation studies I am aware of are (if anyone 
knows of more then please tell me):

Grynberg, A.,?Validation of Radiance?, LBID 1575, LBL Technical 
Information Department, Lawrence Berkeley National Laboratory, Berkeley, 
California, July 1989.
This technical report proved to be inaccessible for me. If anyone has a 
copy, I would be more than happy to read it.

Khodulev, A. and E. Kopylov, ?Physically accurate lighting simulation in 
computer graphics software?, 6. International conference on Computer 
Graphics and Visualization, St. Petersburg, Russia, July 1-5, 1996.
http://www.keldysh.ru/pages/cgraph/articles/pals/
This is a website and describes a white-box scenario, i.e a scenario for 
which you can actually calculate the solution analytically. But how much 
is this a valid scenario for complex illumination situations?
I have my own opinion about website-only references.

Houser, K.W., D.K. Tiller, and I.C. Pasini, ?Toward the accuracy of 
lighting simulations in physically based computer graphics software?, 
Journal of the Illuminating Engineering Society, 28(1), Winter 1999, 
117-129.
the conclusion is that RADIANCE does not do what it says on the package 
(I have my own opinion about this paper)

Ubbelohde, M.S. and Humann, C. ?Comparative evaluation of four 
daylighting software programs?, 1998 ACEEE Summer Study on Energy 
Efficiency in Buildings Proceedings, American Council for an 
Energy-Efficient Economy, 1998.
I asked the author to send me a copy of the paper about 18 months ago 
and I am still waiting.


Mardaljevic, J., ?Validation of a lighting simulation program under real 
sky conditions?, Lighting research and Technology, 27(4), 1995, 181-188.
That is what I call validation: comparison of simulation output and 
measurements from the real environment.
In my personal opinion there is no validation study apart from John 
Mardaljevic's work.

Christoph, I saw your 2001 paper with Walkenhorst in the reference 
section of the survey. Is that a validation?

Rushmeier,Ward,Piatko,Sanders,Rust, 1995,Comparing Real and Synthetic 
Images: Some Ideas About Metrics, 6th Eurographics Workshop on Rendering.
this paper appears on the Radiance site and may I cite from the paper 
(p. 3, section 1.2): 'There are clearly very high levels of uncertainty 
in the measurements made in this experiment.' Now, that paper didn't set 
out as a validation for Radiance, but tried to do soemthing else, so in 
a way it's not an appropriate reference for a validation study, but it 
could have been, if measurements would have been taken more carefully 
and compared to the real room.

Can you please tell me whose work I'm missing here? Or do we mean 
different things when we talk about 'validaton'?
I hope I haven't upset anyone, because that's not what I intended to do. 
  I am just in the pursuit of evidence and if it is out there, then 
please tell me.

>>c) what magnitude of error is acceptable for your work?
I understand that the 'unpredictability' of the sky is the biggest 
problem basically.


Thanks again,

Alexa

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Dr. Alexa I. Ruppertsberg
Department of Optometry
University of Bradford
Bradford
BD7 1DP
UK
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


From MMoeck at engr.psu.edu  Fri Jan 21 17:33:15 2005
From: MMoeck at engr.psu.edu (Martin Moeck)
Date: Fri Jan 21 17:33:43 2005
Subject: [Radiance-general] Evaluation
Message-ID: <84F05BA9118BBD4A8FC6409808CE266C23413B@ENGRMAIL2.engr.psu.edu>

A while ago, I compared radiance with agi32 for a very simple room with a PAR lamp on the ceiling.  The results are at 

www.personal.psu.edu/mum13/comparison_Radiance_AGI32.pdf
and
www.personal.psu.edu/mum13/agi_rad.pdf

The errors for 1 and 2 ambient bounces, as shown in www.personal.psu.edu/mum13/agi_rad.pdf,  are somewhat significant and will be worse for complex environments. 

It is best to do validations where the results are known a priori. Otherwise, you have too many voltage fluctuations, contractor changes and errors, reflectances are off, locations are off, material BRDFs are not known, etc. 

Martin Moeck




-----Original Message-----
From:	Alexa I. Ruppertsberg [mailto:a.i.ruppertsberg@Bradford.ac.uk]
Sent:	Fri 1/21/2005 11:09 AM
To:	Radiance general discussion
Cc:	
Subject:	Re: [Radiance-general] Evaluation
Hi Rob, Jack, Martin and Christoph,

thanks very much for your replies. Together with Christoph's survey I 
have now a better understanding of the usage. I would term this more 
like a 'relative' use: how do two (or more) design solutions compare to 
each other. A will give you more light on the desk than B, e.g.

The other emerging topic seems to me that of 'nice' pictures for the 
clients. Once you have a tool with which you can simulate the building 
and can produce a picture, there is the danger that clients 
'over'-interprete the image ('this is how it's going to look like'). Or 
put the other way, the image they can see either on a CRT or in a 
printed version does not reflect truely what the building is probably 
going to look because of the limited dynamic range of the medium (CRT or 
paper).

> Good question.  Radiance itself has been the subject of many validation
> studies, 
May I challenge this? Validation studies I am aware of are (if anyone 
knows of more then please tell me):

Grynberg, A.,?Validation of Radiance?, LBID 1575, LBL Technical 
Information Department, Lawrence Berkeley National Laboratory, Berkeley, 
California, July 1989.
This technical report proved to be inaccessible for me. If anyone has a 
copy, I would be more than happy to read it.

Khodulev, A. and E. Kopylov, ?Physically accurate lighting simulation in 
computer graphics software?, 6. International conference on Computer 
Graphics and Visualization, St. Petersburg, Russia, July 1-5, 1996.
http://www.keldysh.ru/pages/cgraph/articles/pals/
This is a website and describes a white-box scenario, i.e a scenario for 
which you can actually calculate the solution analytically. But how much 
is this a valid scenario for complex illumination situations?
I have my own opinion about website-only references.

Houser, K.W., D.K. Tiller, and I.C. Pasini, ?Toward the accuracy of 
lighting simulations in physically based computer graphics software?, 
Journal of the Illuminating Engineering Society, 28(1), Winter 1999, 
117-129.
the conclusion is that RADIANCE does not do what it says on the package 
(I have my own opinion about this paper)

Ubbelohde, M.S. and Humann, C. ?Comparative evaluation of four 
daylighting software programs?, 1998 ACEEE Summer Study on Energy 
Efficiency in Buildings Proceedings, American Council for an 
Energy-Efficient Economy, 1998.
I asked the author to send me a copy of the paper about 18 months ago 
and I am still waiting.


Mardaljevic, J., ?Validation of a lighting simulation program under real 
sky conditions?, Lighting research and Technology, 27(4), 1995, 181-188.
That is what I call validation: comparison of simulation output and 
measurements from the real environment.
In my personal opinion there is no validation study apart from John 
Mardaljevic's work.

Christoph, I saw your 2001 paper with Walkenhorst in the reference 
section of the survey. Is that a validation?

Rushmeier,Ward,Piatko,Sanders,Rust, 1995,Comparing Real and Synthetic 
Images: Some Ideas About Metrics, 6th Eurographics Workshop on Rendering.
this paper appears on the Radiance site and may I cite from the paper 
(p. 3, section 1.2): 'There are clearly very high levels of uncertainty 
in the measurements made in this experiment.' Now, that paper didn't set 
out as a validation for Radiance, but tried to do soemthing else, so in 
a way it's not an appropriate reference for a validation study, but it 
could have been, if measurements would have been taken more carefully 
and compared to the real room.

Can you please tell me whose work I'm missing here? Or do we mean 
different things when we talk about 'validaton'?
I hope I haven't upset anyone, because that's not what I intended to do. 
  I am just in the pursuit of evidence and if it is out there, then 
please tell me.

>>c) what magnitude of error is acceptable for your work?
I understand that the 'unpredictability' of the sky is the biggest 
problem basically.


Thanks again,

Alexa

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Dr. Alexa I. Ruppertsberg
Department of Optometry
University of Bradford
Bradford
BD7 1DP
UK
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


_______________________________________________
Radiance-general mailing list
Radiance-general@radiance-online.org
http://www.radiance-online.org/mailman/listinfo/radiance-general



-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/ms-tnef
Size: 5578 bytes
Desc: not available
Url : http://radiance-online.org/pipermail/radiance-general/attachments/20050121/5655668f/attachment.bin
From mm at waterslade.com  Fri Jan 21 18:12:39 2005
From: mm at waterslade.com (Malcolm Macpherson)
Date: Fri Jan 21 18:10:01 2005
Subject: [Radiance-general] One (or more) window behind another
Message-ID: <17123946800046@webserver.waterslade.com>

Skipped content of type multipart/alternative-------------- next part --------------
Waterslade Ltd
5 Thames Street, Eynsham, Oxford OX29 4HF
w:http://www.waterslade.com
t:01865 881882
f:01865 881891

For the latest aerial photography of central London, please visit http://www.3dlondon.co.uk
From cbauer- at t-online.de  Sat Jan 22 03:29:48 2005
From: cbauer- at t-online.de (Carsten Bauer)
Date: Sat Jan 22 02:19:31 2005
Subject: [Radiance-general] Evaluation
References: <41F1292D.9070808@bradford.ac.uk>
Message-ID: <41F1BA9C.1060904@t-online.de>

Alexa I. Ruppertsberg wrote:

> I hope I haven't upset anyone, because that's not what I intended to do. 
>  I am just in the pursuit of evidence and if it is out there, then 
> please tell me.

No problem, nothing's easier than that :-)

You've already mentioned some quite interesting keywords: simulation, 
relativity, interpretation, and, of course, 'nice images'. One could add 
the term 'abstraction'. I'm sure you've already thought about that, too. 
Probably there's not one evidence, but many, and each one depends on the 
situation and the correct mixture of the above terms. (Isn't that concrete?)

I could write more about those nice images, but this is not an artists 
forum...

One general interesting point about Radiance is that it is often applied 
in some sort of 'interface' position, means where science/technology 
meets architecture, ecology, ergonomics, PR & marketing, design and all 
the rest from every day life. And its important to be aware when a 
border is crossed, and not to stretch concepts from one world too far 
into the other. I can understand your concerns that this topic might 
get lost sometimes, on the consultants side as well as on the clients 
side. On may apply the well known cynical saying from politics: every 
client gets the consultant he deserves..


-cb







From gregoryjward at gmail.com  Sat Jan 22 02:46:59 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Sat Jan 22 02:48:05 2005
Subject: [Radiance-general] One (or more) window behind another
In-Reply-To: <17123946800046@webserver.waterslade.com>
References: <17123946800046@webserver.waterslade.com>
Message-ID: <8148247B-6C17-11D9-96DD-000A95BB392A@gmail.com>

Hi Malcolm,

In general, you can arrange your input surfaces for mkillum any way you 
think will benefit your calculation.  You don't have to worry about 
what happens when one window sees another, but if you want to know what 
happens in such cases, check out section 13.1.3 in "Rendering with 
Radiance" starting on page 572.

If you still have questions, maybe you could be a little more specific 
about your concerns.
-Greg

> From: "Malcolm Macpherson" <mm@waterslade.com>
> Date: January 21, 2005 9:12:39 AM PST
>
Hi,

?I am calculating Average Daylight Factors by sampling the illuminance 
on a grid within the room.

I frequently come across situations where there are two completely 
separate layers of glazing serving a room.? One example is for a room 
looking into an?atrium with a glazed roof.?There is one layer of 
glazing in the window in the room, and a second in the roof.? I am not 
sure how best to treat this.???Normally I would use mkillum on the room 
glazing, and allow daylight to penetrate through the atrium roof.? Does 
anyone know if there is possibly a 2 stage procedure so that the atrium 
roof is treated as a secondary source as well as the room window?

Another example, this time with 3 layers of separate glazing, is 
where?there is a corridor between the?room in the above example and the 
glazed atrium, and the corridor has windows looking into the atrium.

I would be glad of anyone's thoughts on this.

Malcolm


From gregoryjward at gmail.com  Sat Jan 22 03:04:52 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Sat Jan 22 03:05:56 2005
Subject: [Radiance-general] Evaluation
In-Reply-To: <41F1292D.9070808@bradford.ac.uk>
References: <41F1292D.9070808@bradford.ac.uk>
Message-ID: <01111C49-6C1A-11D9-96DD-000A95BB392A@gmail.com>

Hi Alexa,

I don't really feel I can add that much to this discussion, as I think 
validation of software by its author is also something to view with 
suspicion, but I agree with you in general that good validation studies 
are very difficult to find.  I just wanted to say something about the 
following reference.

> Grynberg, A.,?Validation of Radiance?, LBID 1575, LBL Technical 
> Information Department, Lawrence Berkeley National Laboratory, 
> Berkeley, California, July 1989.
> This technical report proved to be inaccessible for me. If anyone has 
> a copy, I would be more than happy to read it.

I have a copy of this report, which was prepared by Anat Grynberg 
during her second summer internship at LBNL.  However, I do not think 
it is particularly useful as a numerical validation.  It focuses mostly 
on a "qualitative study" to demonstrate that Radiance can model scenes 
with a realistic level of detail.  Much of the work surrounded the 
creation of the well-known LBNL conference room model.  It also covers 
the initial design of the imaging gonioreflectometer, but does not 
contain much in the way of quantitative comparisons.  Anat did perform 
a quantitative comparison based on a previous study of Superlite, 
comparing it to measurements in a skydome the previous summer, but this 
work was never published.  It is out of date at this point, anyway, as 
the version of Radiance she was using lacked some of the better 
techniques it has now for handling large area sources.

However, if you are interested in seeing these early studies, I can dig 
them up and copy them with some effort.  The color images of course 
will not come out, but you can get a flavor, at least.  The more recent 
studies are much better.  These were undertaken mainly because nothing 
else existed at the time.

-Greg

From njlander at yahoo.com.au  Mon Jan 24 01:52:32 2005
From: njlander at yahoo.com.au (Nicholas Lander)
Date: Mon Jan 24 01:53:46 2005
Subject: [Radiance-general] glass reflectance
Message-ID: <20050124005233.49729.qmail@web54609.mail.yahoo.com>

Hi,

I'm working on a project with glazing options that
have different internal reflectances.  What's the best
way to model this?  I'm thinking trans with 100%
specular transmission and changing the specular
reflectance.

Any ideas?
(I'm cross-posting this on Radiance and DR sites.)

Cheers

Nick L


	
	
		
___________________________________________________________ 
ALL-NEW Yahoo! Messenger - all new features - even more fun! http://uk.messenger.yahoo.com

From gregoryjward at gmail.com  Tue Jan 25 08:39:42 2005
From: gregoryjward at gmail.com (Gregory J. Ward)
Date: Tue Jan 25 08:40:16 2005
Subject: [Radiance-general] glass reflectance
In-Reply-To: <20050124005233.49729.qmail@web54609.mail.yahoo.com>
References: <20050124005233.49729.qmail@web54609.mail.yahoo.com>
Message-ID: <470C1D75-6EA4-11D9-B6F3-00306540F848@gmail.com>

Hi Nick,

I was waiting for someone else to answer your query, but I guess it's  
not happening.

The best option is probably the new "glaze" script in Radiance 3.6, but  
there's no man page and you'll have to dig into the C-shell source a  
bit to see how to specify your own material properties.

The next option is to do as you suggest and vary the specularity of a  
trans primitive.  The downside to this (other than figuring out what  
the heck to set the parameters to) is it won't account for variations  
in reflectance with incident angle.  For this, you would have to use  
the glaze script if you have something other than a piece of clear or  
absorbing glass.

-Greg

P.S.  If you are stuck with Desktop Radiance, you're out of luck with  
regards to glaze.  But, you could use Francesco Anselmo's Cygwin  
version:

http://www.dream.unipa.it/dream/pub/dot/anselmo/radiance/cygwin/ 
radiance_cygwin_3R6P1.tar.gz

> From: Nicholas Lander <njlander@yahoo.com.au>
> Date: January 23, 2005 4:52:32 PM PST
>
> Hi,
>
> I'm working on a project with glazing options that
> have different internal reflectances.  What's the best
> way to model this?  I'm thinking trans with 100%
> specular transmission and changing the specular
> reflectance.
>
> Any ideas?
> (I'm cross-posting this on Radiance and DR sites.)
>
> Cheers
>
> Nick L


From chriskl at familyhealth.com.au  Tue Jan 25 18:15:54 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Tue Jan 25 18:17:08 2005
Subject: [Radiance-general] rcalc and newlines
Message-ID: <41F67ECA.7080002@familyhealth.com.au>

Hi,

How do I get rcalc to NOT output a newline at the end of its output. 
I'm using rcalc to compute a single number, and the newline is annoying.

If you can't get rcalc to do it, what is the command line voodoo 
required to strip it?

Thanks,

Chris

From chriskl at familyhealth.com.au  Tue Jan 25 18:17:55 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Tue Jan 25 18:19:08 2005
Subject: [Radiance-general] Radiance Wiki
Message-ID: <41F67F43.1010101@familyhealth.com.au>

Hi Everyone,

You may or may not know, but Mike Kruger and myself have started up a 
Radiance Wiki.  Please fill it full of all your useful information :)

It will stay around as a Wiki, and any useful and well formatted 
information that ends up in it may make its way into the official docs.

http://www.radiance-wiki.org/

Cheers,

Chris

From Giulio.Antonutto at arup.com  Tue Jan 25 18:33:59 2005
From: Giulio.Antonutto at arup.com (Giulio Antonutto)
Date: Tue Jan 25 18:34:25 2005
Subject: [Radiance-general] rcalc and newlines
Message-ID: <DC0CAEEA090E984C911D3B85B16C3F900302C3E0@l-gnts05>

Christopher,
I would do this way by means of 'echo -n' :

---------------------------
#!/bin/csh -f
set a = `rcalc .....`
echo -n $a > output
----------------------------

Not sure it's what you are looking for..
BTW I hope it helps somehow...
cheers,
giulio

-----Original Message-----
From: radiance-general-bounces@radiance-online.org
[mailto:radiance-general-bounces@radiance-online.org]On Behalf Of
Christopher Kings-Lynne
Sent: 25 January 2005 17:16
To: radiance-general
Subject: [Radiance-general] rcalc and newlines


Hi,

How do I get rcalc to NOT output a newline at the end of its output. 
I'm using rcalc to compute a single number, and the newline is annoying.

If you can't get rcalc to do it, what is the command line voodoo 
required to strip it?

Thanks,

Chris

_______________________________________________
Radiance-general mailing list
Radiance-general@radiance-online.org
http://www.radiance-online.org/mailman/listinfo/radiance-general

___________________________________________________________________
Electronic mail messages entering and leaving Arup business
systems are scanned for acceptability of content and viruses.

From gregoryjward at gmail.com  Tue Jan 25 18:43:09 2005
From: gregoryjward at gmail.com (Gregory J. Ward)
Date: Tue Jan 25 18:43:43 2005
Subject: [Radiance-general] rcalc and newlines
In-Reply-To: <41F67ECA.7080002@familyhealth.com.au>
References: <41F67ECA.7080002@familyhealth.com.au>
Message-ID: <940A4126-6EF8-11D9-89AE-00306540F848@gmail.com>

Use the rcalc -l and -o option together.  For example:

	echo 17 | rcalc -l -o '${$1*2}'

will print out 34 without a newline.

-Greg

> From: Christopher Kings-Lynne <chriskl@familyhealth.com.au>
> Date: January 25, 2005 9:15:54 AM PST
>
> Hi,
>
> How do I get rcalc to NOT output a newline at the end of its output. 
> I'm using rcalc to compute a single number, and the newline is 
> annoying.
>
> If you can't get rcalc to do it, what is the command line voodoo 
> required to strip it?
>
> Thanks,
>
> Chris


From jelle.feringa at ezct.net  Tue Jan 25 22:34:07 2005
From: jelle.feringa at ezct.net (Jelle Feringa // EZCT / Paris)
Date: Tue Jan 25 22:30:58 2005
Subject: [Radiance-general] graphing radiance raytrace paths
Message-ID: <20050125213028.F01E51C00186@mwinf0412.wanadoo.fr>

Hi,
 
What I would love to do is to produce a graph depicting the rays a radiance
rendering actually consists of, moving from the camera back to the light
source.
What would be an appropriate way of doing so? Would a radiance holodeck file
do the trick, since from what I understood, its storing the actual traced
rays in a file format.
The other question would be how many rays such a graph should contain,
probably a 100k is more than sufficient for such a graph, while an actual
radiance render would consist of many more. Looking forward hearing your
suggestions!
 
Cheers,
 
Jelle.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: http://radiance-online.org/pipermail/radiance-general/attachments/20050125/ae76605f/attachment.html
From gregoryjward at gmail.com  Tue Jan 25 22:35:42 2005
From: gregoryjward at gmail.com (Gregory J. Ward)
Date: Tue Jan 25 22:36:11 2005
Subject: [Radiance-general] Re: graphing radiance raytrace paths
In-Reply-To: <20050125213028.F01E51C00186@mwinf0412.wanadoo.fr>
References: <20050125213028.F01E51C00186@mwinf0412.wanadoo.fr>
Message-ID: <106BE589-6F19-11D9-A2AF-00306540F848@gmail.com>

Hi Jelle,

Check out the "xshowtrace" command.  It uses rtrace on an image to 
superimpose ray paths you select.  It doesn't show a side-view with the 
camera in the image, unfortunately.  There's an exercise for the 
reader!

-Greg

> From: "Jelle Feringa // EZCT / Paris" <jelle.feringa@ezct.net>
> Date: January 25, 2005 1:34:07 PM PST
>
Hi,

What I would love to do is to produce a graph depicting the rays a 
radiance rendering actually consists of, moving from the camera back to 
the light source.

What would be an appropriate way of doing so? Would a radiance holodeck 
file do the trick, since from what I understood, its storing the actual 
traced rays in a file format.

The other question would be how many rays such a graph should contain, 
probably a 100k is more than sufficient for such a graph, while an 
actual radiance render would consist of many more. Looking forward 
hearing your suggestions!

?Cheers,

Jelle.


From kd462 at nyu.edu  Tue Jan 25 23:07:28 2005
From: kd462 at nyu.edu (Katja Doerschner)
Date: Tue Jan 25 23:07:53 2005
Subject: [Radiance-general] converting floating point to RADIANCE HDR format
Message-ID: <14e731f14e0bae.14e0bae14e731f@nyu.edu>

Hi,
 I have an array of M x N x 3 (as in RGB) single precision floating 
point numbers,
 and would like to save it as a RADIANCE hdr format which uses 32 bits 
per pixel,
 i.e. R G B have each 8 bits and they all share one exponent which is 
also 8 bits.( If I understand this correctly)
 I would like to know how exactly the format works. How does one pick 
the common exponent? How does one deal with extrem intensity values in 
the different color channels? 
I am writing the program in C.
 Can anyone help?

THANKS  

From gregoryjward at gmail.com  Tue Jan 25 23:32:49 2005
From: gregoryjward at gmail.com (Gregory J. Ward)
Date: Tue Jan 25 23:33:15 2005
Subject: [Radiance-general] converting floating point to RADIANCE HDR
	format
In-Reply-To: <14e731f14e0bae.14e0bae14e731f@nyu.edu>
References: <14e731f14e0bae.14e0bae14e731f@nyu.edu>
Message-ID: <0AE22115-6F21-11D9-901A-00306540F848@gmail.com>

Hi Katja,

Why don't you just borrow the OpenSource C code in the Radiance 
distribution?  No need to roll your own, really.  The Radiance picture 
format is well-described in:

	http://radsite.lbl.gov/radiance/refer/filefmts.pdf

The code you want is in the ray/src/common directory in the 
distribution, which may be downloaded from:

	http://www.radiance-online.org/software
or:
	http://radsite.lbl.gov/radiance/download.html

There is also a program that will convert from floating-point raw files 
to and from Radiance pictures, called pvalue.  It's use is a little 
obscure, though.  It's described in the man pages section on radsite:

	http://radsite.lbl.gov/radiance/man_html/whatis.html

I assume you read the article in Graphics Gems II, already?

-Greg

> From: Katja Doerschner <kd462@nyu.edu>
> Date: January 25, 2005 2:07:28 PM PST
>
> Hi,
>  I have an array of M x N x 3 (as in RGB) single precision floating
> point numbers,
>  and would like to save it as a RADIANCE hdr format which uses 32 bits
> per pixel,
>  i.e. R G B have each 8 bits and they all share one exponent which is
> also 8 bits.( If I understand this correctly)
>  I would like to know how exactly the format works. How does one pick
> the common exponent? How does one deal with extrem intensity values in
> the different color channels?
> I am writing the program in C.
>  Can anyone help?
>
> THANKS


From kd462 at nyu.edu  Tue Jan 25 23:59:31 2005
From: kd462 at nyu.edu (Katja Doerschner)
Date: Tue Jan 25 23:59:58 2005
Subject: [Radiance-general] converting floating point to RADIANCE
	HDR	format
Message-ID: <150126415070bb.15070bb1501264@nyu.edu>

Thank you very much for the fast reply & comprehensive information!
I believe I have everything I need now ;-).

katja


----- Original Message -----
From: "Gregory J. Ward" <gregoryjward@gmail.com>
Date: Tuesday, January 25, 2005 5:32 pm
Subject: Re: [Radiance-general] converting floating point to RADIANCE 
HDR	format

> Hi Katja,
> 
> Why don't you just borrow the OpenSource C code in the Radiance 
> distribution?  No need to roll your own, really.  The Radiance 
> picture 
> format is well-described in:
> 
> 	http://radsite.lbl.gov/radiance/refer/filefmts.pdf
> 
> The code you want is in the ray/src/common directory in the 
> distribution, which may be downloaded from:
> 
> 	http://www.radiance-online.org/software
> or:
> 	http://radsite.lbl.gov/radiance/download.html
> 
> There is also a program that will convert from floating-point raw 
> files 
> to and from Radiance pictures, called pvalue.  It's use is a 
> little 
> obscure, though.  It's described in the man pages section on radsite:
> 
> 	http://radsite.lbl.gov/radiance/man_html/whatis.html
> 
> I assume you read the article in Graphics Gems II, already?
> 
> -Greg
> 
> > From: Katja Doerschner <kd462@nyu.edu>
> > Date: January 25, 2005 2:07:28 PM PST
> >
> > Hi,
> >  I have an array of M x N x 3 (as in RGB) single precision floating
> > point numbers,
> >  and would like to save it as a RADIANCE hdr format which uses 
> 32 bits
> > per pixel,
> >  i.e. R G B have each 8 bits and they all share one exponent 
> which is
> > also 8 bits.( If I understand this correctly)
> >  I would like to know how exactly the format works. How does one 
> pick> the common exponent? How does one deal with extrem intensity 
> values in
> > the different color channels?
> > I am writing the program in C.
> >  Can anyone help?
> >
> > THANKS
> 
> 
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
> 

From jelle.feringa at ezct.net  Wed Jan 26 13:32:11 2005
From: jelle.feringa at ezct.net (Jelle Feringa // EZCT / Paris)
Date: Wed Jan 26 13:28:45 2005
Subject: [Radiance-general] Re: graphing radiance raytrace paths 
Message-ID: <20050126122817.D860F1C00097@mwinf1202.wanadoo.fr>

Hi Greg,

Wow! Thanks for pointing that out to me, that seems quite close to what I
intend to do. I think 'graph' wasn't necessarily the appropriate term, since
often it implies 2d. In fact I'm looking for a way to capture the rays
traced in a rendering to a 3d (polygon) file, preferable colored according
to their illumination value. Maybe you've seen the Maya 6 feauture where
your able to visualize the global illumination cache in coloured points. (if
you haven't it might be interesting that I upload an image to my server)
I'd like to do something similar like that, but its important to trace the
whole path, right from the camera, all the way back to the light source it
emitted (sure, a lot of them will end up at the wall, but the more rays can
be traced to the source, the better) 

As I understood from the man pages, piping ximage (t) to rtrace is close to
what xshowtrace does, except that its output is numbers instead of graphic
lines superimposed on the rendering (by the way, there's no way to control
the interval of xshowtrace -s is there? Awesome soft! Thanks so much!)

So here's what I tried using this approach:

ximage someRendering.pic rtrace -ab 5 -oodLpnsm -h -x 1 -i   someOct.oct >
rays.txt

rays.txt:
4.524520e+00	5.080820e+00	3.480030e+00	-3.025107e-01	3.848206e-01
8.720094e-01	5.183396e+00	2.956487e+00	7.075498e+00	8.000000e+00
0.000000e+00	0.000000e+00	-1.000000e+00	boxSTri321	box321	
4.524520e+00	5.080820e+00	3.480030e+00	-4.554681e-01
-3.514263e-01	-8.179538e-01	4.254556e+00	2.586706e+00	3.585657e+00
-3.348016e-16	0.000000e+00	0.000000e+00	1.000000e+00	box0.b	box0

4.524520e+00	5.080820e+00	3.480030e+00	-9.447599e-02
-6.675847e-01	-7.385154e-01	4.712197e+00	4.079331e+00	1.935029e+00
-2.426444e-16	0.000000e+00	0.000000e+00	1.000000e+00	box0.b	box0



Still that type of data comes near, but wont be sufficient for the graph
that I intend to make. The kind of script would allow for:

-setting the maximum number of rays traced
-outputting the coordinated of each ray in XYZ values where rays intersect,
all the way up to their source.
-these rays would purely be casted from the camera, not selected points in
space as in the xshowtrace approach
-what could be great is that rays will be coloured according to their
luminance value.
-the graph should be dense enough that the architecture from which the rays
were cast from becomes present in the graph.

In the end it'll be a very beautiful and powerful image, exposing radiance
inner mechanism!

Cheers, and thanks again for your feedback!

Jelle




From gregoryjward at gmail.com  Wed Jan 26 16:27:41 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Wed Jan 26 16:28:16 2005
Subject: [Radiance-general] Re: graphing radiance raytrace paths 
In-Reply-To: <20050126122817.D860F1C00097@mwinf1202.wanadoo.fr>
References: <20050126122817.D860F1C00097@mwinf1202.wanadoo.fr>
Message-ID: <D1AF9715-6FAE-11D9-A96E-000A95BB392A@gmail.com>

Hi Jelle,

You can get much closer to what you want if you simply add a 't' in 
your rtrace's -o option, like so:

% ximage someRendering.pic | rtrace -ab 5 -otodLpnsm -h -x 1 -i  
someOct.oct > rays.txt

This is going to give you more rays than you can possibly want, so I'd 
also set -ad 32 or so to reduce the number of interreflected rays 
generated.  Any other trimming, you'll have to do yourself.

Also, this will not show all the rays returning to the light sources, 
as this part of the calcuation never gets fully 'traced', the reason 
being that the direct calculation in Radiance attempts to minimize the 
actual number of rays followed to sources as an optimization.  If you 
want to see the paths all the way back to the sources, you'll have to 
get into the rt/source.c file and start modifying the code directly.

Regarding the -s option in xshowtrace, you can go in and change it 
yourself.  The sleep call is on line 260 in px/xshowtrace.c.  
Unfortunately, sleep only takes integer arguments, but you can replace 
it with a call to nanosleep() on most systems.

-Greg

> From: "Jelle Feringa // EZCT / Paris" <jelle.feringa@ezct.net>
> Date: January 26, 2005 4:32:11 AM PST
>
> Hi Greg,
>
> Wow! Thanks for pointing that out to me, that seems quite close to 
> what I
> intend to do. I think 'graph' wasn't necessarily the appropriate term, 
> since
> often it implies 2d. In fact I'm looking for a way to capture the rays
> traced in a rendering to a 3d (polygon) file, preferable colored 
> according
> to their illumination value. Maybe you've seen the Maya 6 feauture 
> where
> your able to visualize the global illumination cache in coloured 
> points. (if
> you haven't it might be interesting that I upload an image to my 
> server)
> I'd like to do something similar like that, but its important to trace 
> the
> whole path, right from the camera, all the way back to the light 
> source it
> emitted (sure, a lot of them will end up at the wall, but the more 
> rays can
> be traced to the source, the better)
>
> As I understood from the man pages, piping ximage (t) to rtrace is 
> close to
> what xshowtrace does, except that its output is numbers instead of 
> graphic
> lines superimposed on the rendering (by the way, there's no way to 
> control
> the interval of xshowtrace -s is there? Awesome soft! Thanks so much!)
>
> So here's what I tried using this approach:
>
> ximage someRendering.pic rtrace -ab 5 -oodLpnsm -h -x 1 -i   
> someOct.oct >
> rays.txt
> ...


From jelle.feringa at ezct.net  Wed Jan 26 17:21:47 2005
From: jelle.feringa at ezct.net (Jelle Feringa // EZCT / Paris)
Date: Wed Jan 26 17:22:15 2005
Subject: [Radiance-general] Re: graphing radiance raytrace paths 
Message-ID: <20050126162147.02B3F1C000BE@mwinf1203.wanadoo.fr>


% ximage someRendering.pic | rtrace -ab 5 -otodLpnsm -h -x 1 -i  
someOct.oct > rays.txt


	Wow, that's getting very close to what I need, thanks very much,
indeed I had problems getting rays to bounce. I'm sorry I never got to
wrestle rtrace before, I was stuck too long with the DTPrad wintel
binaries, I'm glad to have radiance's full power on my disposal now
(thanks Fransesco!)

Also, this will not show all the rays returning to the light sources, 
as this part of the calcuation never gets fully 'traced', the reason 
being that the direct calculation in Radiance attempts to minimize the 
actual number of rays followed to sources as an optimization.  If you 
want to see the paths all the way back to the sources, you'll have to 
get into the rt/source.c file and start modifying the code directly.


	Now that would be computationally perverse to undo that! Hmmmmmmm...
	Since I'm only starting to program (god bless python) that might be
somewhat ambitious ;-)
	Also tracing the rays to the source would be for sake of the image,
there's no numerical ardour to get that done...

Regarding the -s option in xshowtrace, you can go in and change it 
yourself.  The sleep call is on line 260 in px/xshowtrace.c.  
Unfortunately, sleep only takes integer arguments, but you can replace 
it with a call to nanosleep() on most systems.

	Now that sounds like something I could pull off!
	Cheers, thanks a lot!

Jelle.





From nickd at xco2.com  Thu Jan 27 09:47:56 2005
From: nickd at xco2.com (nick devlin)
Date: Thu Jan 27 09:48:10 2005
Subject: [Radiance-general] Waldram projection camera views. 
Message-ID: <opsk86p6xhbxkgpz@nick.xco2.com>

Good morning,

I am interested to know if it is possible to generate a camera view that  
replicates the projection of a waldram diagram? I then assume it would be  
possible to overlay the relevant waldram diagram using Pcomb.

In particular I am looking to address the calculations of Rights to Light  
issues in the UK. I am confident of being able to calculate the sky  
component within a scene at reference points, but as a nervious beginner  
would like to be able to generate the waldram diagram from the same  
reference points to double check the accuracy [and convince potential  
clients].

Many thanks..

Nickd



From chriskl at familyhealth.com.au  Thu Jan 27 13:04:55 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Thu Jan 27 13:06:34 2005
Subject: [Radiance-general] Waldram projection camera views.
In-Reply-To: <opsk86p6xhbxkgpz@nick.xco2.com>
References: <opsk86p6xhbxkgpz@nick.xco2.com>
Message-ID: <41F8D8E7.8000108@familyhealth.com.au>

Hi Nick,

Try writing a .cal file that deforms a regular grid of rays into a 
waldram grid.  You can find the equation for waldrams in oen of Percy J. 
Waldram's publications.  You can then fire the deformed rays into your 
scene, deforming the final render.

You can then overlay the grid by writing another .cal file that 
generates a grid overlay on the fly for pcomb.

It's kind of tricky, but really the devil is in the details :D

I'd like to help you more, but I need permission from my employer for 
that :D

Chris

nick devlin wrote:
> Good morning,
> 
> I am interested to know if it is possible to generate a camera view 
> that  replicates the projection of a waldram diagram? I then assume it 
> would be  possible to overlay the relevant waldram diagram using Pcomb.
> 
> In particular I am looking to address the calculations of Rights to 
> Light  issues in the UK. I am confident of being able to calculate the 
> sky  component within a scene at reference points, but as a nervious 
> beginner  would like to be able to generate the waldram diagram from the 
> same  reference points to double check the accuracy [and convince 
> potential  clients].
> 
> Many thanks..
> 
> Nickd
> 
> 
> 
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general

From tarik.rahman at ed.ac.uk  Thu Jan 27 17:18:45 2005
From: tarik.rahman at ed.ac.uk (Tarik Rahman)
Date: Thu Jan 27 17:19:08 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <opsk86p6xhbxkgpz@nick.xco2.com>
References: <opsk86p6xhbxkgpz@nick.xco2.com>
Message-ID: <1106842725.41f9146558dbb@sms.ed.ac.uk>

Hi
I'm trying to light a room with the light that's irradiated onto a mirror sphere
in order to insert synthetic objects into the room. In radiance I take a close
up .pic of the mirror sphere and convert it to a light probe using HDRShop. Do
I use same code as in Debevec's tutorial, you know
void colorpict hdr_env
7 red green blue lp_smallMirr.hdr angmap.cal sb_u sb_v
0
0

hdr_env glow env_glow
0
0
4 1 1 1 0

!genbox env_glow room 50 30 50 -i | -t 2.5 2.85 2.5

for the lighting? Will angmap.cal work for any light probe or do I have to write
my own because when I render this, the reflections from the light probe aren't
mapped onto the walls of the room properly?

Thanks for any help

Tarik


--
Tarik Rahman
PhD student, Institute of Perception, Action and Behaviour
School of Informatics
University of Edinburgh

From tiago at tkh.att.ne.jp  Thu Jan 27 17:44:34 2005
From: tiago at tkh.att.ne.jp (Santiago Torres)
Date: Thu Jan 27 17:42:02 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <1106842725.41f9146558dbb@sms.ed.ac.uk>
Message-ID: <ABEIIOCILNBBDDEPEPICKEBPCEAA.tiago@tkh.att.ne.jp>

Hi Tarik,
I`ve never used a mirror sphere, but have mapped to source. You have to look
that the .cal file corresponds to the kind of light probe you are using
(i.e. that the directions are transated correctly into pixel coordinates)
I think Debevec uses at least two kind of light probes, cubic and spherical.
Maybe that`s the problem?
HTH,

Santiago




> -----Original Message-----
> From: radiance-general-bounces@radiance-online.org
> [mailto:radiance-general-bounces@radiance-online.org]On Behalf Of
> Tarik Rahman
> Sent: Friday, January 28, 2005 1:19 AM
> To: Radiance general discussion
> Subject: [Radiance-general] Lighting from a light probe
>
>
> Hi
> I'm trying to light a room with the light that's irradiated onto
> a mirror sphere
> in order to insert synthetic objects into the room. In radiance I
> take a close
> up .pic of the mirror sphere and convert it to a light probe
> using HDRShop. Do
> I use same code as in Debevec's tutorial, you know
> void colorpict hdr_env
> 7 red green blue lp_smallMirr.hdr angmap.cal sb_u sb_v
> 0
> 0
>
> hdr_env glow env_glow
> 0
> 0
> 4 1 1 1 0
>
> !genbox env_glow room 50 30 50 -i | -t 2.5 2.85 2.5
>
> for the lighting? Will angmap.cal work for any light probe or do
> I have to write
> my own because when I render this, the reflections from the light
> probe aren't
> mapped onto the walls of the room properly?
>
> Thanks for any help
>
> Tarik
>
>
> --
> Tarik Rahman
> PhD student, Institute of Perception, Action and Behaviour
> School of Informatics
> University of Edinburgh
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>
>



From gregoryjward at gmail.com  Thu Jan 27 17:58:46 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Thu Jan 27 17:59:20 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <1106842725.41f9146558dbb@sms.ed.ac.uk>
References: <opsk86p6xhbxkgpz@nick.xco2.com>
	<1106842725.41f9146558dbb@sms.ed.ac.uk>
Message-ID: <B5386EB3-7084-11D9-B9C1-000A95BB392A@gmail.com>

Hi Tarik,

You have to make sure your light probe capture is aligned properly, so 
it's a matter of figuring out the right orientation vectors in your 
synthetic scene.  There are also matting issues in the final combine 
stage.  Are you working from Debevec's tutorial, which was published in 
IEEE CG&A?  See also the thread from November on this list under the 
heading "Alpha channel/object matte".  There are some scripts and tips 
in there.

There are a lot of hurdles to jump in getting image-based lighting to 
work.  A lot of it, you're just going to have to figure out on your 
own, I'm afraid.

Good luck!
-Greg


From tarik.rahman at ed.ac.uk  Thu Jan 27 18:02:08 2005
From: tarik.rahman at ed.ac.uk (Tarik Rahman)
Date: Thu Jan 27 18:02:31 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <ABEIIOCILNBBDDEPEPICKEBPCEAA.tiago@tkh.att.ne.jp>
References: <ABEIIOCILNBBDDEPEPICKEBPCEAA.tiago@tkh.att.ne.jp>
Message-ID: <1106845328.41f91e90560b1@sms.ed.ac.uk>

Yeah I'm pretty sure it's the spherical light probe that the code is for. I
don't know if it matters what the up vector, azimuth and elevation angles are
from the .pic file and because I think HDRShop reads the view parameters and
converts it to a .hdr light probe correctly.

Quoting Santiago Torres <tiago@tkh.att.ne.jp>:

> Hi Tarik,
> I`ve never used a mirror sphere, but have mapped to source. You have to look
> that the .cal file corresponds to the kind of light probe you are using
> (i.e. that the directions are transated correctly into pixel coordinates)
> I think Debevec uses at least two kind of light probes, cubic and spherical.
> Maybe that`s the problem?
> HTH,
>
> Santiago
>
>
>
>
> > -----Original Message-----
> > From: radiance-general-bounces@radiance-online.org
> > [mailto:radiance-general-bounces@radiance-online.org]On Behalf Of
> > Tarik Rahman
> > Sent: Friday, January 28, 2005 1:19 AM
> > To: Radiance general discussion
> > Subject: [Radiance-general] Lighting from a light probe
> >
> >
> > Hi
> > I'm trying to light a room with the light that's irradiated onto
> > a mirror sphere
> > in order to insert synthetic objects into the room. In radiance I
> > take a close
> > up .pic of the mirror sphere and convert it to a light probe
> > using HDRShop. Do
> > I use same code as in Debevec's tutorial, you know
> > void colorpict hdr_env
> > 7 red green blue lp_smallMirr.hdr angmap.cal sb_u sb_v
> > 0
> > 0
> >
> > hdr_env glow env_glow
> > 0
> > 0
> > 4 1 1 1 0
> >
> > !genbox env_glow room 50 30 50 -i | -t 2.5 2.85 2.5
> >
> > for the lighting? Will angmap.cal work for any light probe or do
> > I have to write
> > my own because when I render this, the reflections from the light
> > probe aren't
> > mapped onto the walls of the room properly?
> >
> > Thanks for any help
> >
> > Tarik
> >
> >
> > --
> > Tarik Rahman
> > PhD student, Institute of Perception, Action and Behaviour
> > School of Informatics
> > University of Edinburgh
> >
> > _______________________________________________
> > Radiance-general mailing list
> > Radiance-general@radiance-online.org
> > http://www.radiance-online.org/mailman/listinfo/radiance-general
> >
> >
>
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>


--
Tarik Rahman
PhD student, Institute of Perception, Action and Behaviour
School of Informatics
University of Edinburgh

From gregoryjward at gmail.com  Thu Jan 27 18:08:49 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Thu Jan 27 18:09:31 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <1106845328.41f91e90560b1@sms.ed.ac.uk>
References: <ABEIIOCILNBBDDEPEPICKEBPCEAA.tiago@tkh.att.ne.jp>
	<1106845328.41f91e90560b1@sms.ed.ac.uk>
Message-ID: <1CCD7310-7086-11D9-B9C1-000A95BB392A@gmail.com>

There's something I'm not getting, here.  Why would you synthesize a 
light probe?  The whole point is to use a captured environment, isn't 
it?  If you had a good synthetic environment, you would just render 
your synthetic object(s) into it directly.  Or are you doing this as a 
test?  I would be surprised if HDRShop paid attention to the Radiance 
view parameters in the .pic file, as it's not expecting to read a 
Radiance rendering as a light probe.

By the way, there are two types of spherical projections used in 
HDRShop -- an angular projection and a spherical projection.  They are 
subtly different.

-Greg

> From: Tarik Rahman <tarik.rahman@ed.ac.uk>
> Date: January 27, 2005 9:02:08 AM PST
>
> Yeah I'm pretty sure it's the spherical light probe that the code is 
> for. I
> don't know if it matters what the up vector, azimuth and elevation 
> angles are
> from the .pic file and because I think HDRShop reads the view 
> parameters and
> converts it to a .hdr light probe correctly.


From chriskl at familyhealth.com.au  Thu Jan 27 18:25:53 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Thu Jan 27 18:27:12 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <B5386EB3-7084-11D9-B9C1-000A95BB392A@gmail.com>
References: <opsk86p6xhbxkgpz@nick.xco2.com>	<1106842725.41f9146558dbb@sms.ed.ac.uk>
	<B5386EB3-7084-11D9-B9C1-000A95BB392A@gmail.com>
Message-ID: <41F92421.5000409@familyhealth.com.au>

> There are a lot of hurdles to jump in getting image-based lighting to 
> work.  A lot of it, you're just going to have to figure out on your own, 
> I'm afraid.

And once you've figured it out, add some information about the process 
to the Wiki :)

http://www.radiance-wiki.org/

Chris

From kthibault at biomechanicsinc.com  Thu Jan 27 18:48:07 2005
From: kthibault at biomechanicsinc.com (Kirk Thibault)
Date: Thu Jan 27 18:48:37 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <1106842725.41f9146558dbb@sms.ed.ac.uk>
References: <opsk86p6xhbxkgpz@nick.xco2.com>
	<1106842725.41f9146558dbb@sms.ed.ac.uk>
Message-ID: <9A177C4E-708B-11D9-9487-000A956A0F62@biomechanicsinc.com>

One of the first things to consider is your "up" vector.  Debevec uses 
Y up in hs <angmap.cal>, Radiance defaults to Z up.  This is easily 
changed in the Debevec <angmap.cal> file by simply replacing the 
coordinate (x,y,z) references consistently in the angmap.cal file (see 
Debevec's comments in the <angmap.cal> file for an explanation of the 
direction convention).

It sounds like you are trying to light the image with a light probe and 
also include polygons in the scene that will appear as the synthetic 
"room" (floor, ceiling, and 4 walls [N, E, S, W]).  You may have better 
luck generating a "cross" format probe, then taking each of the six 
cross segments and individually mapping them to the walls of your room. 
  Then give each of the polygons the glow and let the HDR-images on each 
of the six "room" polygons illuminate your interior scene.

Does that make sense?  it may be easier to try by using one of 
Debevec's cross probes on his site and xforming it appropriately so 
that the correct segment fills each of the six room polygons - once 
this is done you can try illuminating your Rad. scene with it.

Fun!

kirk

On Jan 27, 2005, at 11:18 AM, Tarik Rahman wrote:

> Hi
> I'm trying to light a room with the light that's irradiated onto a 
> mirror sphere
> in order to insert synthetic objects into the room. In radiance I take 
> a close
> up .pic of the mirror sphere and convert it to a light probe using 
> HDRShop. Do
> I use same code as in Debevec's tutorial, you know
> void colorpict hdr_env
> 7 red green blue lp_smallMirr.hdr angmap.cal sb_u sb_v
> 0
> 0
>
> hdr_env glow env_glow
> 0
> 0
> 4 1 1 1 0
>
> !genbox env_glow room 50 30 50 -i | -t 2.5 2.85 2.5
>
> for the lighting? Will angmap.cal work for any light probe or do I 
> have to write
> my own because when I render this, the reflections from the light 
> probe aren't
> mapped onto the walls of the room properly?
>
> Thanks for any help
>
> Tarik
>
>
> --
> Tarik Rahman
> PhD student, Institute of Perception, Action and Behaviour
> School of Informatics
> University of Edinburgh
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general


From tarik.rahman at ed.ac.uk  Thu Jan 27 19:03:28 2005
From: tarik.rahman at ed.ac.uk (Tarik Rahman)
Date: Thu Jan 27 19:03:52 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <1CCD7310-7086-11D9-B9C1-000A95BB392A@gmail.com>
References: <ABEIIOCILNBBDDEPEPICKEBPCEAA.tiago@tkh.att.ne.jp>
	<1106845328.41f91e90560b1@sms.ed.ac.uk>
	<1CCD7310-7086-11D9-B9C1-000A95BB392A@gmail.com>
Message-ID: <1106849008.41f92cf0a42cb@sms.ed.ac.uk>

Yes I see what you mean. I am doing it as a test though, using the angular
projection. Slipped my mind, of course HDRShop wouldn't be looking at the view
parameters in a .pic file.


Quoting Greg Ward <gregoryjward@gmail.com>:

> There's something I'm not getting, here.  Why would you synthesize a
> light probe?  The whole point is to use a captured environment, isn't
> it?  If you had a good synthetic environment, you would just render
> your synthetic object(s) into it directly.  Or are you doing this as a
> test?  I would be surprised if HDRShop paid attention to the Radiance
> view parameters in the .pic file, as it's not expecting to read a
> Radiance rendering as a light probe.
>
> By the way, there are two types of spherical projections used in
> HDRShop -- an angular projection and a spherical projection.  They are
> subtly different.
>
> -Greg
>
> > From: Tarik Rahman <tarik.rahman@ed.ac.uk>
> > Date: January 27, 2005 9:02:08 AM PST
> >
> > Yeah I'm pretty sure it's the spherical light probe that the code is
> > for. I
> > don't know if it matters what the up vector, azimuth and elevation
> > angles are
> > from the .pic file and because I think HDRShop reads the view
> > parameters and
> > converts it to a .hdr light probe correctly.
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
>


--
Tarik Rahman
PhD student, Institute of Perception, Action and Behaviour
School of Informatics
University of Edinburgh

From kthibault at biomechanicsinc.com  Thu Jan 27 22:42:14 2005
From: kthibault at biomechanicsinc.com (Kirk Thibault)
Date: Thu Jan 27 22:42:46 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <1106842725.41f9146558dbb@sms.ed.ac.uk>
References: <opsk86p6xhbxkgpz@nick.xco2.com>
	<1106842725.41f9146558dbb@sms.ed.ac.uk>
Message-ID: <4F29E743-70AC-11D9-B928-000A956A0F62@biomechanicsinc.com>

I don't know if attachments are allowed, but here's a graphical 
explanation of my previous babble.

kirk

PS - Sorry if the attachment doesn't post - I can email it to you Tarik.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mapping.jpg
Type: image/jpeg
Size: 33872 bytes
Desc: not available
Url : http://radiance-online.org/pipermail/radiance-general/attachments/20050127/ca3348a3/mapping-0001.jpg
-------------- next part --------------


On Jan 27, 2005, at 11:18 AM, Tarik Rahman wrote:

> Hi
> I'm trying to light a room with the light that's irradiated onto a 
> mirror sphere
> in order to insert synthetic objects into the room. In radiance I take 
> a close
> up .pic of the mirror sphere and convert it to a light probe using 
> HDRShop. Do
> I use same code as in Debevec's tutorial, you know
> void colorpict hdr_env
> 7 red green blue lp_smallMirr.hdr angmap.cal sb_u sb_v
> 0
> 0
>
> hdr_env glow env_glow
> 0
> 0
> 4 1 1 1 0
>
> !genbox env_glow room 50 30 50 -i | -t 2.5 2.85 2.5
>
> for the lighting? Will angmap.cal work for any light probe or do I 
> have to write
> my own because when I render this, the reflections from the light 
> probe aren't
> mapped onto the walls of the room properly?
>
> Thanks for any help
>
> Tarik
>
>
> --
> Tarik Rahman
> PhD student, Institute of Perception, Action and Behaviour
> School of Informatics
> University of Edinburgh
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
From gregoryjward at gmail.com  Thu Jan 27 23:10:46 2005
From: gregoryjward at gmail.com (Gregory J. Ward)
Date: Thu Jan 27 23:11:24 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <4F29E743-70AC-11D9-B928-000A956A0F62@biomechanicsinc.com>
References: <opsk86p6xhbxkgpz@nick.xco2.com>
	<1106842725.41f9146558dbb@sms.ed.ac.uk>
	<4F29E743-70AC-11D9-B928-000A956A0F62@biomechanicsinc.com>
Message-ID: <4B43F10C-70B0-11D9-A50E-00306540F848@gmail.com>

Regarding posting images, I did manage to get the attachment from 
Kirk's post, but in general we should keep attachments to a minimum.  A 
lot of mailers get upset about them, and they create long download 
times for those of us who are still in 56K modemland.  (Not me, but 
this friend of mine...)

The general etiquette is if it's an image and it's over 100K, then it 
should go on a website with a URL for those who are interested.  If you 
have multiple images and details, again a webpage is preferable.

Oh, and if you reply to a post with an attachment -- PLEASE take the 
attachment off your own e-mail.  In general, I like to keep attached 
copies of e-mails to abbreviated versions (unless they are short), and 
not attach e-mails with a nested attachment.  In general, everyone's 
been really good about that.

That said, this is a really, really nice diagram.  Thanks, Kirk.

-Greg


From kthibault at biomechanicsinc.com  Fri Jan 28 02:35:45 2005
From: kthibault at biomechanicsinc.com (Kirk Thibault)
Date: Fri Jan 28 02:39:12 2005
Subject: [Radiance-general] Lighting from a light probe
In-Reply-To: <4B43F10C-70B0-11D9-A50E-00306540F848@gmail.com>
References: <opsk86p6xhbxkgpz@nick.xco2.com>
	<1106842725.41f9146558dbb@sms.ed.ac.uk>
	<4F29E743-70AC-11D9-B928-000A956A0F62@biomechanicsinc.com>
	<4B43F10C-70B0-11D9-A50E-00306540F848@gmail.com>
Message-ID: <EE4418BA-70CC-11D9-9E1D-000393868CBC@biomechanicsinc.com>

Sorry - I figured I might cause a problem - I tried to make the file 
about 50k but, next time, I'll try to find some web space and post the 
file there and post a link to it here.

Apologies,

kirk

On Jan 27, 2005, at 5:10 PM, Gregory J. Ward wrote:

> Regarding posting images, I did manage to get the attachment from 
> Kirk's post, but in general we should keep attachments to a minimum.  
> A lot of mailers get upset about them, and they create long download 
> times for those of us who are still in 56K modemland.  (Not me, but 
> this friend of mine...)
>
> The general etiquette is if it's an image and it's over 100K, then it 
> should go on a website with a URL for those who are interested.  If 
> you have multiple images and details, again a webpage is preferable.
>
> Oh, and if you reply to a post with an attachment -- PLEASE take the 
> attachment off your own e-mail.  In general, I like to keep attached 
> copies of e-mails to abbreviated versions (unless they are short), and 
> not attach e-mails with a nested attachment.  In general, everyone's 
> been really good about that.
>
> That said, this is a really, really nice diagram.  Thanks, Kirk.
>
> -Greg
>
>
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general


From chriskl at familyhealth.com.au  Fri Jan 28 15:06:46 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Fri Jan 28 15:08:15 2005
Subject: [Radiance-general] Generating a black and white pic
Message-ID: <41FA46F6.6020302@familyhealth.com.au>

Hi,

I wish to render a scene and output a black and white image where the 
black areas have 0 irradiance and everything else is white.

I then want to pcomb this over another image so that on that image all 
the black parts of the mask appear in black, but wherever the mask is 
white, the underlying picture shows through.

How can I do this?  I can see it should be possible, but the devil is in 
the details it seems...

Thanks,

Chris

From raphael.compagnon at eif.ch  Fri Jan 28 15:13:53 2005
From: raphael.compagnon at eif.ch (Raphael Compagnon)
Date: Fri Jan 28 15:14:16 2005
Subject: [Radiance-general] Generating a black and white pic
In-Reply-To: <41FA46F6.6020302@familyhealth.com.au>
Message-ID: <5.1.0.14.2.20050128151205.01fe1bb8@pop.eif.ch>

This command should do what you expect:

pcomb -e 'ro=li(1)*ri(2);go=li(1)*gi(2);bo=li(1)*bi(2)' mask.pic 
picture.pic >result.pic

At 28.01.2005 15:06, you wrote:
>Hi,
>
>I wish to render a scene and output a black and white image where the 
>black areas have 0 irradiance and everything else is white.
>
>I then want to pcomb this over another image so that on that image all the 
>black parts of the mask appear in black, but wherever the mask is white, 
>the underlying picture shows through.
>
>How can I do this?  I can see it should be possible, but the devil is in 
>the details it seems...
>
>Thanks,
>
>Chris
>
>_______________________________________________
>Radiance-general mailing list
>Radiance-general@radiance-online.org
>http://www.radiance-online.org/mailman/listinfo/radiance-general


From chriskl at familyhealth.com.au  Fri Jan 28 15:58:53 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Fri Jan 28 16:00:14 2005
Subject: [Radiance-general] Generating a black and white pic
In-Reply-To: <5.1.0.14.2.20050128151205.01fe1bb8@pop.eif.ch>
References: <5.1.0.14.2.20050128151205.01fe1bb8@pop.eif.ch>
Message-ID: <41FA532D.1030608@familyhealth.com.au>



Raphael Compagnon wrote:
> This command should do what you expect:
> 
> pcomb -e 'ro=li(1)*ri(2);go=li(1)*gi(2);bo=li(1)*bi(2)' mask.pic 
> picture.pic >result.pic

Ah yes, and I can threshold my mask image like this:

pcomb -e 'lo=if(li(1), 1, 0)' input.pic > mask.pic

Cheers,

Chris

From gregoryjward at gmail.com  Fri Jan 28 16:15:46 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Fri Jan 28 16:16:27 2005
Subject: [Radiance-general] Generating a black and white pic
In-Reply-To: <41FA532D.1030608@familyhealth.com.au>
References: <5.1.0.14.2.20050128151205.01fe1bb8@pop.eif.ch>
	<41FA532D.1030608@familyhealth.com.au>
Message-ID: <7C7BFD29-713F-11D9-970E-000A95BB392A@gmail.com>

Be careful with thresholding, since the if() function takes any 
non-zero positive value as "true".  For this reason, it's generally a 
good idea to use some small epsilon to avoid errors, like:

	if(li(1)-1e-7, 1, 0);

-G

> From: Christopher Kings-Lynne <chriskl@familyhealth.com.au>
> Date: January 28, 2005 6:58:53 AM PST
>
> Raphael Compagnon wrote:
>> This command should do what you expect:
>> pcomb -e 'ro=li(1)*ri(2);go=li(1)*gi(2);bo=li(1)*bi(2)' mask.pic 
>> picture.pic >result.pic
>
> Ah yes, and I can threshold my mask image like this:
>
> pcomb -e 'lo=if(li(1), 1, 0)' input.pic > mask.pic
>
> Cheers,
>
> Chris


From chriskl at familyhealth.com.au  Fri Jan 28 16:17:41 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Fri Jan 28 16:19:08 2005
Subject: [Radiance-general] Generating a black and white pic
In-Reply-To: <7C7BFD29-713F-11D9-970E-000A95BB392A@gmail.com>
References: <5.1.0.14.2.20050128151205.01fe1bb8@pop.eif.ch>	<41FA532D.1030608@familyhealth.com.au>
	<7C7BFD29-713F-11D9-970E-000A95BB392A@gmail.com>
Message-ID: <41FA5795.70202@familyhealth.com.au>

> Be careful with thresholding, since the if() function takes any non-zero 
> positive value as "true".  For this reason, it's generally a good idea 
> to use some small epsilon to avoid errors, like:
> 
>     if(li(1)-1e-7, 1, 0);

In my case, the areas are in total shadow (ab=0), and hence have an 
input brightness of exactly zero.

So in your example above, you're also including areas that have a very 
slight amount of brightness, right?

Chris

From gregoryjward at gmail.com  Fri Jan 28 16:41:31 2005
From: gregoryjward at gmail.com (Greg Ward)
Date: Fri Jan 28 16:42:02 2005
Subject: Fwd: [Radiance-general] Generating a black and white pic
Message-ID: <14DA4C4E-7143-11D9-BEF4-000A95BB392A@gmail.com>

A radiance value of 10^-7 is negligible.  However, even if your value 
_should_ be exactly zero, round-off error could bring it up to as high 
as 10^-15 or so, which would cause your if statement to return 1.  I'm 
just suggesting that you be careful when comparing floating point 
values.

-G

> From: Christopher Kings-Lynne <chriskl@familyhealth.com.au>
> Date: January 28, 2005 7:17:41 AM PST
>
>> Be careful with thresholding, since the if() function takes any 
>> non-zero positive value as "true".  For this reason, it's generally a 
>> good idea to use some small epsilon to avoid errors, like:
>>     if(li(1)-1e-7, 1, 0);
>
> In my case, the areas are in total shadow (ab=0), and hence have an 
> input brightness of exactly zero.
>
> So in your example above, you're also including areas that have a very 
> slight amount of brightness, right?
>
> Chris


From gregoryjward at gmail.com  Fri Jan 28 19:27:55 2005
From: gregoryjward at gmail.com (Gregory J. Ward)
Date: Fri Jan 28 19:28:29 2005
Subject: [Radiance-general] Compressed (LZW) TIFFs
Message-ID: <54119F10-715A-11D9-BAF5-00306540F848@gmail.com>

Hi Everyone,

For anyone who has been missing the -z option of ra_tiff, which used to 
generate LZW output, it is working again in the latest release, or 
should have been.  The issue surrounded the infamous Unisys patent on 
LZW compression, which expired a couple of years ago.  The 3.6 release 
was _supposed_ to have the new TIFF library with -z enabled again, but 
due to pilot error (mine), it never got in there.

To get the latest version, you'll need to download and recompile the 
overlay for 3.6 that's on the Radiance websites:

	http://radsite.lbl.gov/radiance/download.html
and
	http://www.radiance-online.org/software/

Look for the file "rad3R6P1supp.tar.gz".

If you don't know what ra_tiff is or have never used and don't intend 
to use this option, then feel free to ignore this message.

-Greg


From chriskl at familyhealth.com.au  Mon Jan 31 11:56:36 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Mon Jan 31 11:58:18 2005
Subject: [Radiance-general] Calculating kWh
Message-ID: <41FE0EE4.402@familyhealth.com.au>

Hi,

How would I convert the irradiance given on a surface to kilowatt hours?

(Sorry for the dumb question :D)

Chris

From Giulio.Antonutto at arup.com  Mon Jan 31 12:12:14 2005
From: Giulio.Antonutto at arup.com (Giulio Antonutto)
Date: Mon Jan 31 12:12:51 2005
Subject: [Radiance-general] Calculating kWh
Message-ID: <DC0CAEEA090E984C911D3B85B16C3F900302C3FB@l-gnts05>

not sure I understood your question, however:
100 kW/sqm  ->  take the area of the surface (10sqm) then you get 1'000 kW 
then find the time interval (7 hours, may be) and kW h = 7'000

if you need to integrate during the day you need the average in kW for a
given time period and multiply for that....
is it this your question?


> ----------
> From: 	radiance-general-bounces@radiance-online.org on behalf of
> Christopher Kings-Lynne
> Reply To: 	Radiance general discussion
> Sent: 	Monday, January 31, 2005 10:56 AM
> To: 	Radiance-General
> Subject: 	[Radiance-general] Calculating kWh
> 
> Hi,
> 
> How would I convert the irradiance given on a surface to kilowatt hours?
> 
> (Sorry for the dumb question :D)
> 
> Chris
> 
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
> 
> 
> 
___________________________________________________________________
Electronic mail messages entering and leaving Arup business
systems are scanned for acceptability of content and viruses.

From chriskl at familyhealth.com.au  Mon Jan 31 12:16:56 2005
From: chriskl at familyhealth.com.au (Christopher Kings-Lynne)
Date: Mon Jan 31 12:18:20 2005
Subject: [Radiance-general] Calculating kWh
In-Reply-To: <DC0CAEEA090E984C911D3B85B16C3F900302C3FB@l-gnts05>
References: <DC0CAEEA090E984C911D3B85B16C3F900302C3FB@l-gnts05>
Message-ID: <41FE13A8.3040701@familyhealth.com.au>

I guess my question is 'in what units is the irradiance (-i) given in 
Radiance'?

Chris

Giulio Antonutto wrote:
> not sure I understood your question, however:
> 100 kW/sqm  ->  take the area of the surface (10sqm) then you get 1'000 kW 
> then find the time interval (7 hours, may be) and kW h = 7'000
> 
> if you need to integrate during the day you need the average in kW for a
> given time period and multiply for that....
> is it this your question?
> 
> 
> 
>>----------
>>From: 	radiance-general-bounces@radiance-online.org on behalf of
>>Christopher Kings-Lynne
>>Reply To: 	Radiance general discussion
>>Sent: 	Monday, January 31, 2005 10:56 AM
>>To: 	Radiance-General
>>Subject: 	[Radiance-general] Calculating kWh
>>
>>Hi,
>>
>>How would I convert the irradiance given on a surface to kilowatt hours?
>>
>>(Sorry for the dumb question :D)
>>
>>Chris
>>
>>_______________________________________________
>>Radiance-general mailing list
>>Radiance-general@radiance-online.org
>>http://www.radiance-online.org/mailman/listinfo/radiance-general
>>
>>
>>
> 
> ___________________________________________________________________
> Electronic mail messages entering and leaving Arup business
> systems are scanned for acceptability of content and viruses.
> 
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general

From Giulio.Antonutto at arup.com  Mon Jan 31 12:36:46 2005
From: Giulio.Antonutto at arup.com (Giulio Antonutto)
Date: Mon Jan 31 12:37:42 2005
Subject: [Radiance-general] Calculating kWh
Message-ID: <DC0CAEEA090E984C911D3B85B16C3F900302C3FF@l-gnts05>

ooops....
well I believe that the irradiance Radiance gives you is referred only to
the visible spectrum....
unless you use some trick... (but I could be wrong...)
may be you wish to check some interesting works about the matter:

http://www.dream.unipa.it/dream/pub/dot/anselmo/radiance/05.php

and

R. Compagnon, D. Raydan, Irradiance and illuminance distributions in urban
areas 
Proceedings of PLEA 2000, Cambridge (UK), July 2000, editors: K. Steemers
and S. Yannas, James & James (Science Publishers) Ltd, London, 2000.

hope this is more usefull...
cheers
giulio

> ----------
> From: 	radiance-general-bounces@radiance-online.org on behalf of
> Christopher Kings-Lynne
> Reply To: 	Radiance general discussion
> Sent: 	Monday, January 31, 2005 11:16 AM
> To: 	Radiance general discussion
> Subject: 	Re: [Radiance-general] Calculating kWh
> 
> I guess my question is 'in what units is the irradiance (-i) given in 
> Radiance'?
> 
> Chris
> 
> Giulio Antonutto wrote:
> > not sure I understood your question, however:
> > 100 kW/sqm  ->  take the area of the surface (10sqm) then you get 1'000
> kW 
> > then find the time interval (7 hours, may be) and kW h = 7'000
> > 
> > if you need to integrate during the day you need the average in kW for a
> > given time period and multiply for that....
> > is it this your question?
> > 
> > 
> > 
> >>----------
> >>From: 	radiance-general-bounces@radiance-online.org on behalf of
> >>Christopher Kings-Lynne
> >>Reply To: 	Radiance general discussion
> >>Sent: 	Monday, January 31, 2005 10:56 AM
> >>To: 	Radiance-General
> >>Subject: 	[Radiance-general] Calculating kWh
> >>
> >>Hi,
> >>
> >>How would I convert the irradiance given on a surface to kilowatt hours?
> >>
> >>(Sorry for the dumb question :D)
> >>
> >>Chris
> >>
> >>_______________________________________________
> >>Radiance-general mailing list
> >>Radiance-general@radiance-online.org
> >>http://www.radiance-online.org/mailman/listinfo/radiance-general
> >>
> >>
> >>
> > 
> > ___________________________________________________________________
> > Electronic mail messages entering and leaving Arup business
> > systems are scanned for acceptability of content and viruses.
> > 
> > _______________________________________________
> > Radiance-general mailing list
> > Radiance-general@radiance-online.org
> > http://www.radiance-online.org/mailman/listinfo/radiance-general
> 
> _______________________________________________
> Radiance-general mailing list
> Radiance-general@radiance-online.org
> http://www.radiance-online.org/mailman/listinfo/radiance-general
> 
> 
> 
___________________________________________________________________
Electronic mail messages entering and leaving Arup business
systems are scanned for acceptability of content and viruses.

From njlander at yahoo.com.au  Mon Jan 31 23:17:41 2005
From: njlander at yahoo.com.au (Nicholas Lander)
Date: Mon Jan 31 23:18:59 2005
Subject: [Radiance-general] Waldram projection camera views. 
Message-ID: <20050131221741.10212.qmail@web54608.mail.yahoo.com>

Nick,

If you?re looking at right to light issues, I?d
suggest using a simpler program, such as Ecotect
(www.squ1.com)  which calculates waldram diagrams for
you.  If memory serves, waldram diagrams come up in
terms of view of sky / skylight availability, which
are geometric issues, rather than ones of daylight.  

Then you can just use Radiance in the regular way to
work out change in available daylight in a room.

Regards,

Nick L

>Hi Nick,
>
>Try writing a .cal file that deforms a regular grid
>of rays into a 
>waldram grid.  You can find the equation for
>waldrams in oen of Percy J. 
>Waldram's publications.  You can then fire the
>deformed rays into your 
>scene, deforming the final render.
>
>You can then overlay the grid by writing >another
.cal file that 
>generates a grid overlay on the fly for pcomb.
>
>It's kind of tricky, but really the devil is in the
>details :D
>
>I'd like to help you more, but I need permission
>from my employer for 
>that :D
>
>Chris
>
>nick devlin wrote:
>> Good morning,
>> 
>> I am interested to know if it is possible to
>generate a camera view 
>> that  replicates the projection of a waldram
>diagram? I then assume it 
>> would be  possible to overlay the relevant waldram
>diagram using Pcomb.
>> 
>> In particular I am looking to address the
>calculations of Rights to 
>> Light  issues in the UK. I am confident of being
>able to calculate the 
>> sky  component within a scene at reference points,
>but as a nervious 
>> beginner  would like to be able to generate the
>waldram diagram from the 
>> same  reference points to double check the
>accuracy [and convince 
>> potential  clients].
>> 
>> Many thanks..
>> 
>> Nickd
>> 
>> 
>> 
>> _______________________________________________
>> Radiance-general mailing list
>> Radiance-general at radiance-online.org
>>
http://www.radiance->online.org/mailman/listinfo/radiance-general




	
	
		
___________________________________________________________ 
ALL-NEW Yahoo! Messenger - all new features - even more fun! http://uk.messenger.yahoo.com

